{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58ab2118",
   "metadata": {},
   "source": [
    "## üìò Domina tus datos con Pandas: Fundamentos esenciales para todo Analista üêº"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db85604a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "üë®‚Äçüíª Autor: Brayan Neciosup  \n",
    "üìç Portafolio: [brayanneciosup](https://bryanneciosup626.wixsite.com/brayandataanalitics)  \n",
    "üîó LinkedIn: [linkedin.com/brayanneciosup](https://www.linkedin.com/in/brayan-rafael-neciosup-bola%C3%B1os-407a59246/)  \n",
    "üíª GitHub: [github.com/BrayanR03](https://github.com/BrayanR03)  \n",
    "üìö Serie: Fundamentos de Pandas y Polars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5deda25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar librer√≠a: pip install pandas\n",
    "# Importamos la librer√≠a\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f41eeb4",
   "metadata": {},
   "source": [
    "### üìå Manipulaci√≥n de Datos en Pandas: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f864ed",
   "metadata": {},
   "source": [
    "La manipulaci√≥n de datos, tambi√©n conocida como data wrangling, es una fase \n",
    "fundamental en todo proyecto de an√°lisis de datos. Consiste en transformar \n",
    "un dataset crudo, es decir, datos en su forma original, posiblemente desordenada o\n",
    "incompleta en un formato estructurado y √∫til, como un DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83843421",
   "metadata": {},
   "source": [
    "#### Fase 1. Fuentes de Datos üóÉÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0530db",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "    Pandas üêº permite leer datos desde m√∫ltiples fuentes como archivos CSV, Excel, JSON, \n",
    "    bases de datos SQL, entre otros formatos comunes. Esta flexibilidad facilita el trabajo\n",
    "    con datasets provenientes de distintos or√≠genes, tanto locales como remotos.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bfcdfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eventos_logs.json', 'json_basico.json', 'Pedidos.xlsx', 'penguins.csv', 'titanic.csv']\n"
     ]
    }
   ],
   "source": [
    "# Paso A). DEFINIR LA CARPETA ORIGEN DE DONDE PROVIENE NUESTROS DATASETS (LOCAL)\n",
    "\"\"\"\n",
    "    üìù SINTAXIS: \n",
    "        \n",
    "        carpeta_origen = \"RutaCarpetaOrigen\"\n",
    "    \n",
    "    ### üß† Va a depender en que entorno nos encontremos porque las rutas \n",
    "    ###     de carpetas pueden ser (\\) o (/).\n",
    "\"\"\"\n",
    "# üí° EJEMPLO 1 (Ruta completa):\n",
    "\n",
    "# carpeta_origen = \"C:/Users/USER/Documents/FundamentosPandasPolars/datasets\" \n",
    "\n",
    "# print(carpeta_origen)\n",
    "\n",
    "# üí° EJEMPLO 2 (Ruta relativa):\n",
    "\n",
    "carpeta_origen = f\"../datasets/\"\n",
    "# print(carpeta_origen)\n",
    "import os # ‚¨ÖÔ∏è Permite trabajar con archivos\n",
    "print(os.listdir(carpeta_origen)) # ‚¨ÖÔ∏è Mostrar los archivos de la carpeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a23575e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso B). DEFINIR EL NOMBRE DEL ARCHIVO DEL DATASET\n",
    "\"\"\"\n",
    "    üìù SINTAXIS:\n",
    "    \n",
    "        nombre_archivo = \"NombreArchivo.extension\"\n",
    "\n",
    "    ### üß† Depender√° de la extensi√≥n del archivo para indicarle a Pandas que funci√≥n utilizar.\n",
    "\"\"\"\n",
    "# üí° EJEMPLO 1 (.csv): \n",
    "archivos_csv = \"penguins.csv\"\n",
    "\n",
    "# üí° EJEMPLO 2 (.xlsx): \n",
    "archivos_xlsx = \"Pedidos.xlsx\"\n",
    "\n",
    "# üí° EJEMPLO 3 (.json): \n",
    "archivos_json = \"eventos_logs.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a32b11c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evento.usuario_id</th>\n",
       "      <th>evento.accion</th>\n",
       "      <th>evento.timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U846</td>\n",
       "      <td>compra</td>\n",
       "      <td>2025-05-25T21:07:47.202219Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U321</td>\n",
       "      <td>registro</td>\n",
       "      <td>2025-05-23T11:50:47.202219Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U813</td>\n",
       "      <td>login</td>\n",
       "      <td>2025-05-25T19:09:47.202219Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U677</td>\n",
       "      <td>registro</td>\n",
       "      <td>2025-05-27T09:41:47.202219Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U425</td>\n",
       "      <td>compra</td>\n",
       "      <td>2025-05-23T14:44:47.202219Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  evento.usuario_id evento.accion             evento.timestamp\n",
       "0              U846        compra  2025-05-25T21:07:47.202219Z\n",
       "1              U321      registro  2025-05-23T11:50:47.202219Z\n",
       "2              U813         login  2025-05-25T19:09:47.202219Z\n",
       "3              U677      registro  2025-05-27T09:41:47.202219Z\n",
       "4              U425        compra  2025-05-23T14:44:47.202219Z"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paso C). LECTURA DE LOS ARCHIVOS (PASO A + PASO B)\n",
    "\"\"\"\n",
    "    ### üß† Para los archivos .csv, se recomienda conocer el separador o\n",
    "    ###     delimitador presente en el archivo e indicarle a Pandas.\n",
    "\n",
    "    üìù SINTAXIS:\n",
    "    \n",
    "        dataset_nombre = pd.read_extensi√≥n(carpeta_origen+nombre_archivo.extensi√≥n)\n",
    "\"\"\"\n",
    "import pandas as pd # ‚úÖ No olvidar importar pandas al inicio del notebook\n",
    "\n",
    "# üí° EJEMPLO 1 (Lectura de .csv): \n",
    "\n",
    "dataset_csv = pd.read_csv(carpeta_origen+archivos_csv,sep=\",\") # ‚¨ÖÔ∏è Indicamos el delimitador en sep.\n",
    "# dataset_csv.head() # ‚¨ÖÔ∏è Funci√≥n que permite leer y retornar los 5 primeros registros del archivo.\n",
    "\"\"\"===============================================================================================\"\"\"\n",
    "# üí° EJEMPLO 2 (Lectura de .xlsx): \n",
    "\n",
    "dataset_excel = pd.read_excel(\n",
    "                 io=carpeta_origen+archivos_xlsx,\n",
    "                 sheet_name=\"Hoja1\") # ‚¨ÖÔ∏è Indicamos el nombre de la Hoja donde se encuentra\n",
    "                                     #     la informaci√≥n.\n",
    "# dataset_excel.head() # ‚¨ÖÔ∏è Funci√≥n que permite leer y retornar los 5 primeros registros del archivo.\n",
    "\n",
    "\"\"\" ‚ö†Ô∏è En caso les arroje error sobre No module named 'openpyxl\n",
    "       solo instalemos el m√≥dulo con: pip install openpyxl\n",
    "'\"\"\"\n",
    "# dataset_excel.head() # ‚¨ÖÔ∏è Funci√≥n que permite leer y retornar los 5 primeros registros del archivo.\n",
    "\"\"\"===============================================================================================\"\"\"\n",
    "# üí° EJEMPLO 3 (Lectura de .json):\n",
    "\n",
    "### Archivo b√°sico JSON\n",
    "archivo_json_basico = \"json_basico.json\" # ‚¨ÖÔ∏è Nombre de archivo b√°sico JSON\n",
    "dataset_json1 = pd.read_json(carpeta_origen+archivo_json_basico) # ‚¨ÖÔ∏è Lectura de JSON b√°sico\n",
    "# dataset_json1.head()\n",
    "\n",
    "### Archivo complejo JSON\n",
    "import json # ‚¨ÖÔ∏è Utilizaremos la librer√≠a json para el aplanamiento del Archivo JSON complejo.\n",
    "archivo_json_complejo = \"eventos_logs.json\" # ‚¨ÖÔ∏è Nombre de archivo complejo JSON\n",
    "with open(carpeta_origen + archivo_json_complejo, \"r\", encoding=\"utf-8\") as file_data:\n",
    "    data_archivo_json_complejo = json.load(file_data)\n",
    "dataset_json2 = pd.json_normalize(data_archivo_json_complejo) # ‚¨ÖÔ∏è Lectura de archivo JSON complejo.\n",
    "dataset_json2.head() # ‚¨ÖÔ∏è Funci√≥n que permite leer y retornar los 5 primeros registros del archivo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f16228",
   "metadata": {},
   "source": [
    "#### 1.5 Fuentes de Datos - Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151d9dff",
   "metadata": {},
   "source": [
    "Antes de continuar con las siguientes fases de manipulaci√≥n de datos, es importante\n",
    "presentar una segunda librer√≠a muy utilizada en el an√°lisis exploratorio y \n",
    "visualizaci√≥n de datos: **Seaborn**. Aunque Seaborn fue dise√±ada principalmente para\n",
    "crear visualizaciones estad√≠sticas, tambi√©n incluye una colecci√≥n de **datasets**,\n",
    "que resultan muy √∫tiles para practicar t√©cnicas de manipulaci√≥n de datos con Pandas.\n",
    "\n",
    "üîß Instalaci√≥n y uso de Seaborn \n",
    "\n",
    "Para utilizar Seaborn en nuestro entorno de trabajo, sigue estos pasos:\n",
    "\n",
    "a) Instalaci√≥n en la terminal (si no la tienes instalada): pip install seaborn\n",
    "\n",
    "b) Importaci√≥n de la librer√≠a: import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a75d4f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949</td>\n",
       "      <td>Jan</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949</td>\n",
       "      <td>Feb</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1949</td>\n",
       "      <td>Mar</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1949</td>\n",
       "      <td>Apr</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1949</td>\n",
       "      <td>May</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year month  passengers\n",
       "0  1949   Jan         112\n",
       "1  1949   Feb         118\n",
       "2  1949   Mar         132\n",
       "3  1949   Apr         129\n",
       "4  1949   May         121"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Mediante su funci√≥n .load_dataset(NombreDelDataset), permite traer datasets almacenados\n",
    "    internamente desntro de Seaborn y autom√°ticamente se convierten en un Dataframe de Pandas.\n",
    "    \n",
    "    üìù SINTAXIS:\n",
    "\n",
    "        dataframe_nombre = sns.load_dataset(NombreDataset) ‚¨ÖÔ∏è Entre comillas podemos instanciar al dataset.\n",
    "        \n",
    "        ### ‚û°Ô∏è Estos son los datasets m√°s utilizados: penguins,titanic, flights, iris, tips, diamonds.\n",
    "        ### ‚û°Ô∏è Si deseas conocer todos los datasets, usa la siguiente funci√≥n: sns.get_dataset_names()\n",
    "\"\"\"\n",
    "import seaborn as sns # ‚¨ÖÔ∏è  Primordial Importar la librer√≠a.\n",
    "# üí° Traer los nombres de todos los datasets de Seaborn:\n",
    "# sns.get_dataset_names() # ‚¨ÖÔ∏è Devuelve una lista con los nombres de todos sus datasets.\n",
    "\n",
    "# üí° Lectura de dataset titanic:\n",
    "df_titanic = sns.load_dataset(\"titanic\")\n",
    "# df_titanic.head()\n",
    "\n",
    "# üí° Lectura de dataset penguins:\n",
    "df_penguins = sns.load_dataset(\"penguins\")\n",
    "df_penguins.head()\n",
    "\n",
    "# üí° Lectura de dataset iris:\n",
    "df_iris = sns.load_dataset(\"iris\")\n",
    "# df_iris.head()\n",
    "\n",
    "# üí° Lectura de dataset flights:\n",
    "df_flights = sns.load_dataset(\"flights\")\n",
    "df_flights.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3001c3c2",
   "metadata": {},
   "source": [
    "#### Fase 2. Exploraci√≥n Inicial üîç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa79a06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    Male  \n",
       "1       3800.0  Female  \n",
       "2       3250.0  Female  \n",
       "3          NaN     NaN  \n",
       "4       3450.0  Female  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Utilizaremos el dataset de penguins (dataset de Seaborn importado en un csv)\n",
    "\"\"\"\n",
    "df_penguins = pd.read_csv(\"../datasets/penguins.csv\",sep=\",\") # ‚¨ÖÔ∏è Accedemos al archivo en la carpeta datasets\n",
    "df_penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b2687a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DetallePedidosPedidoID</th>\n",
       "      <th>PedidoFechaHoraRegistro</th>\n",
       "      <th>PedidoEstado</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-05-26 18:02:01.240</td>\n",
       "      <td>F</td>\n",
       "      <td>524361.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-05-26 18:02:02.430</td>\n",
       "      <td>F</td>\n",
       "      <td>524387.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2025-05-26 18:02:46.287</td>\n",
       "      <td>F</td>\n",
       "      <td>515269.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2025-05-26 18:02:46.290</td>\n",
       "      <td>F</td>\n",
       "      <td>523261.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2025-05-26 18:02:46.290</td>\n",
       "      <td>F</td>\n",
       "      <td>532688.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DetallePedidosPedidoID PedidoFechaHoraRegistro PedidoEstado      Total\n",
       "0                       1 2025-05-26 18:02:01.240            F  524361.11\n",
       "1                       2 2025-05-26 18:02:02.430            F  524387.46\n",
       "2                       3 2025-05-26 18:02:46.287            F  515269.86\n",
       "3                       4 2025-05-26 18:02:46.290            F  523261.27\n",
       "4                       5 2025-05-26 18:02:46.290            F  532688.61"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    A). Quitar encabezados originales provenientes del Dataset.\n",
    "    \n",
    "        üìù SINTAXIS:\n",
    "        \n",
    "            dataset_nombre = pl.read_extension(ruta_carpeta_archivo,sep=\"Delimitador\",header=None|Omitir)\n",
    "            \n",
    "            üí° Importante: header, es el par√°metro que si establecemos en None, los encabezados se vuelven parte\n",
    "                           de los registros del dataset, agregandole la posici√≥n de cada columna como nuevo encabezado.\n",
    "                                        \n",
    "            ### üß† Tener en cuenta que solo se aplicar√° a las extensiones .excel y .csv\n",
    "    \n",
    "#### PARA LOS EJEMPLOS USAREMOS ALGUNOS DATASET PREVIAMENTE VISTOS EN LA FASE 1.\n",
    "\"\"\"\n",
    "\n",
    "# üí° EJEMPLO 1: Archivo CSV \n",
    "\n",
    "df_penguins = pd.read_csv(carpeta_origen+archivos_csv,sep=\",\",header=None) #‚¨ÖÔ∏è Ocultamos los encabezados\n",
    "# df_penguins.head()\n",
    "\n",
    "# üí° EJEMPLO 2: Archivo CSV\n",
    "\n",
    "df_penguins = pd.read_csv(carpeta_origen+archivos_csv,sep=\",\") #‚¨ÖÔ∏è Mostramos los encabezados\n",
    "# df_penguins.head()\n",
    "\n",
    "# # üí° EJEMPLO 3: Archivo EXCEL \n",
    "\n",
    "df_penguins_excel = pd.read_excel(carpeta_origen+archivos_xlsx,sheet_name=\"Hoja1\",header=None) #‚¨ÖÔ∏è Ocultamos los encabezados\n",
    "# df_penguins_excel.head()\n",
    "\n",
    "# # üí° EJEMPLO 4: Archivo EXCEL\n",
    "\n",
    "df_penguins_excel = pd.read_excel(carpeta_origen+archivos_xlsx,sheet_name=\"Hoja1\") #‚¨ÖÔ∏è Mostramos los encabezados\n",
    "df_penguins_excel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28ba0c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>38.9</td>\n",
       "      <td>17.8</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3625.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.2</td>\n",
       "      <td>19.6</td>\n",
       "      <td>195.0</td>\n",
       "      <td>4675.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>34.1</td>\n",
       "      <td>18.1</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3475.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>42.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>190.0</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "5  Adelie  Torgersen            39.3           20.6              190.0   \n",
       "6  Adelie  Torgersen            38.9           17.8              181.0   \n",
       "7  Adelie  Torgersen            39.2           19.6              195.0   \n",
       "8  Adelie  Torgersen            34.1           18.1              193.0   \n",
       "9  Adelie  Torgersen            42.0           20.2              190.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    Male  \n",
       "1       3800.0  Female  \n",
       "2       3250.0  Female  \n",
       "3          NaN     NaN  \n",
       "4       3450.0  Female  \n",
       "5       3650.0    Male  \n",
       "6       3625.0  Female  \n",
       "7       4675.0    Male  \n",
       "8       3475.0     NaN  \n",
       "9       4250.0     NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    B). Mostrar los N primeros registros de un dataset\n",
    "    \n",
    "        üìù SINTAXIS:\n",
    "    \n",
    "            dataset_nombre.head(N√∫meroDeRegistros) ‚¨ÖÔ∏è Indicamos un n√∫mero para la cantidad de registros a mostrar    \n",
    "\"\"\"\n",
    "# üí° EJEMPO 1: \n",
    "\n",
    "# df_penguins.head(5) ## ‚¨ÖÔ∏è Mostrar 5 primeros registros del dataset\n",
    "\n",
    "# üí° EJEMPO 2: \n",
    "\n",
    "df_penguins.head(10) ## ‚¨ÖÔ∏è Mostrar 10 primeros registros del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4eb656d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>46.2</td>\n",
       "      <td>14.1</td>\n",
       "      <td>217.0</td>\n",
       "      <td>4375.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>55.1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>5850.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>44.5</td>\n",
       "      <td>15.7</td>\n",
       "      <td>217.0</td>\n",
       "      <td>4875.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>48.8</td>\n",
       "      <td>16.2</td>\n",
       "      <td>222.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>47.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>214.0</td>\n",
       "      <td>4925.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>46.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4850.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>50.4</td>\n",
       "      <td>15.7</td>\n",
       "      <td>222.0</td>\n",
       "      <td>5750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>45.2</td>\n",
       "      <td>14.8</td>\n",
       "      <td>212.0</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>49.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    species  island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "334  Gentoo  Biscoe            46.2           14.1              217.0   \n",
       "335  Gentoo  Biscoe            55.1           16.0              230.0   \n",
       "336  Gentoo  Biscoe            44.5           15.7              217.0   \n",
       "337  Gentoo  Biscoe            48.8           16.2              222.0   \n",
       "338  Gentoo  Biscoe            47.2           13.7              214.0   \n",
       "339  Gentoo  Biscoe             NaN            NaN                NaN   \n",
       "340  Gentoo  Biscoe            46.8           14.3              215.0   \n",
       "341  Gentoo  Biscoe            50.4           15.7              222.0   \n",
       "342  Gentoo  Biscoe            45.2           14.8              212.0   \n",
       "343  Gentoo  Biscoe            49.9           16.1              213.0   \n",
       "\n",
       "     body_mass_g     sex  \n",
       "334       4375.0  Female  \n",
       "335       5850.0    Male  \n",
       "336       4875.0     NaN  \n",
       "337       6000.0    Male  \n",
       "338       4925.0  Female  \n",
       "339          NaN     NaN  \n",
       "340       4850.0  Female  \n",
       "341       5750.0    Male  \n",
       "342       5200.0  Female  \n",
       "343       5400.0    Male  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    C). Mostrar los N √∫ltimos registros de un dataset\n",
    "    \n",
    "        üìù SINTAXIS:\n",
    "    \n",
    "            dataset_nombre.tail(N√∫meroDeRegistros) ‚¨ÖÔ∏è Indicamos un n√∫mero para la cantidad de registros a mostrar    \n",
    "\"\"\"\n",
    "# üí° EJEMPO 1: \n",
    "\n",
    "# df_penguins.tail(5) ## ‚¨ÖÔ∏è Mostrar 5 √∫ltimos registros del dataset\n",
    "\n",
    "# üí° EJEMPO 2: \n",
    "\n",
    "df_penguins.tail(10) ## ‚¨ÖÔ∏è Mostrar 10 √∫ltimos registros del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8f82b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    D). Mostrar el vol√∫men del dataset (Cantidad de filas y columnas respectivamente) \n",
    "    \n",
    "        üìù SINTAXIS:\n",
    "    \n",
    "            dataset_nombre.shape ‚¨ÖÔ∏è Nos muestra la cantidad de filas y columnas en forma de tupla (,)\n",
    "            \n",
    "            #### üß† Podemos acceder a la cantidad de filas o columnas bas√°ndonos en la posici√≥n\n",
    "                     de los datos que retorna la tupla, gracias a .shape ‚û°Ô∏è 0 = filas y 1 = columnas    \n",
    "\"\"\"\n",
    "# üí° EJEMPO 1: \n",
    "\n",
    "df_penguins.shape ## ‚¨ÖÔ∏è Muestra el vol√∫men de registros del dataset en forma de tupla. (CantidadFilas,CantidadColumnas)\n",
    "\n",
    "# üí° EJEMPO 2: \n",
    "\n",
    "df_penguins.shape[0] ## ‚¨ÖÔ∏è Muestra la cantidad de registros (filas) del dataset\n",
    "\n",
    "# üí° EJEMPO 3: \n",
    "\n",
    "df_penguins.shape[1] ## ‚¨ÖÔ∏è Muestra la cantidad de columnas del dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da038ca",
   "metadata": {},
   "source": [
    "#### Fase 3. Transformaci√≥n de Datos üí±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5b3e71",
   "metadata": {},
   "source": [
    "##### 3.1 Datos Cualitativos üî†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b39ecc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADELIE</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADELIE</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADELIE</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADELIE</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADELIE</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  ADELIE  Torgersen            39.1           18.7              181.0   \n",
       "1  ADELIE  Torgersen            39.5           17.4              186.0   \n",
       "2  ADELIE  Torgersen            40.3           18.0              195.0   \n",
       "3  ADELIE  Torgersen             NaN            NaN                NaN   \n",
       "4  ADELIE  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    Male  \n",
       "1       3800.0  Female  \n",
       "2       3250.0  Female  \n",
       "3          NaN     NaN  \n",
       "4       3450.0  Female  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    A). CONVERTIR A MAY√öSCULAS LOS DATOS CUALITATIVOS DE UNA COLUMNA EN UN DATASET\n",
    "    \n",
    "    üìù SINTAXIS:\n",
    "    \n",
    "        dataset_nombre[NombreColumnaCualitativa].str.upper()\n",
    "    \n",
    "    ### üß† En este caso, debemos almacenar en una variable los cambios a realizar en el dataframe\n",
    "\"\"\"\n",
    "\n",
    "# üí° EJEMPLO:\n",
    "\n",
    "df_penguins[\"species\"] = df_penguins[\"species\"].str.upper() ## ‚¨ÖÔ∏è Convertimos a may√∫sculas los datos de la columna cualitativa \"\"species\"\"\n",
    "df_penguins.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910f332c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    Male  \n",
       "1       3800.0  Female  \n",
       "2       3250.0  Female  \n",
       "3          NaN     NaN  \n",
       "4       3450.0  Female  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    B). CONVERTIR A MIN√öSCULAS LOS DATOS CUALITATIVOS DE UNA COLUMNA EN UN DATASET\n",
    "    \n",
    "    üìù SINTAXIS:\n",
    "    \n",
    "        dataset_nombre[NombreColumnaCualitativa].str.lower()\n",
    "    \n",
    "    ### üß† En este caso, debemos almacenar en una variable los cambios a realizar en el dataframe\n",
    "\"\"\"\n",
    "\n",
    "# üí° EJEMPLO:\n",
    "\n",
    "df_penguins[\"species\"] = df_penguins[\"species\"].str.lower() ## ‚¨ÖÔ∏è Convertimos a min√∫sculas los datos de la columna cualitativa \"\"species\"\"\n",
    "df_penguins.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003e373c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    Male  \n",
       "1       3800.0  Female  \n",
       "2       3250.0  Female  \n",
       "3          NaN     NaN  \n",
       "4       3450.0  Female  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    C). CONVERTIR A MAY√öSCULA LA PRIMERA LETRA DE CADA DATO CUALITATIVOS DE UNA COLUMNA EN UN DATASET\n",
    "    \n",
    "    üìù SINTAXIS:\n",
    "    \n",
    "        dataset_nombre[NombreColumnaCualitativa].str.title()\n",
    "    \n",
    "    ### üß† En este caso, debemos almacenar en una variable los cambios a realizar en el dataframe\n",
    "\"\"\"\n",
    "\n",
    "# üí° EJEMPLO:\n",
    "\n",
    "df_penguins[\"species\"] = df_penguins[\"species\"].str.title() ## ‚¨ÖÔ∏è Convertimos la primera letra en may√∫scula de cada dato en la columna cualitativa \"\"species\"\"\n",
    "df_penguins.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becc7cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>PrimeraLetraEnMay√∫scula</th>\n",
       "      <th>PrimeraLetraEnMin√∫scula</th>\n",
       "      <th>TodasLasLetraEnMay√∫scula</th>\n",
       "      <th>TodaUnaCadenaDespuesDeUnaMay√∫scula</th>\n",
       "      <th>TodoDespuesDeUnaMay√∫scula</th>\n",
       "      <th>TodoDespuesDeUnaMin√∫scula</th>\n",
       "      <th>TodoDespuesDeUnN√∫mero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>A</td>\n",
       "      <td>d</td>\n",
       "      <td>A</td>\n",
       "      <td>delie</td>\n",
       "      <td>delie</td>\n",
       "      <td>elie</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>A</td>\n",
       "      <td>d</td>\n",
       "      <td>A</td>\n",
       "      <td>delie</td>\n",
       "      <td>delie</td>\n",
       "      <td>elie</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>A</td>\n",
       "      <td>d</td>\n",
       "      <td>A</td>\n",
       "      <td>delie</td>\n",
       "      <td>delie</td>\n",
       "      <td>elie</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>d</td>\n",
       "      <td>A</td>\n",
       "      <td>delie</td>\n",
       "      <td>delie</td>\n",
       "      <td>elie</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>A</td>\n",
       "      <td>d</td>\n",
       "      <td>A</td>\n",
       "      <td>delie</td>\n",
       "      <td>delie</td>\n",
       "      <td>elie</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex PrimeraLetraEnMay√∫scula PrimeraLetraEnMin√∫scula  \\\n",
       "0       3750.0    Male                       A                       d   \n",
       "1       3800.0  Female                       A                       d   \n",
       "2       3250.0  Female                       A                       d   \n",
       "3          NaN     NaN                       A                       d   \n",
       "4       3450.0  Female                       A                       d   \n",
       "\n",
       "  TodasLasLetraEnMay√∫scula TodaUnaCadenaDespuesDeUnaMay√∫scula  \\\n",
       "0                        A                              delie   \n",
       "1                        A                              delie   \n",
       "2                        A                              delie   \n",
       "3                        A                              delie   \n",
       "4                        A                              delie   \n",
       "\n",
       "  TodoDespuesDeUnaMay√∫scula TodoDespuesDeUnaMin√∫scula TodoDespuesDeUnN√∫mero  \n",
       "0                     delie                      elie                   NaN  \n",
       "1                     delie                      elie                   NaN  \n",
       "2                     delie                      elie                   NaN  \n",
       "3                     delie                      elie                   NaN  \n",
       "4                     delie                      elie                   NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    D). EXTRAER DE CADA DATO CUALITATIVO UNA CADENA EN ESPEC√çFICO MEDIANTE >>EXPRESIONES REGULARES<< EN UN DATASET\n",
    "    \n",
    "    üìù SINTAXIS:\n",
    "    \n",
    "        dataset_nombre[NombreColumnaCualitativa].str.extract()\n",
    "    \n",
    "    ### üß† En este caso, debemos almacenar en una variable los cambios a realizar en el dataframe\n",
    "\"\"\"\n",
    "##üí° EJEMPLO 1: ‚¨ÖÔ∏è Extraemos primera letra en may√∫scula \n",
    "df_penguins[\"PrimeraLetraEnMay√∫scula\"] = df_penguins[\"species\"].str.extract(r'([A-Z])')\n",
    "# df_penguins.head()\n",
    "\n",
    "##üí° EJEMPLO 2: ‚¨ÖÔ∏è Extraemos primera letra en min√∫scula\n",
    "df_penguins[\"PrimeraLetraEnMin√∫scula\"] = df_penguins[\"species\"].str.extract(r'([a-z])')\n",
    "# df_penguins.head()\n",
    "\n",
    "##üí° EJEMPLO 3: ‚¨ÖÔ∏è Retornamos todo despu√©s de una letra en may√∫scula\n",
    "df_penguins[\"TodoDespuesDeUnaMay√∫scula\"] = df_penguins[\"species\"].str.extract(r'[A-Z](.*)')\n",
    "# df_penguins.head()\n",
    "\n",
    "##üí° EJEMPLO 4: ‚¨ÖÔ∏è Retornamos todo despu√©s de una letra en min√∫scula\n",
    "df_penguins[\"TodoDespuesDeUnaMin√∫scula\"] = df_penguins[\"species\"].str.extract(r'[a-z](.*)')\n",
    "df_penguins.head()\n",
    "\n",
    "##üí° EJEMPLO 5: ‚¨ÖÔ∏è Retornamos todo despu√©s de un n√∫mero\n",
    "df_penguins[\"TodoDespuesDeUnN√∫mero\"] = df_penguins[\"species\"].str.extract(r'[0-9](.*)')\n",
    "df_penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5001aaa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre</th>\n",
       "      <th>categoria_producto</th>\n",
       "      <th>codigo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JUAN p√©rez</td>\n",
       "      <td>ELECTR√ìNICA 1</td>\n",
       "      <td>0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAR√çA L√ìPEZ</td>\n",
       "      <td>ropa Mujer</td>\n",
       "      <td>0023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ana Mart√≠nez</td>\n",
       "      <td>hogar y DECORACI√ìN</td>\n",
       "      <td>1234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>carlos rodr√≠guez</td>\n",
       "      <td>LIBROS</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sof√≠a Garc√≠a</td>\n",
       "      <td>Juguetes ni√±os</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              nombre  categoria_producto codigo\n",
       "0        JUAN p√©rez        ELECTR√ìNICA 1   0001\n",
       "1        MAR√çA L√ìPEZ          ropa Mujer   0023\n",
       "2       Ana Mart√≠nez  hogar y DECORACI√ìN   1234\n",
       "3  carlos rodr√≠guez              LIBROS     123\n",
       "4       Sof√≠a Garc√≠a      Juguetes ni√±os   9999"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    E). REEMPLAZAR VALORES DE DATOS CUALITATIVOS MEDIANTE >>EXPRESIONES REGULARES<< EN UN DATASET\n",
    "    \n",
    "    üìù SINTAXIS:\n",
    "    \n",
    "        dataset_nombre[NombreColumnaCualitativa].str.replace(pat=Patr√≥nExpresi√≥nRegular,repl=CadenaAReemplazar,regex=True)\n",
    "    \n",
    "    ### üß† En este caso, debemos almacenar en una variable los cambios a realizar en el dataframe\n",
    "\"\"\"\n",
    "### DATASET DE PRUEBA PARA ESTE EJEMPLO\n",
    "datos_sucios = {\n",
    "    \"nombre\": [\n",
    "        \"  JUAN  p√©rez  \", \n",
    "        \"MAR√çA@@L√ìPEZ\", \n",
    "        \"Ana--Mart√≠nez\", \n",
    "        \"carlos_rodr√≠guez \", \n",
    "        \"Sof√≠a123 Garc√≠a\"\n",
    "    ],\n",
    "    \"categoria_producto\": [\n",
    "        \"ELECTR√ìNICA#1\", \n",
    "        \"ropa--Mujer\", \n",
    "        \"hogar_y_DECORACI√ìN\", \n",
    "        \"LIBROS@@\", \n",
    "        \"Juguetes  ni√±os\"\n",
    "    ],\n",
    "    \"codigo\": [\n",
    "        \"ID-0001\", \n",
    "        \"ID-0023\", \n",
    "        \"CL-1234\", \n",
    "        \"ID-abc123\", \n",
    "        \"id-9999\"\n",
    "    ]\n",
    "}\n",
    "## Dataset de prueba (sucio)\n",
    "df_test = pd.DataFrame(datos_sucios)\n",
    "# df_test.head()\n",
    "\n",
    "## Dataset de prueba (limpio)\n",
    "df_test_clean = df_test.copy() \n",
    "\n",
    "## üí° EJEMPLO 1: ‚¨ÖÔ∏è Eliminar caract√©res especiales (@@,#,--,_)\n",
    "df_test_clean[\"categoria_producto\"] = df_test_clean[\"categoria_producto\"].str.replace(pat=r'[^A-Za-z0-9√Å√â√ç√ì√ö√°√©√≠√≥√∫√ë√±√ú√º]',repl=' ',regex=True)\n",
    "df_test_clean[\"nombre\"] = df_test_clean[\"nombre\"].str.replace(pat=r'[^A-Za-z√Å√â√ç√ì√ö√°√©√≠√≥√∫√ë√±√ú√º]',repl=' ',regex=True)\n",
    "# df_test_clean.head()\n",
    "\n",
    "## üí° EJEMPLO 2: ‚¨ÖÔ∏è Normalizar espacios (Varios espacios en blanco a uno solo)\n",
    "df_test_clean[\"categoria_producto\"] = df_test_clean[\"categoria_producto\"].str.replace(pat=r'\\s+',repl=' ',regex=True)\n",
    "df_test_clean[\"nombre\"] = df_test_clean[\"nombre\"].str.replace(pat=r'\\s+',repl=' ',regex=True)\n",
    "# df_test_clean.head()\n",
    "\n",
    "## üí° EJEMPLO 3: ‚¨ÖÔ∏è Reemplazar guiones por espacios en blanco\n",
    "df_test_clean[\"nombre\"] = df_test_clean[\"nombre\"].str.replace(pat=r'[-_]',repl=' ',regex=True)\n",
    "# df_test_clean.head()\n",
    "\n",
    "## üí° EJEMPLO 4: ‚¨ÖÔ∏è Eliminar prefijos (ID- || CL- || id- || Letras)\n",
    "df_test_clean[\"codigo\"] = df_test_clean[\"codigo\"].str.replace(pat=r'^ID-',repl='',regex=True)\n",
    "df_test_clean[\"codigo\"] = df_test_clean[\"codigo\"].str.replace(pat=r'^id-',repl='',regex=True)\n",
    "df_test_clean[\"codigo\"] = df_test_clean[\"codigo\"].str.replace(pat=r'^CL-',repl='',regex=True)\n",
    "df_test_clean[\"codigo\"] = df_test_clean[\"codigo\"].str.replace(pat=r'[A-Za-z]',repl='',regex=True)\n",
    "df_test_clean.head()\n",
    "\n",
    "\n",
    "#### üí° EJEMPLO 6: ‚¨ÖÔ∏è Eliminar n√∫mero en caso no necesitemos\n",
    "#### df_test_clean[\"codigo\"] = df_test_clean[\"codigo\"].str.replace(pat=r'([0-9])',repl='',regex=True)\n",
    "#### df_test_clean.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42104f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    F). ELIMINAR VALORES DUPLICADOS EN DATOS CUALITATIVOS DE UN DATASET\n",
    "    \n",
    "    üìù SINTAXIS:\n",
    "    \n",
    "        dataset_nombre.drop_duplicates(subset=[NombreColumna1,NombreColumnaN],keep=\"first\" | \"last\",inplace=True | False)\n",
    "        \n",
    "        keep: Es el par√°metro que establece el valor que va a quedar de todos los duplicados (Primer valor=first - √öltimo valor=last)\n",
    "              [En caso de no llamar al par√°metro keep, se establece \"first\".]\n",
    "        \n",
    "    ### üß† En este caso, debemos trabajar sobre el mismo dataset/dataframe para eliminar los duplicados.\n",
    "\"\"\"\n",
    "### ‚úÖüóÉÔ∏è Dataset a utilizar: Diamonds\n",
    "## ---- Importamos Seaborn\n",
    "import seaborn as sns \n",
    "df_diamonds = sns.load_dataset(\"diamonds\")\n",
    "# df_diamonds.head()\n",
    "# df_diamonds.shape[0] ## ‚¨ÖÔ∏è Cantidad de datos inicial: 53940\n",
    "\n",
    "## üí° EJEMPLO 1: ELIMINAR VALORES DUPLICADOS DE TODO EL DATASET (keep=\"first\" por defecto)\n",
    "# df_diamonds.drop_duplicates(inplace=True) \n",
    "# df_diamonds.shape[0] ## ‚¨ÖÔ∏è Cantidad de datos restantes: 53794\n",
    "\n",
    "# üí° EJEMPLO 2: ELIMINAR VALORES DUPLICADOS DE TODO EL DATASET (keep=\"last\")\n",
    "# df_diamonds.drop_duplicates(inplace=True,keep=\"last\") \n",
    "# df_diamonds.shape[0] ## ‚¨ÖÔ∏è Cantidad de datos restantes: 53794\n",
    "\n",
    "# üí° EJEMPLO 3: ELIMINAR VALORES DUPLICADOS DE UNA COLUMNA ESPEC√çFICA (keep=\"first\" por defecto)\n",
    "# df_diamonds[\"carat\"].shape[0] ## ‚¨ÖÔ∏è Cantidad inicial de datos: 53940\n",
    "# df_diamonds.drop_duplicates(subset=[\"carat\"],inplace=True,keep=\"first\") \n",
    "# df_diamonds[\"carat\"].shape[0] ## ‚¨ÖÔ∏è Cantidad de datos restantes: 273   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70730690",
   "metadata": {},
   "source": [
    "##### 3.2 Datos Cuantitativos üî¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "516a9d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    Male  \n",
       "1       3800.0  Female  \n",
       "2       3250.0  Female  \n",
       "3          NaN     NaN  \n",
       "4       3450.0  Female  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns  ##üí° Utilizaremos la librer√≠a Seaborn para obtener datasets de prueba.\n",
    "\n",
    "df_penguins = sns.load_dataset(\"penguins\") ## ‚¨ÖÔ∏è Para este ejemplo utilizaremos el dataset de \"\"\"penguins\"\"\"\n",
    "df_penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4b77ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body_mass_g    643131.077327\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    A). EXPLORACI√ìN B√ÅSICA Y RESUMEN ESTAD√çSTICO\n",
    "        \n",
    "        üìù Para los datos cuantitativos podemos obtener su estad√≠stica b√°sica\n",
    "            mediante .decribe() el cu√°l retornar√° el valor de las columnas float o int.\n",
    "\"\"\"\n",
    "df_penguins.describe()                  ## ‚¨ÖÔ∏è Estad√≠stica simple - Todas las columnas (int/float)\n",
    "df_penguins[[\"body_mass_g\"]].describe() ## ‚¨ÖÔ∏è Estad√≠stica simple - Columna body_mass_g\n",
    "df_penguins[[\"body_mass_g\"]].mean()     ## ‚¨ÖÔ∏è Media estad√≠stica - Columna body_mass_g\n",
    "df_penguins[[\"body_mass_g\"]].median()   ## ‚¨ÖÔ∏è Mediana estad√≠stica - Columna body_mass_g\n",
    "df_penguins[[\"body_mass_g\"]].min()      ## ‚¨ÖÔ∏è Valor m√≠nimo - Columna body_mass_g\n",
    "df_penguins[[\"body_mass_g\"]].max()      ## ‚¨ÖÔ∏è Valor m√°ximo - Columna body_mass_g\n",
    "df_penguins[[\"body_mass_g\"]].sum()      ## ‚¨ÖÔ∏è Suma total - Columna body_mass_g\n",
    "df_penguins[[\"body_mass_g\"]].std()      ## ‚¨ÖÔ∏è Desviaci√≥n est√°ndar - Columna body_mass_g\n",
    "df_penguins[[\"body_mass_g\"]].var()      ## ‚¨ÖÔ∏è Varianza - Columna body_mass_g\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70551e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    B). VERIFICAR VALORES NULOS EN LA(S) COLUMNA(AS) DEL DATASET\n",
    "        \n",
    "        üóíÔ∏èSINTAXIS:\n",
    "    \n",
    "        dataset_nombre.isnull().sum() ‚¨ÖÔ∏è Para todo el dataset.\n",
    "        dataset_nombre[NombreColumna].isnull().sum() ‚¨ÖÔ∏è A nivel de columna\n",
    "\"\"\"\n",
    "\n",
    "## üí° EJEMPLO 1: VERIFICAR CANTIDAD DE VALORES NULOS EN TODAS LAS COLUMNAS DEL DATASET\n",
    "df_penguins.isnull().sum() ##‚¨ÖÔ∏è Retornar√° una serie de Pandas.\n",
    "\n",
    "## üí° EJEMPLO 2: VERIFICAR CANTIDAD DE VALORES NULOS EN UNA COLUMNA ESPEC√çFICA DEL DATASET\n",
    "df_penguins[\"body_mass_g\"].isnull().sum() ##‚¨ÖÔ∏è Retornar√° la cantidad de datos nulos de una columna.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b91c9c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    C). FILTRANDO VALORES EN COLUMNAS CUANTITATIVAS\n",
    "\"\"\"\n",
    "\n",
    "# df_penguins.shape[0] ## ‚¨ÖÔ∏è Cantidad de datos del dataset : 344\n",
    "\n",
    "## üí° EJEMPLO 1: FILTRAR VALORES DE COLUMNA \"body_mass_g\" MAYOR A 3000\n",
    "df_penguins_bmg_mayor_3000 = df_penguins.query('body_mass_g>3000')\n",
    "# df_penguins_bmg_mayor_3000.head()\n",
    "df_penguins_bmg_mayor_3000.shape[0] ## ‚¨ÖÔ∏è Cantidad de datos resultantes : 331\n",
    "\n",
    "## üí° EJEMPLO 2: FILTRAR VALORES DE COLUMNA \"body_mass_g\" ENTRE 1000 y 3000\n",
    "df_penguins_bmg_entre_1000_3000 = df_penguins.query('body_mass_g>=1000 & body_mass_g<=3000')\n",
    "# df_penguins_bmg_entre_1000_3000.head()\n",
    "df_penguins_bmg_entre_1000_3000.shape[0] ## ‚¨ÖÔ∏è Cantidad de datos resultantes : 11\n",
    "\n",
    "## üí° EJEMPLO 3: FILTRAR VALORES NULOS EN COLUMNA \"body_mass_g\"\n",
    "df_penguins_nulos_body_mass_g = df_penguins[(df_penguins[\"body_mass_g\"].isnull())]\n",
    "# df_penguins_nulos_body_mass_g.head()\n",
    "# df_penguins_nulos_body_mass_g.shape[0] ## ‚¨ÖÔ∏è Cantidad de datos resultantes : 2\n",
    "\n",
    "## üí° EJEMPLO 4: FILTRAR VALORES NO NULOS EN COLUMNA \"body_mass_g\"\n",
    "df_penguins_no_nulos_body_mass_g = df_penguins[(df_penguins[\"body_mass_g\"].notnull())]\n",
    "# df_penguins_no_nulos_body_mass_g.head()\n",
    "df_penguins_no_nulos_body_mass_g.shape[0] ## ‚¨ÖÔ∏è Cantidad de datos resultantes : 342\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2ac1964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species              0\n",
       "island               0\n",
       "bill_length_mm       0\n",
       "bill_depth_mm        0\n",
       "flipper_length_mm    0\n",
       "body_mass_g          0\n",
       "sex                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    D). RELLENANDO DATOS Null Y NaN DE LAS COLUMNAS DE UN DATASET\n",
    "    \n",
    "        ### üß†EXISTE UNA SIMILITUDAD ENTRE DATOS NaN Y Null DEBIDO QUE AMBOS SON\n",
    "               TRATADOS COMO VALORES FALTANTES INTERNAMENTE POR PANDAS Y SON CONSIDERADOS\n",
    "               EQUIVALENTES A EFECTOS DE AN√ÅLISIS Y LIMPIEZA.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"======================================================================================\n",
    "    üìù RELLENANDO DATOS Null Y NaN\n",
    "\n",
    "        üóíÔ∏èSINTAXIS:\n",
    "        \n",
    "            dataset_nombre.fillna(value={NombreColumna:ValorARellenar},inplace=True||False,axis=0) ‚¨ÖÔ∏è A nivel de columna\n",
    "            dataset_nombre.fillna(value=ValorARellenar,inplace=True||False,axis=0) ‚¨ÖÔ∏è Para todo el dataset.\n",
    "            \n",
    "            ### üß† Tengamos en cuenta que debemos almacenar estos cambios en una nueva variable.\n",
    "\"\"\"\n",
    "## üí° EJEMPLO 1: LLENADO TODOS LOS DATOS NULOS DE UNA COLUMNA EN ESPEC√çFICO\n",
    "# df_penguins.fillna(value={\"body_mass_g\":0},inplace=True,axis=0) ## ‚¨ÖÔ∏è Rellenaremos con Cero.\n",
    "# df_penguins[\"body_mass_g\"].isnull().sum() ## ‚úÖ Datos nulos reemplazados\n",
    "\n",
    "## üí° EJEMPLO 2: LLENADO TODOS LOS DATOS NULOS DEL DATASET COMPLETO.\n",
    "df_penguins.fillna(value=0,inplace=True,axis=0) ## ‚¨ÖÔ∏è Rellenaremos con Cero.\n",
    "df_penguins.isnull().sum() ## ‚úÖ Datos nulos reemplazados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8567d27",
   "metadata": {},
   "source": [
    "#### Fase 4. Agrupamiento de Datos ‚ôæÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea888a5",
   "metadata": {},
   "source": [
    "\"\"\"El agrupamiento de la informaci√≥n nos brinda el resumen de la informaci√≥n proveniente \n",
    "de un dataset, logrando econtrar ciertos patrones en cada grupo de informaci√≥n.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eeb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "üìù SINTAXIS:\n",
    "\n",
    "dataset_nombre_agrupado = \n",
    "    dataset_nombre.groupby(by=[\"NombreColumna1\",\"NombreColumnaN],as_index=False,observed=True)[\"NombreColumnaAgregada\"]\n",
    "                  .funcionAgregada().rename({\"nombre_columna_generada_de_agrupacion\":\"nuevo_nombre_columna\"},axis=1)\n",
    "                  .reset_index(level=0,drop=True)\n",
    "    \n",
    "    - as_index=False: Mantiene las columnas agrupadas como columnas normales, no como √≠ndice.\n",
    "    - observed=True: En columnas categ√≥ricas, solo agrupa por combinaciones observadas y evita advertencias.\n",
    "    - .reset_index(level=0, drop=True): Elimina el √≠ndice de nivel 0 sin agregarlo como columna;\n",
    "                                        √∫til para limpiar la estructura despu√©s de agrupar o pivotear.\n",
    "\n",
    "       \n",
    "    ### üß† En este caso, debemos almacenar en una variable los cambios a realizar en el dataframe.\n",
    "\n",
    "‚ùé En el agrupamiento de informaci√≥n, podemos utilizar diversas funciones de agregaci√≥n, tales como:\n",
    "\n",
    "üí°.min():    ‚¨ÖÔ∏è Permite obtener el m√≠nimo valor de la informaci√≥n agrupada.\n",
    "üí°.max():    ‚¨ÖÔ∏è Permite obtener el m√°ximo valor de la informaci√≥n agrupada.\n",
    "üí°.sum():    ‚¨ÖÔ∏è Permite sumar la informaci√≥n de una columna cuantitativa por la informaci√≥n agrupada.\n",
    "üí°.count():  ‚¨ÖÔ∏è Permite contar la cantidad de informaci√≥n de una columna por la informaci√≥n agrupada.\n",
    "üí°.mean():   ‚¨ÖÔ∏è Permite obtener la media de una columna cuantitativa por la informaci√≥n agrupada.\n",
    "üí°.median(): ‚¨ÖÔ∏è Permite obtener la mediana de una columna cuantitativa por la informaci√≥n agrupada.\n",
    "\"\"\"\n",
    "###‚úîÔ∏è Usaremos el dataset de \"penguins\"\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "df_penguins = sns.load_dataset(\"penguins\") \n",
    "# df_penguins.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af0133a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>cantidad_species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chinstrap</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     species  cantidad_species\n",
       "0     Adelie               152\n",
       "1  Chinstrap                68\n",
       "2     Gentoo               124"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## üí° EJEMPLO 1: (AGRUPANDO POR UNA COLUMNA) \n",
    "df_agrupado_uno = df_penguins.groupby(by=[\"species\"],as_index=False,observed=True)[\"body_mass_g\"].mean().rename({\"body_mass_g\":\"avg_body_mass_g\"},axis=1)\n",
    "# df_agrupado_uno.head()\n",
    "\n",
    "## üí° EJEMPLO 2: (AGRUPAR POR DOS COLUMNAS)\n",
    "df_agrupado_dos = df_penguins.groupby(by=[\"species\",\"sex\"],as_index=False,observed=True)[\"body_mass_g\"].mean().rename({\"body_mass_g\":\"avg_body_mass_g\"},axis=1)\n",
    "# df_agrupado_dos.head()\n",
    "\n",
    "## üí° EJEMPLO 3: (AGRUPAR LA INFORMACI√ìN POR LA CANTIDAD DE LA MISMA COLUMNA)\n",
    "df_agrupado_tres = df_penguins.groupby(by=[\"species\"],as_index=False,observed=True).size().rename({\"size\":\"cantidad_species\"},axis=1).reset_index(level=0,drop=True)\n",
    "df_agrupado_tres.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5a3ee8",
   "metadata": {},
   "source": [
    "##### Fase 4.1 C√°lculos M√≥viles en Pandas üêºüíπ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77f19f6",
   "metadata": {},
   "source": [
    "As√≠ como SQL SERVER permite realizar c√°lculos m√≥viles basados en funciones de agregaci√≥n\n",
    "(min,max,mean,entre otros), Pandas lo realiza mediante la funci√≥n .rolling() entre una N cantidad de\n",
    "filas hacia atr√°s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b76216f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    üìù SINTAXIS: \n",
    "        \n",
    "        1Ô∏è‚É£ C√°lculo M√≥vil sin Particionamiento: Permite el c√°lculo m√≥vil de una columna que no es afectada por otra(s).\n",
    "        \n",
    "        dataset_nombre[NuevaColumnaMovil] = dataset_nombre[NombreColumnaCalcular]\n",
    "                                            .rolling(window=CantidadFilasAcumulacion,\n",
    "                                                     min_periods=CantidadMinimaFilasAcumulacion)\n",
    "                                            .funcionAgregacion(sum,mean,count,median,etc)\n",
    "                                            \n",
    "        2Ô∏è‚É£ C√°lculo M√≥vil con Particionamiento: Permite el c√°lculo m√≥vil por columnas en espec√≠fico.\n",
    "        \n",
    "        dataset_nombre[NuevaColumnaMovil] = dataset_nombre.group_by(Columna1Particionar,ColumnaNParticionar)\n",
    "                                            [NombreColumnaCalcular].rolling(window=CantidadFilasAcumulacion,\n",
    "                                            min_periods=CantidadMinimaFilasAcumulacion)\n",
    "                                            .funcionAgregacion(sum,mean,count,median,etc)\n",
    "                                            .reset_index(drop=True,level=0)\n",
    "\n",
    "        üí° Importante: El par√°metro min_periods permitir√° que el c√°lculo m√≥vil sea de una m√≠nima \n",
    "                       cantidad de periodos para evitar valores NaN. Adem√°s, los par√°metros as_index y observed\n",
    "                       que se colocaban en el group_by() ya no ser√°n necesarios, sin embargo, debemos establecer\n",
    "                       .reset_index(drop=True,level=0) para que los indices coincidan y se pueda asignar \n",
    "                       el resultado de vuelta al Dataframe original.                                            \n",
    "\n",
    "        ### üß† Cuando realizamos el c√°lculo m√≥vil a una columna, Pandas siempre incluir√° la fila actual.\n",
    "\"\"\"\n",
    "### üíπ USAREMOS EL SIGUIENTE DATASET DE EJEMPLO (FORMATO .json):\n",
    "import json\n",
    "with open(\"../datasets/ventas.json\",\"r\") as file:\n",
    "    data_json = json.load(file)\n",
    "df_ventas = pd.DataFrame(data=data_json[\"ventas\"])\n",
    "# df_ventas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc6ce05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nro_venta</th>\n",
       "      <th>fecha</th>\n",
       "      <th>cliente</th>\n",
       "      <th>total</th>\n",
       "      <th>valor_minimo_3_dias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>Cliente_10</td>\n",
       "      <td>350.25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>2024-02-15</td>\n",
       "      <td>Cliente_3</td>\n",
       "      <td>410.50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>2024-03-08</td>\n",
       "      <td>Cliente_7</td>\n",
       "      <td>120.75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>2024-04-20</td>\n",
       "      <td>Cliente_1</td>\n",
       "      <td>250.00</td>\n",
       "      <td>120.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>2024-05-11</td>\n",
       "      <td>Cliente_10</td>\n",
       "      <td>300.90</td>\n",
       "      <td>120.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nro_venta       fecha     cliente   total  valor_minimo_3_dias\n",
       "0       1001  2024-01-22  Cliente_10  350.25                  NaN\n",
       "1       1002  2024-02-15   Cliente_3  410.50                  NaN\n",
       "2       1003  2024-03-08   Cliente_7  120.75                  NaN\n",
       "3       1004  2024-04-20   Cliente_1  250.00               120.75\n",
       "4       1005  2024-05-11  Cliente_10  300.90               120.75"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### üí° EJEMPLO 1: C√ÅLCULO M√ìVIL ‚û°Ô∏è VENTAS ACUMULATIVAS (SUMA ACUMULADA SIN PARTICIONES)\n",
    "df_ventas_acumuladas = df_ventas.copy()\n",
    "df_ventas_acumuladas[\"ventas_acumuladas\"] = df_ventas_acumuladas[\"total\"].cumsum() ##‚¨ÖÔ∏è Usamos .cumsum() \n",
    "# df_ventas_acumuladas.tail()\n",
    "\n",
    "### üí° EJEMPLO 2: C√ÅLCULO M√ìVIL ‚û°Ô∏è VENTAS ACUMULATIVAS (SUMA ACUMULADA CADA 3 DIAS) (‚úÖ INCLUYE FILA ACTUAL)\n",
    "df_ventas_acumuladas_3_dias = df_ventas.copy()\n",
    "df_ventas_acumuladas_3_dias[\"ventas_acumuladas\"] = df_ventas_acumuladas_3_dias[\"total\"].rolling(window=3).sum() ## ‚¨ÖÔ∏è.rolling()\n",
    "####üí° Los Valores NaN no permiten realizar sumatorias por 1 o 2 valores, deben ser 3 (‚úÖ Incluye la fiLa actual - ‚ùåNo particionamos).\n",
    "# df_ventas_acumuladas_3_dias.head(6) \n",
    "\n",
    "### üí° EJEMPLO 3: C√ÅLCULO M√ìVIL ‚û°Ô∏è VENTAS ACUMULATIVAS (SUMA ACUMULADA CADA 3 DIAS) ‚úÖ (‚ùå NO INCLUYE FILA ACTUAL)\n",
    "df_ventas_acumuladas_3_dias_sin_fila_actual = df_ventas.copy()\n",
    "df_ventas_acumuladas_3_dias_sin_fila_actual[\"ventas_acumuladas\"] = df_ventas_acumuladas_3_dias_sin_fila_actual[\"total\"].shift(1).rolling(\n",
    "                                                                   window=3).sum() ## ‚¨ÖÔ∏è.rolling()\n",
    "####üí° Los Valores NaN no permiten realizar sumatorias por 1 o 2 valores, deben ser 3 (‚ùå No incluye la fiLa actual - ‚ùåNo particionamos).\n",
    "# df_ventas_acumuladas_3_dias_sin_fila_actual.head(7) \n",
    "\n",
    "### üí° EJEMPLO 4: C√ÅLCULO M√ìVIL ‚û°Ô∏è VENTAS ACUMULATIVAS (SUMA ACUMULADA CON PARTICIONES)\n",
    "df_ventas_acumuladas_particiones = df_ventas.sort_values(by=\"cliente\").copy() ## ‚¨ÖÔ∏è Ordenamos antes de particionar\n",
    "# df_ventas_acumuladas_particiones.head()\n",
    "df_ventas_acumuladas_particiones[\"ventas_acumuladas\"] = df_ventas_acumuladas_particiones.groupby(\"cliente\")[\"total\"].cumsum() \n",
    "# df_ventas_acumuladas_particiones.head() ## ‚úÖ .group_by() permite el particionamiento y reinicia el acumulado por cada cliente.\n",
    "\n",
    "#=======================================================================================================================================\n",
    "\n",
    "### üí° EJEMPLO 5: C√ÅLCULO M√ìVIL ‚û°Ô∏è PROMEDIO M√ìVIL (PROMEDIO CADA 3 D√çAS) (‚úÖ INCLUYE FILA ACTUAL)\n",
    "df_ventas_promedio_3_dias = df_ventas.copy() \n",
    "# df_ventas_promedio_3_dias.head()\n",
    "df_ventas_promedio_3_dias[\"promedio_ventas_3_dias\"] = df_ventas_promedio_3_dias[\"total\"].rolling(\n",
    "                                                      window=3).mean().reset_index(drop=True,level=0)\n",
    "####üí° Los Valores NaN no permiten calcular el promedio por 1 o 2 valores, deben ser 3 (‚úÖ Incluye la fiLa actual - ‚ùåNo particionamos).\n",
    "# df_ventas_promedio_3_dias.head()\n",
    "\n",
    "\n",
    "### üí° EJEMPLO 6: C√ÅLCULO M√ìVIL ‚û°Ô∏è PROMEDIO M√ìVIL (PROMEDIO CADA 3 D√çAS) (‚ùå NO INCLUYE FILA ACTUAL)\n",
    "df_ventas_promedio_3_dias_sin_fila_actual = df_ventas.copy()\n",
    "# df_ventas_promedio_3_dias_sin_fila_actual.head()\n",
    "df_ventas_promedio_3_dias_sin_fila_actual[\"promedio_ventas_3_dias\"] = df_ventas_promedio_3_dias_sin_fila_actual[\"total\"].shift(1).rolling(\n",
    "                                                      window=3).mean().reset_index(drop=True,level=0)\n",
    "####üí° Los Valores NaN no permiten calcular el promedio por 1 o 2 valores, deben ser 3 (‚ùå No incluye la fiLa actual - ‚ùåNo particionamos).\n",
    "# df_ventas_promedio_3_dias_sin_fila_actual.head()\n",
    "\n",
    "\n",
    "#=======================================================================================================================================\n",
    "\n",
    "### üí° EJEMPLO 7: C√ÅLCULO M√ìVIL ‚û°Ô∏è M√ÅXIMO M√ìVIL (VALOR M√ÅXIMO CADA 3 D√çAS) (‚úÖ INCLUYE FILA ACTUAL)\n",
    "df_ventas_maximo_3_dias = df_ventas.copy() \n",
    "# df_ventas_maximo_3_dias.head()\n",
    "df_ventas_maximo_3_dias[\"valor_maximo_3_dias\"] = df_ventas_maximo_3_dias[\"total\"].rolling(\n",
    "                                                      window=3).max().reset_index(drop=True,level=0)\n",
    "####üí° Los Valores NaN no permiten calcular el promedio por 1 o 2 valores, deben ser 3 (‚úÖ Incluye la fiLa actual - ‚ùåNo particionamos).\n",
    "# df_ventas_maximo_3_dias.head()\n",
    "\n",
    "### üí° EJEMPLO 8: C√ÅLCULO M√ìVIL ‚û°Ô∏è M√ÅXIMO M√ìVIL (VALOR M√ÅXIMO CADA 3 D√çAS) (‚ùå NO INCLUYE FILA ACTUAL)\n",
    "df_ventas_maximo_3_dias_sin_fila_actual = df_ventas.copy()\n",
    "# df_ventas_maximo_3_dias_sin_fila_actual.head()\n",
    "df_ventas_maximo_3_dias_sin_fila_actual[\"valor_maximo_3_dias\"] = df_ventas_maximo_3_dias_sin_fila_actual[\"total\"].shift(1).rolling(\n",
    "                                                      window=3).max().reset_index(drop=True,level=0)\n",
    "####üí° Los Valores NaN no permiten calcular el promedio por 1 o 2 valores, deben ser 3 (‚ùå No incluye la fiLa actual - ‚ùåNo particionamos).\n",
    "df_ventas_maximo_3_dias_sin_fila_actual.head()\n",
    "\n",
    "#=======================================================================================================================================\n",
    "\n",
    "### üí° EJEMPLO 9: C√ÅLCULO M√ìVIL ‚û°Ô∏è M√çNIMO M√ìVIL (VALOR M√çNIMO CADA 3 D√çAS) (‚úÖ INCLUYE FILA ACTUAL)\n",
    "df_ventas_minimo_3_dias = df_ventas.copy() \n",
    "# df_ventas_minimo_3_dias.head()\n",
    "df_ventas_minimo_3_dias[\"valor_minimo_3_dias\"] = df_ventas_minimo_3_dias[\"total\"].rolling(\n",
    "                                                      window=3).min().reset_index(drop=True,level=0)\n",
    "####üí° Los Valores NaN no permiten calcular el promedio por 1 o 2 valores, deben ser 3 (‚úÖ Incluye la fiLa actual - ‚ùåNo particionamos).\n",
    "# df_ventas_minimo_3_dias.head()\n",
    "\n",
    "### üí° EJEMPLO 10: C√ÅLCULO M√ìVIL ‚û°Ô∏è M√çNIMO M√ìVIL (VALOR M√çNIMO CADA 3 D√çAS) (‚ùå NO INCLUYE FILA ACTUAL)\n",
    "df_ventas_minimo_3_dias_sin_fila_actual = df_ventas.copy()\n",
    "# df_ventas_minimo_3_dias_sin_fila_actual.head()\n",
    "df_ventas_minimo_3_dias_sin_fila_actual[\"valor_minimo_3_dias\"] = df_ventas_minimo_3_dias_sin_fila_actual[\"total\"].shift(1).rolling(\n",
    "                                                      window=3).min().reset_index(drop=True,level=0)\n",
    "####üí° Los Valores NaN no permiten calcular el promedio por 1 o 2 valores, deben ser 3 (‚ùå No incluye la fiLa actual - ‚ùåNo particionamos).\n",
    "df_ventas_minimo_3_dias_sin_fila_actual.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c26b64b",
   "metadata": {},
   "source": [
    "##### Fase 4.2 Pivot Tables en Pandas üêºüíπ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee10451",
   "metadata": {},
   "source": [
    "Las Pivot Table permiten transformar filas de un dataset/dataframe en columnas de un nuevo dataset/dataframe,\n",
    "permitiendo un an√°lisis m√°s detallado sobre un grupo espec√≠fico de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62af067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>27.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>30.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          age\n",
       "sex          \n",
       "female  27.92\n",
       "male    30.73"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "    Pandas permite el pivoteo de informaci√≥n a trav√©s de 2 fomas:\n",
    "    \n",
    "    - pivot: Funci√≥n que permite el pivoteo de datos de un dataset/dataframe\n",
    "             sin embargo, limita los requerimientos espec√≠ficos en los datos\n",
    "             (No permite duplicados y no trabaja con funciones de agregaci√≥n)\n",
    "      \n",
    "      üìù SINTAXIS:\n",
    "          dataset_pivoteado_nombre = dataset_original_nombre.pivot(index=NombreColumnaDataframe,columns=NombreColumnaDataframe,\n",
    "                                     values=NombreColumnaDataframe) ‚¨ÖÔ∏è No es recomendado el uso de pivot ‚ùå!!       \n",
    "             \n",
    "    - pivot_table: Funci√≥n m√°s potente y flexible que .pivot(), debido que permite trabajar con \n",
    "                   duplicados y sobretodo con funciones de agregaci√≥n.\n",
    "      üìù SINTAXIS:\n",
    "          dataset_pivoteado_nombre = dataset_original_nombre.pivot_table(index=NombreColumnaDataframe,columns=NombreColumnaDataframe,\n",
    "                                     values=NombreColumnaDataframe,,aggfunc=NombreFunci√≥nAgregaci√≥n,\n",
    "                                     margins=True|False, margins_name=NombreColumnaFilaTotal) ‚¨ÖÔ∏è Es recomendado su uso ‚úÖ.  \n",
    "\n",
    "\"\"\"\n",
    "### ‚úÖüóÉÔ∏è Dataset a utilizar: titanic\n",
    "## ---- Importamos Seaborn\n",
    "import seaborn as sns \n",
    "df_titanic = sns.load_dataset(\"titanic\")\n",
    "# df_titanic.head()\n",
    "\n",
    "#### üí° EJEMPLO 1: USANDO PIVOT (HALLAR EL PROMEDIO DE EDAD POR CLASE Y G√âNERO)\n",
    "## df_pivot_uno = df_titanic.pivot(index=\"pclass\",columns=\"sex\",values=\"age\")\n",
    "## df_pivot_uno.head() ##  ‚ùåError: ValueError: Index contains duplicate entries, cannot reshape\n",
    "\n",
    "#### üí° EJEMPLO 2: USANDO PIVOT_TABLE (HALLAR EL PROMEDIO DE EDAD POR CLASE Y G√âNERO)\n",
    "df_pivot_dos = df_titanic.pivot_table(index=\"pclass\",columns=\"sex\",values=\"age\",aggfunc=\"mean\").round(2)\n",
    "df_pivot_dos.head() ##  ‚úÖ Resultado exitoso.\n",
    "\n",
    "#### üí° EJEMPLO 3: USANDO PIVOT_TABLE (HALLAR EL PROMEDIO DE FARE POR CLASE Y SEXO, \n",
    "####                                   ADEM√ÅS AGREGAR UN TOTAL A NIVEL DE FILA Y COLUMNA CALCULANDO EL PROMEDIO)\n",
    "df_pivot_tres = df_titanic.pivot_table(index=\"pclass\",columns=\"sex\",values=\"fare\",aggfunc=\"mean\",margins=True,margins_name=\"Total\").round(2)\n",
    "## üí° Cuando usamos el par√°metro margins, permite agregar una columna y fila adicional para realizar un c√°lculo a nivel de fila y columna\n",
    "df_pivot_tres.head()\n",
    "\n",
    "#### üí° EJEMPLO 4: USANDO PIVOT_TABLE (HALLAR EL PROMEDIO DE EDAD POR G√âNERO) [PIVOT A NIVEL DE FILA, USANDO SOLO \"columns\"]\n",
    "df_pivot_cuatro = df_titanic.pivot_table(columns=\"sex\",values=\"age\",aggfunc=\"mean\").round(2)\n",
    "df_pivot_cuatro.head() ##  ‚úÖ Resultado exitoso.\n",
    "\n",
    "#### üí° EJEMPLO 5: USANDO PIVOT_TABLE (HALLAR EL PROMEDIO DE EDAD POR G√âNERO) [PIVOT A NIVEL DE FILA, USANDO SOLO \"index\"]\n",
    "df_pivot_cinco = df_titanic.pivot_table(index=\"sex\",values=\"age\",aggfunc=\"mean\").round(2)\n",
    "df_pivot_cinco.head() ##  ‚úÖ Resultado exitoso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5200557e",
   "metadata": {},
   "source": [
    "##### Fase 4.2 UnPivot Tables en Pandas üêºüíπ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360b35f9",
   "metadata": {},
   "source": [
    "Los UnPivot Tables permiten transformar columnas de un dataset/dataframe en filas de un nuevo dataset/dataframe,\n",
    "permitiendo reestablecer el estado del dataframe al original, sin embargo:\n",
    "**LA FUNCI√ìN DE AGREGACI√ìN UTILIZADA EN PIVOT NO REGRESA A SU FORMA NORMAL LOS DATOS, ES DECIR, SE MANTIENE EL C√ÅLCULO DE LA FUNCI√ìN DE AGREGACI√ìN**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aedee3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex     female   male\n",
      "pclass               \n",
      "1        34.61  41.28\n",
      "2        28.72  30.74\n",
      "3        21.75  26.51\n",
      "   pclass     sex    age\n",
      "0       1  female  34.61\n",
      "1       2  female  28.72\n",
      "2       3  female  21.75\n",
      "3       1    male  41.28\n",
      "4       2    male  30.74\n",
      "5       3    male  26.51\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "      üìù SINTAXIS:\n",
    "          dataframe_unpivoteado_nombre = pd.melt(frame=NombreDataframe,id_vars=[NombreColumnaIndice],value_vars=[Valor1Pivoteado,ValorNPivoteado],\n",
    "                                         var_name=NombreColumnaValoresPivoteados,value_name=NombreColumnaValorFuncionAgregacionPivoteado)\n",
    "          frame: Nombre del Dataset/Dataframe pivoteado previamente.\n",
    "          id_vars: Nombre de la columna del dataset/dataframe pivoteado que se estaleci√≥ como *index*\n",
    "          value_vars: Nombre de cada valor establecido como columna en el dataset/dataframe pivoteado\n",
    "          var_name: Nombre de la columna que ser√° utilizada como parte de los valores pivoteados.\n",
    "          value_name: Nombre de la columna el dataset/dataframe pivoteado que es utlizada por la funci√≥n de agregaci√≥n.       \n",
    "\n",
    "\"\"\"\n",
    "### ‚úÖüóÉÔ∏è Dataframe pivoteado a utilizar: df_titanic\n",
    "## ---- Importamos Seaborn\n",
    "import seaborn as sns \n",
    "df_titanic = sns.load_dataset(\"titanic\")\n",
    "# df_titanic.head()\n",
    "\n",
    "## ‚úÖ DATASET PIVOTEADO\n",
    "df_pivoteado = df_titanic.pivot_table(index=\"pclass\",columns=\"sex\",values=\"age\",aggfunc=\"mean\").round(2)\n",
    "# df_pivoteado.head() \n",
    "\n",
    "#### üí° EJEMPLO 1: DESPIVOTEAR EL DATASET PIVOTEADO\n",
    "import pandas as pd\n",
    "## --- PASO 1). RESETEAR EL INDICE DE EL DATASET/DATAFRAME PIVOTEADO\n",
    "df_pivoteado_reset_index = df_pivoteado.reset_index() \n",
    "##---- PASO 2). UNPIVOTEAR DATASET/DATAFRAME\n",
    "df_unpivot_uno = pd.melt(frame=df_pivoteado_reset_index,id_vars=[\"pclass\"],value_vars=[\"female\",\"male\"],var_name=\"sex\",value_name=\"age\")\n",
    "# df_unpivot_uno.head()\n",
    "\n",
    "##---- COMPARACI√ìN DE PIVOT y UNPIVOT TABLE DEL DATASET/DATAFRAME\n",
    "print(df_pivoteado)\n",
    "print(df_unpivot_uno)\n",
    "## üí° Como se mencion√≥ anteriormente, el unpivot table no regresa los datos calculados por \n",
    "##    la funci√≥n de agregaci√≥n (en este caso \"mean\") a su forma base del dataset/dataframe original (df_titanic).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "103505eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sex</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.61</td>\n",
       "      <td>41.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.72</td>\n",
       "      <td>30.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.75</td>\n",
       "      <td>26.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sex     female   male\n",
       "pclass               \n",
       "1        34.61  41.28\n",
       "2        28.72  30.74\n",
       "3        21.75  26.51"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "df_example = sns.load_dataset(\"titanic\")\n",
    "# df_example.head()\n",
    "df_pivot = df_example.pivot_table(index=\"pclass\",columns=\"sex\",values=\"age\",aggfunc=\"mean\").round(2)\n",
    "df_pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a38a29",
   "metadata": {},
   "source": [
    "#### Fase 5. Combinar y Unir Datasets/Dataframes en Pandas üêº‚ôæÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872ee46e",
   "metadata": {},
   "source": [
    "Pandas permite la unificaci√≥n de datasets/dataframes mediante dos formas:\n",
    "    - Utilizando Merge \n",
    "    - Utilizando Concat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9f095b",
   "metadata": {},
   "source": [
    "##### Merge en Pandas üìäüêº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7c28bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    üìù SINTAXIS: \n",
    "\n",
    "        Forma 1). MEDIANTE pd.merge() ‚¨ÖÔ∏è Directamente desde Pandas.\n",
    "        \n",
    "        dataset_nombre=pd.merge(left=dataset_nombre_1,right=dataset_nombre_2,on='ColumnaEnComun',\n",
    "                                how='left || rigth || inner || cross || outer || left_anti || rigth_anti',\n",
    "                                left_on='NombreColumnaEnCom√∫n',right_on='NombreColumnaEnCom√∫n')\n",
    "        ==================================================================================================                                \n",
    "        Forma 2). MEDIANTE dataframe_nombre.merge() ‚¨ÖÔ∏è Directamente desde el dataset/dataframe.\n",
    "        \n",
    "        dataset_unificado_nombre=dataset_nombre_1.merge(right=dataset_nombre_2,on='ColumnaEnComun',\n",
    "                                how='left || rigth || inner || cross || outer || left_anti || rigth_anti',\n",
    "                                left_on='NombreColumnaEnCom√∫n',right_on='NombreColumnaEnCom√∫n')                                \n",
    "                                \n",
    "        ==================================================================================================  \n",
    "\n",
    "    ### üí°Importante: Merge permite unificar los datasets/dataframes a nivel columnar, es decir,\n",
    "                       unifica horizontalmente las columnas de un dataset/dataframe A; con las columnas\n",
    "                       de un dataset/dataframe B; gracias a una columna en com√∫n que tienen ambos \n",
    "                       conjuntos de datos.\n",
    "                       \n",
    "                       left_on ‚¨ÖÔ∏è‚û°Ô∏è right_on : Par√°metros que permiten unificar dataset/dataframes\n",
    "                                                cuando las columnas en com√∫n tienen diferente nombre.     \n",
    "\"\"\"\n",
    "### ‚úÖ Utilizaremos este dataset de ejemplo:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "diccionario_uno = {\n",
    "    \"ID_Cliente\":[1,2,3,4,5],\n",
    "    \"Nombre\": [\"Pepito\",\"Juanito\",\"Pedrito\",\"Brayan\",\"Carlos\"],\n",
    "    \"Departamento\":[\"LAS QUINTANAS\",\"EL GOLF\",\"BUENOS AIRES\",\"SAN ANDR√âS\",\"CALIFORNIA\"]\n",
    "}\n",
    "diccionario_dos = {\n",
    "    \"ID_Cliente\":[1,1,2,2,5,4,1,None],\n",
    "    \"Ventas\":np.random.uniform(low=1450.25,high=1980.30,size=8).tolist()\n",
    "}\n",
    "\n",
    "df_uno = pd.DataFrame(diccionario_uno)\n",
    "df_dos = pd.DataFrame(diccionario_dos)\n",
    "\n",
    "diccionario_tres = {\n",
    "    \"Cliente_ID\":[1,1,2,2,5,4,1,None],\n",
    "    \"Ventas\":np.random.uniform(low=1450.25,high=1980.30,size=8).tolist()\n",
    "}\n",
    "df_tres = pd.DataFrame(diccionario_tres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8178ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================= FORMA 1=====================================================================================\n",
    "\n",
    "#### üí° EJEMPLO 1 (UNIFICACI√ìN DE DATAFRAMES [INNER] ‚û°Ô∏è Forma 1.) \n",
    "df_ejemplo_1 = pd.merge(left=df_uno,right=df_dos,on=\"ID_Cliente\",how=\"inner\")\n",
    "# df_ejemplo_1.shape[0] ## Cantidad de registros: 7\n",
    "# df_ejemplo_1.head(7)\n",
    "## [NO SE ENCUENTRA EL CLIENTE 3] ‚û°Ô∏è INNER MANTIENE LA INFORMACI√ìN RELACIONADA Y EXISTENTE ENTRE AMBOS DATASETS\n",
    "\n",
    "#### üí° EJEMPLO 2 (UNIFICACI√ìN DE DATAFRAMES [LEFT] ‚û°Ô∏è Forma 1.)\n",
    "df_ejemplo_2 = pd.merge(left=df_uno,right=df_dos,on=\"ID_Cliente\",how=\"left\")\n",
    "# df_ejemplo_2.shape[0] ## Cantidad de registros: 8\n",
    "# df_ejemplo_2.head(8)\n",
    "## [SE ENCUENTRA EL CLIENTE 3] ‚û°Ô∏è LEFT MANTIENE LA INFORMACI√ìN DEL LADO IZQUIERDO (df_uno) \n",
    "## [AS√ç NO EXISTA ALG√öN REGISTRO EN EL LADO DERECHO (df_dos)]\n",
    "\n",
    "#### üí° EJEMPLO 3 (UNIFICACI√ìN DE DATAFRAMES [RIGHT] ‚û°Ô∏è Forma 1.)\n",
    "df_ejemplo_3 = pd.merge(left=df_uno,right=df_dos,on=\"ID_Cliente\",how=\"right\")\n",
    "# df_ejemplo_3.shape[0] ## Cantidad de registros: 8\n",
    "# df_ejemplo_3.head(8)\n",
    "## [SE ENCUENTRA EL CLIENTE 3] ‚û°Ô∏è RIGHT MANTIENE LA INFORMACI√ìN DEL LADO DERECHO (df_dos) \n",
    "## [AS√ç NO EXISTA ALG√öN REGISTRO EN EL LADO IZQUIERDO (df_uno)]\n",
    "\n",
    "#### üí° EJEMPLO 4 (UNIFICACI√ìN DE DATAFRAMES [OUTER] ‚û°Ô∏è Forma 1.)\n",
    "df_ejemplo_4 = pd.merge(left=df_uno,right=df_dos,on=\"ID_Cliente\",how=\"outer\")\n",
    "# df_ejemplo_4.shape[0] ## Cantidad de registros: 9\n",
    "# df_ejemplo_4.head(9)\n",
    "## ‚û°Ô∏è OUTER MANTIENE LA INFORMACI√ìN DE AMBOS DATAFRAMES.\n",
    "\n",
    "#### üí° EJEMPLO 5 (UNIFICACI√ìN DE DATAFRAMES [CROSS] ‚û°Ô∏è Forma 1.)\n",
    "df_ejemplo_5 = pd.merge(left=df_uno,right=df_dos,how=\"cross\")\n",
    "# df_ejemplo_5.shape[0] ## Cantidad de registros: 40\n",
    "# df_ejemplo_5.head()\n",
    "## ‚û°Ô∏è CROSS GENERA TODAS LAS COMBINACIONES POSIBLES DE LAS FILAS DEL df_uno CON LAS FILAS DEL df_dos. \n",
    "#     (YA NO NECESITAMOS UTILIZAR EL PAR√ÅMETRO \"on=\")\n",
    "\n",
    "#### üí° EJEMPLO 6 (UNIFICACI√ìN DE DATAFRAMES [INNER] ‚û°Ô∏è Forma 1. + left_on + right_on)\n",
    "df_ejemplo_6 = pd.merge(left=df_uno,right=df_tres,how=\"inner\",left_on=\"ID_Cliente\",right_on=\"Cliente_ID\")\n",
    "# df_ejemplo_6.shape[0] ## Cantidad de registros: 7\n",
    "# df_ejemplo_6.head(7)\n",
    "## ‚û°Ô∏è CUANDO UTILIZAMOS left_on Y right_on YA NO NECESITAMOS UTILIZAR EL PAR√ÅMETRO \"on=\"\n",
    "## üìù left_on ‚¨ÖÔ∏è‚û°Ô∏è right_on : Par√°metros que permiten unificar dataset/dataframes\n",
    "##    cuando las columnas en com√∫n tienen diferente nombre.\n",
    "\n",
    "#### üí° EJEMPLO LEFT-RIGHT_ANTI (UNIFICACI√ìN DE DATAFRAMES [LEFT_ANTI])\n",
    "#### df_ejemplo_left_anti = pd.merge(left=df_uno,right=df_dos,how=\"left_anti\",on=\"ID_Cliente\")\n",
    "#### df_ejemplo_left_anti.shape[0] ## Cantidad de registros: --\n",
    "#### df_ejemplo_left_anti.head()\n",
    "\n",
    "#### df_ejemplo_left_right = pd.merge(left=df_uno,right=df_dos,how=\"right_anti\",on=\"ID_Cliente\")\n",
    "#### df_ejemplo_left_right.shape[0] ## Cantidad de registros: --\n",
    "#### df_ejemplo_left_right.head()\n",
    "\n",
    "#### üìù LEFT Y RIGHT ANTI A√öN NO EST√ÅN DISPONIBLES EN LA VERSI√ìN DE PANDAS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb552f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================================== FORMA 2 ===============================================================================\n",
    "\n",
    "#### üí° EJEMPLO 1 (UNIFICACI√ìN DE DATAFRAMES [INNER] ‚û°Ô∏è Forma 2.) \n",
    "df_ejemplo_1 = df_uno.merge(right=df_dos,on=\"ID_Cliente\",how=\"inner\")\n",
    "# df_ejemplo_1.shape[0] ## Cantidad de registros: 7\n",
    "# df_ejemplo_1.head(7)\n",
    "## [NO SE ENCUENTRA EL CLIENTE 3] ‚û°Ô∏è INNER MANTIENE LA INFORMACI√ìN RELACIONADA Y EXISTENTE ENTRE AMBOS DATASETS\n",
    "\n",
    "#### üí° EJEMPLO 2 (UNIFICACI√ìN DE DATAFRAMES [LEFT] ‚û°Ô∏è Forma 2.)\n",
    "df_ejemplo_2 = df_uno.merge(right=df_dos,on=\"ID_Cliente\",how=\"left\")\n",
    "# df_ejemplo_2.shape[0] ## Cantidad de registros: 8\n",
    "# df_ejemplo_2.head(8)\n",
    "## [SE ENCUENTRA EL CLIENTE 3] ‚û°Ô∏è LEFT MANTIENE LA INFORMACI√ìN DEL LADO IZQUIERDO (df_uno) \n",
    "## [AS√ç NO EXISTA ALG√öN REGISTRO EN EL LADO DERECHO (df_dos)]\n",
    "\n",
    "#### üí° EJEMPLO 3 (UNIFICACI√ìN DE DATAFRAMES [RIGHT] ‚û°Ô∏è Forma 2.)\n",
    "df_ejemplo_3 = df_uno.merge(right=df_dos,on=\"ID_Cliente\",how=\"right\")\n",
    "# df_ejemplo_3.shape[0] ## Cantidad de registros: 8\n",
    "# df_ejemplo_3.head(8)\n",
    "## [SE ENCUENTRA EL CLIENTE 3] ‚û°Ô∏è RIGHT MANTIENE LA INFORMACI√ìN DEL LADO DERECHO (df_dos) \n",
    "## [AS√ç NO EXISTA ALG√öN REGISTRO EN EL LADO IZQUIERDO (df_uno)]\n",
    "\n",
    "#### üí° EJEMPLO 4 (UNIFICACI√ìN DE DATAFRAMES [OUTER] ‚û°Ô∏è Forma 2.)\n",
    "df_ejemplo_4 = df_uno.merge(right=df_dos,on=\"ID_Cliente\",how=\"outer\")\n",
    "# df_ejemplo_4.shape[0] ## Cantidad de registros: 9\n",
    "# df_ejemplo_4.head(9)\n",
    "## ‚û°Ô∏è OUTER MANTIENE LA INFORMACI√ìN DE AMBOS DATAFRAMES.\n",
    "\n",
    "#### üí° EJEMPLO 5 (UNIFICACI√ìN DE DATAFRAMES [CROSS] ‚û°Ô∏è Forma 2.)\n",
    "df_ejemplo_5 = df_uno.merge(right=df_dos,how=\"cross\")\n",
    "# df_ejemplo_5.shape[0] ## Cantidad de registros: 40\n",
    "# df_ejemplo_5.head()\n",
    "## ‚û°Ô∏è CROSS GENERA TODAS LAS COMBINACIONES POSIBLES DE LAS FILAS DEL df_uno CON LAS FILAS DEL df_dos. \n",
    "##     (YA NO NECESITAMOS UTILIZAR EL PAR√ÅMETRO \"on=\")\n",
    "\n",
    "# #### üí° EJEMPLO 6 (UNIFICACI√ìN DE DATAFRAMES [INNER] ‚û°Ô∏è Forma 2. + left_on + right_on)\n",
    "df_ejemplo_6 = df_uno.merge(right=df_tres,how=\"inner\",left_on=\"ID_Cliente\",right_on=\"Cliente_ID\")\n",
    "# df_ejemplo_6.shape[0] ## Cantidad de registros: 7\n",
    "# df_ejemplo_6.head(7)\n",
    "## ‚û°Ô∏è CUANDO UTILIZAMOS left_on Y right_on YA NO NECESITAMOS UTILIZAR EL PAR√ÅMETRO \"on=\"\n",
    "## üìù left_on ‚¨ÖÔ∏è‚û°Ô∏è right_on : Par√°metros que permiten unificar dataset/dataframes\n",
    "##    cuando las columnas en com√∫n tienen diferente nombre.\n",
    "\n",
    "#### üí° EJEMPLO LEFT-RIGHT_ANTI (UNIFICACI√ìN DE DATAFRAMES [LEFT_ANTI])\n",
    "#### df_ejemplo_left_anti = df_uno.merge(right=df_dos,how=\"left_anti\",on=\"ID_Cliente\")\n",
    "#### df_ejemplo_left_anti.shape[0] ## Cantidad de registros: --\n",
    "#### df_ejemplo_left_anti.head()\n",
    "\n",
    "#### df_ejemplo_left_right = df_uno.merge(right=df_dos,how=\"right_anti\",on=\"ID_Cliente\")\n",
    "#### df_ejemplo_left_right.shape[0] ## Cantidad de registros: --\n",
    "#### df_ejemplo_left_right.head()\n",
    "\n",
    "#### üìù LEFT Y RIGHT ANTI A√öN NO EST√ÅN DISPONIBLES EN LA VERSI√ìN ACTUAL DE PANDAS (2.3.1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7385962a",
   "metadata": {},
   "source": [
    "##### Concat en Pandas üìäüêº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db290321",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    üìù SINTAXIS: \n",
    "\n",
    "        dataset_union_nombre = pd.concat([\n",
    "            dataset_nombre_1.set_index([\"NombreColumna1\",\"NombreColumna2\",\"NombreColumnaN\"]),\n",
    "            dataset_nombre_2.set_index([\"NombreColumna1\",\"NombreColumna2\",\"NombreColumnaN\"])],\n",
    "            axis = 1,ignore_index = True\n",
    "        )\n",
    "                                                        \n",
    "        ==================================================================================================  \n",
    "\n",
    "    ### üí°Importante: Concat permite unificar los datasets/dataframes a nivel fila, es decir,\n",
    "                       unifica verticalmente las columnas de un dataset/dataframe A; con las columnas\n",
    "                       de un dataset/dataframe B; gracias a la(s) columna(s) en com√∫n que tienen ambos \n",
    "                       conjuntos de datos.\n",
    "                       \n",
    "                       Debemos tener en cuenta que ambos datasets/dataframes deben tener la misma cantidad\n",
    "                       tipos y orden en las columnas. Adem√°s, el par√°metro \"axis\" siempre debe igualarse a 1 para\n",
    "                       que los datastes/dataframes se unifiquen a nivel vertical columnar. Por otro lado,\n",
    "                       el par√°metro \"ignore_index\" debe permanecer en True para que el √≠ndice del dataset/\n",
    "                       dataframe nuevo se reestablezca.\n",
    "\"\"\"\n",
    "### ‚úÖ Utilizaremos este dataset de ejemplo:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "diccionario_uno = {\n",
    "    \"Categorias\":[\"ELECTRODOM√âSTICOS\",\"TECNOLOG√çA\",\"JUGUETES\",\"DEPORTE\",\"CULTURA\"],\n",
    "    \"A√±o\": [2022,2022,2023,2023,2023],\n",
    "    \"Ventas\":np.random.uniform(low=3500.25,high=3800.30,size=5).round(2).tolist()\n",
    "}\n",
    "\n",
    "diccionario_dos = {\n",
    "    \"Categorias\":[\"ELECTRODOM√âSTICOS\",\"TECNOLOG√çA\",\"JUGUETES\",\"DEPORTE\",\"CULTURA\"],\n",
    "    \"A√±o\": [2024,2024,2024,2025,2025],\n",
    "    \"Ventas\":np.random.uniform(low=2150.25,high=4580.30,size=5).round(2).tolist()\n",
    "}\n",
    "\n",
    "diccionario_tres = {\n",
    "    \"Cat\":[\"ELECTRODOM√âSTICOS\",\"TECNOLOG√çA\",\"JUGUETES\",\"DEPORTE\",\"CULTURA\"],\n",
    "    \"A√±os\": [2024,2024,2024,2025,2025],\n",
    "    \"Vent\":np.random.uniform(low=2150.25,high=4580.30,size=5).round(2).tolist()\n",
    "}\n",
    "\n",
    "df_uno = pd.DataFrame(diccionario_uno)\n",
    "df_dos = pd.DataFrame(diccionario_dos)\n",
    "df_tres = pd.DataFrame(diccionario_tres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0d83b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Categorias</th>\n",
       "      <th>A√±o</th>\n",
       "      <th>Ventas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ELECTRODOM√âSTICOS</th>\n",
       "      <th>2022</th>\n",
       "      <th>3681.64</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TECNOLOG√çA</th>\n",
       "      <th>2022</th>\n",
       "      <th>3712.02</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JUGUETES</th>\n",
       "      <th>2023</th>\n",
       "      <th>3787.70</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEPORTE</th>\n",
       "      <th>2023</th>\n",
       "      <th>3584.49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CULTURA</th>\n",
       "      <th>2023</th>\n",
       "      <th>3569.32</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELECTRODOM√âSTICOS</th>\n",
       "      <th>2024</th>\n",
       "      <th>4365.75</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TECNOLOG√çA</th>\n",
       "      <th>2024</th>\n",
       "      <th>4182.75</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JUGUETES</th>\n",
       "      <th>2024</th>\n",
       "      <th>3024.93</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEPORTE</th>\n",
       "      <th>2025</th>\n",
       "      <th>3321.68</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CULTURA</th>\n",
       "      <th>2025</th>\n",
       "      <th>4189.49</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [(ELECTRODOM√âSTICOS, 2022, 3681.64), (TECNOLOG√çA, 2022, 3712.02), (JUGUETES, 2023, 3787.7), (DEPORTE, 2023, 3584.49), (CULTURA, 2023, 3569.32), (ELECTRODOM√âSTICOS, 2024, 4365.75), (TECNOLOG√çA, 2024, 4182.75), (JUGUETES, 2024, 3024.93), (DEPORTE, 2025, 3321.68), (CULTURA, 2025, 4189.49)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### üí° EJEMPLO 1 (UNIFICACI√ìN DE DATAFRAMES A NIVEL COLUMNAR - VERTICAL) \n",
    "df_ejemplo_1 = pd.concat([df_uno.set_index([\"Categorias\",\"A√±o\",\"Ventas\"]),\n",
    "                         df_dos.set_index([\"Categorias\",\"A√±o\",\"Ventas\"])],axis=1,ignore_index=True)\n",
    "# df_ejemplo_1.shape[0] ## Cantidad de registros: 10\n",
    "# df_ejemplo_1.head(10)\n",
    "\n",
    "#### üí° EJEMPLO 2 (UNIFICACI√ìN DE DATAFRAMES A NIVEL COLUMNAR - VERTICAL) ‚¨ÖÔ∏è CON DIFERENTES NOMBRES \n",
    "\n",
    "##---- PASO A). RENOMBRAR LAS COLUMNAS\n",
    "df_tres.rename({\"Cat\":\"Categorias\",\"A√±os\":\"A√±o\",\"Vent\":\"Ventas\"},axis=1,inplace=True)\n",
    "# df_tres.head()\n",
    "\n",
    "##---- PASO B). UNIFICAR DATASETS/DATAFRAMES\n",
    "\n",
    "df_ejemplo_2 = pd.concat([df_uno.set_index([\"Categorias\",\"A√±o\",\"Ventas\"]),\n",
    "                         df_tres.set_index([\"Categorias\",\"A√±o\",\"Ventas\"])],axis=1,ignore_index=True)\n",
    "# df_ejemplo_2.shape[0] ## Cantidad de registros: 10\n",
    "# df_ejemplo_2.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267df056",
   "metadata": {},
   "source": [
    "#### Fase 6. Exportaci√≥n de Datos en Pandas üêºüóÉÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7502fee6",
   "metadata": {},
   "source": [
    "Esta fase final en la manipulaci√≥n de datos brinda permite que la informaci√≥n previamente procesada se pueda consumir, intercambiar o almacenar. Su importancia radica en garantizar informaci√≥n limpia y transformada est√© disponible para otros sistemas, an√°lisis posteriores o toma de decisiones, ya sea en archivos planos (CSV, Excel), estructurados (JSON, Parquet) o de alto rendimiento en entornos de Big Data (Parquet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58035c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### üí° UTLIZAREMOS DE EJEMPLO ESTE DATASET\n",
    "data = {\n",
    "    \"id\": [1, 2, 3, 3, None],\n",
    "    \"nombre\": [\"Ana\", \"Luis\", \"Karla\", \"Karla\", \"Pedro\"],\n",
    "    \"edad\": [23, 35, 29, 29, None]\n",
    "}\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77d16e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ‚úÖ Realizaremos una Limpieza b√°sica\n",
    "df = df.dropna()                 # eliminar filas con valores nulos\n",
    "df = df.drop_duplicates()        # eliminar duplicados\n",
    "df[\"id\"] = df[\"id\"].astype(int)  # castear columna a entero\n",
    "df.rename(columns={\"nombre\": \"Nombre\", \"edad\": \"Edad\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75594e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV exportado.\n"
     ]
    }
   ],
   "source": [
    "### ‚úÖ Exportando el dataset\n",
    "## ----- Formato CSV(Comma Separated Values) \n",
    "\"\"\"\n",
    "    SINTAXIS: \n",
    "        dataset_nombre.to_csv(path_or_buf=\"RutaAlmacenarArchivoExportado\", index=True | False, sep=\"SeparadorDatos\")    \n",
    "    \n",
    "    ‚úîÔ∏è path_or_buf: Es el par√°metro que permite especificar la ruta donde se almacenar√° el archivo.\n",
    "    ‚úîÔ∏è index: Es el par√°metro que permite establecer un √≠ndice a cada registro dentro del archivo. (True=Si || False=No)\n",
    "    ‚úîÔ∏è sep: Es el par√°metro que permite especificar el signo de puntuaci√≥n a separar los datos (Mayormente utilizamos (,) o (;) ).\n",
    "    \n",
    "    ### üß† TENER EN CUENTA QUE LA EXTENSI√ìN DEBE SER IGUAL A LA FUNCI√ìN DE EXPORTACI√ìN DEL ARCHIVO\n",
    "    ###     Por ejemplo: ‚úÖ to_csv-> .csv ---- ‚ùå to_csv -> .xlsx\n",
    "\"\"\"\n",
    "### üí° EJEMPLO\n",
    "df.to_csv(path_or_buf=\"../datasets/fase_exportacion/pandas_export.csv\", index=False, sep=\",\")\n",
    "print(\"Archivo CSV exportado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06bad49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo Excel exportado.\n"
     ]
    }
   ],
   "source": [
    "### ‚úÖ Exportando el dataset\n",
    "## ----- Formato EXCEL\n",
    "\"\"\"\n",
    "    SINTAXIS: \n",
    "        dataset_nombre.df.to_excel(excel_writer=\"RutaAlmacenarArchivoExportado\",sheet_name=\"NombreDeLaHojaDelExcel\",index=True | False)    \n",
    "    \n",
    "    ‚úîÔ∏è excel_writer: Es el par√°metro que permite especificar la ruta donde se almacenar√° el archivo.\n",
    "    ‚úîÔ∏è sheet_name: Es el par√°metro que permite establecer el nombre de la hoja donde se almacenar√° el archivo excel.\n",
    "    ‚úîÔ∏è index: Es el par√°metro que permite establecer un √≠ndice a cada registro dentro del archivo. (True=Si || False=No)\n",
    "    \n",
    "    ### üß† TENER EN CUENTA QUE LA EXTENSI√ìN DEBE SER IGUAL A LA FUNCI√ìN DE EXPORTACI√ìN DEL ARCHIVO\n",
    "    ###     Por ejemplo: ‚úÖ to_excel-> .xlsx ---- ‚ùå to_excel -> .csv\n",
    "    \n",
    "    ### üß† SE MOSTRAR√ÅN LOS EJEMPLOS CON LOS PRINCIPALES PAR√ÅMETROS (excel_writer, sheet_name e index)\n",
    "\"\"\"\n",
    "### üí° EJEMPLO\n",
    "df.to_excel(excel_writer=\"../datasets/fase_exportacion/pandas_export.xlsx\",sheet_name=\"HojaPrueba\",index=False) \n",
    "print(\"Archivo Excel exportado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c1d649f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo JSON B√°sico exportado.\n",
      "Archivo JSON BIG DATA exportado.\n",
      "Archivo JSON ORIENT RECORDS exportado.\n",
      "Archivo JSON ORIENT INDEX exportado.\n",
      "Archivo JSON ORIENT COLUMNS exportado.\n",
      "Archivo JSON ORIENT VALUES exportado.\n",
      "Archivo JSON ORIENT SPLIT exportado.\n",
      "Archivo JSON ORIENT TABLE exportado.\n"
     ]
    }
   ],
   "source": [
    "### ‚úÖ Exportando el dataset\n",
    "## ----- Formato JSON (JAVASCRIPT OBJECT NOTATION)\n",
    "\"\"\"\n",
    "    SINTAXIS: \n",
    "        dataset_nombre.to_json(path_or_buf=\"RutaAlmacenarArchivoExportado\",orient=\"Orientaciones\",lines=True | False)  \n",
    "    \n",
    "    ‚úîÔ∏è path_or_buf: Es el par√°metro que permite especificar la ruta donde se almacenar√° el archivo.\n",
    "    ‚úîÔ∏è orient: Es el par√°metro que permite establecer la orientaci√≥n de los datos del archivo.\n",
    "    ‚úîÔ∏è lines: Es el par√°metro que permite especificar el tipo de procesamiento que se brindar√° al archivo \n",
    "              (True en caso sea un JSON B√°sico y False en caso el JSON si el procesamiento es en BIG DATA).\n",
    "              \n",
    "    ### üß† TENER EN CUENTA QUE LA EXTENSI√ìN DEBE SER IGUAL A LA FUNCI√ìN DE EXPORTACI√ìN DEL ARCHIVO\n",
    "    ###     Por ejemplo: ‚úÖ to_json-> .json ---- ‚ùå to_json -> .xlsx\n",
    "\"\"\"\n",
    "### üí° EJEMPLO 1 (JSON B√ÅSICO)\n",
    "df.to_json(path_or_buf=\"../datasets/fase_exportacion/pandas_export_basico.json\",orient=\"records\",lines=False)\n",
    "print(\"Archivo JSON B√°sico exportado.\")\n",
    "\n",
    "### üí° EJEMPLO 2 (JSON ORIENTADO A PROCESAMIENTO EN BIG DATA[LINEA POR LINEA])\n",
    "df.to_json(path_or_buf=\"../datasets/fase_exportacion/pandas_export_big_data.json\",orient=\"records\",lines=True)\n",
    "print(\"Archivo JSON BIG DATA exportado.\")\n",
    "\n",
    "### üí° EJEMPLO 3 (JSON ORIENTACI√ìN B√ÅSICA Y COMUNMENTE UTILIZADA) ‚û°Ô∏è orient = \"records\"\n",
    "df.to_json(path_or_buf=\"../datasets/fase_exportacion/pandas_export_records.json\",orient=\"records\",lines=False)\n",
    "print(\"Archivo JSON ORIENT RECORDS exportado.\")\n",
    "\n",
    "### üí° EJEMPLO 4 (JSON ORIENTACI√ìN CON √çNDICE) ‚û°Ô∏è orient = \"index\"\n",
    "df.to_json(path_or_buf=\"../datasets/fase_exportacion/pandas_export_index.json\",orient=\"index\",lines=False)\n",
    "print(\"Archivo JSON ORIENT INDEX exportado.\") ## ‚û°Ô∏è SE ASIGNA UN  √çNDICE AL JSON EXPORTADO. \n",
    "\n",
    "### üí° EJEMPLO 5 (JSON ORIENTACI√ìN CON COLUMNAS) ‚û°Ô∏è orient = \"columns\"\n",
    "df.to_json(path_or_buf=\"../datasets/fase_exportacion/pandas_export_columns.json\",orient=\"columns\",lines=False)\n",
    "print(\"Archivo JSON ORIENT COLUMNS exportado.\") ## ‚û°Ô∏è AGRUPA POR COLUMNAS (CADA COLUMNA ES UN OBJETO CON VALORES INDEXADOS)\n",
    "\n",
    "### üí° EJEMPLO 6 (RETORNA UNA LISTA CON LOS VALORES DE CADA COLMUMNA) ‚û°Ô∏è orient = \"values\"\n",
    "df.to_json(path_or_buf=\"../datasets/fase_exportacion/pandas_export_values.json\",orient=\"values\",lines=False)\n",
    "print(\"Archivo JSON ORIENT VALUES exportado.\") ## ‚û°Ô∏è RETORNA UNA LISTA DE LISTAS.\n",
    "\n",
    "### üí° EJEMPLO 7 (RETORNA UN JSON CON LA ESTRUCTURA DEL DATAFRAME) ‚û°Ô∏è orient = \"split\"\n",
    "df.to_json(path_or_buf=\"../datasets/fase_exportacion/pandas_export_split.json\",orient=\"split\",lines=False)\n",
    "print(\"Archivo JSON ORIENT SPLIT exportado.\") ## ‚û°Ô∏è RETORNA UN JSON QUE CONTIENE: COLUMNAS,INDICES Y DATOS.\n",
    "\n",
    "### üí° EJEMPLO 8 (RETORNA UN JSON CON LOS METADATOS DE LA ESTRUCTURA DEL DATAFRAME) ‚û°Ô∏è orient = \"table\"\n",
    "df.to_json(path_or_buf=\"../datasets/fase_exportacion/pandas_export_table.json\",orient=\"table\",lines=False)\n",
    "print(\"Archivo JSON ORIENT TABLE exportado.\") ## ‚û°Ô∏è RETORNA UN JSON QUE CONTIENE: SCHEMAS, DATA DEL DATAFRAME.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5aebc191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo PARQUET exportado.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### ‚úÖ Exportando el dataset\n",
    "## ----- Formato PARQUET (FORMATO COLUMNAR OPTIMIZADO PARA SOLUCIONES DE BIG DATA)\n",
    "\"\"\"\n",
    "    SINTAXIS: \n",
    "        dataset_nombre.to_parquet(path=\"RutaAlmacenarArchivoExportado\",index=False,\n",
    "              engine=\"auto|fastparquet|pyarrow\", compression=\"brotli|gzip|lz4|snappy|zstd\")\n",
    "    \n",
    "    ‚úîÔ∏è path: Es el par√°metro que permite especificar la ruta donde se almacenar√° el archivo.\n",
    "    ‚úîÔ∏è compression: Es el par√°metro que permite reducir el tama√±o del archivo.\n",
    "    ‚úîÔ∏è engine: Es el par√°metro que permite establecer la velocidad de escritura/lectura \n",
    "    ‚úîÔ∏è index: Es el par√°metro que permite establecer un √≠ndice a cada registro dentro del archivo. (True=Si || False=No)\n",
    "                  \n",
    "    ### üß† TENER EN CUENTA QUE LA EXTENSI√ìN DEBE SER IGUAL A LA FUNCI√ìN DE EXPORTACI√ìN DEL ARCHIVO\n",
    "    ###     Por ejemplo: ‚úÖ to_parquet-> .parquet ---- ‚ùå to_parquet -> .xlsx\n",
    "    ### üí° EN LOS SIGUIENTES EJEMPLOS UTILIZAREMOS LOS PAR√ÅMETROS CON LOS VALORES MEJORES OPTIMIZADOS.\n",
    "\"\"\"\n",
    "### üí° EJEMPLO 1: EXPOTANDO FORMATO PARQUET (compression='snappy' y engine='pyarrow')\n",
    "df.to_parquet(path=\"../datasets/fase_exportacion/pandas_export_parquet.parquet\",index=False,engine=\"pyarrow\",\n",
    "              compression=\"snappy\")\n",
    "print(\"Archivo PARQUET exportado.\")\n",
    "\n",
    "### üß† A tener en cuenta:\n",
    "\"\"\"\n",
    "compression=\"snappy\"  # R√°pido, compresi√≥n moderada\n",
    "compression=\"gzip\"    # Lento, alta compresi√≥n\n",
    "compression=\"brotli\"  # Mejor compresi√≥n, m√°s lento\n",
    "\n",
    "===================================================\n",
    "\n",
    "engine=\"pyarrow\"     # M√°s r√°pido\n",
    "engine=\"fastparquet\" # Alternativa\n",
    "\n",
    "\"\"\"\n",
    "print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70e02fad",
   "metadata": {},
   "source": [
    "### 📘 Talleres de Ingeniería de Datos con Pandas y Polars 🐼🐻‍❄️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76db83f1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "👨‍💻 Autor: Brayan Neciosup  \n",
    "📍 Portafolio: [brayanneciosup](https://bryanneciosup626.wixsite.com/brayandataanalitics)  \n",
    "🔗 LinkedIn: [linkedin.com/brayanneciosup](https://www.linkedin.com/in/brayan-rafael-neciosup-bola%C3%B1os-407a59246/)  \n",
    "💻 GitHub: [github.com/BrayanR03](https://github.com/BrayanR03)  \n",
    "📚 Serie: Fundamentos de Pandas y Polars   \n",
    "📓 Estos talleres constarán de 3 niveles (Básico-Intermedio-Avanzado)   \n",
    "🔍 Abarcará temas desde Fundamentos de Data Wrangling hacia Casos de Uso Avanzado   \n",
    "📝 Cada ejercicio presenta su enunciado, dataset, resultado esperado y solución.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533cd600",
   "metadata": {},
   "source": [
    "#### FUNDAMENTOS DE DATA WRANGLING (MANIPULACIÓN DE DATOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90306f5b",
   "metadata": {},
   "source": [
    "##### 🥉 NIVEL BÁSICO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f1a1a3",
   "metadata": {},
   "source": [
    "###### PANDAS 🐼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c51d9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "1. Detección de valores nulos en columnas principales\n",
    "\n",
    "🗃️ Dataset: TITANIC\n",
    "🗒️ Enunciado: Identifica cuántos valores faltantes hay en las columnas age, embarked y deck.\n",
    "✍️ Resultado esperado: un conteo por columna con la cantidad de valores nulos.\n",
    "\n",
    "\"\"\"\n",
    "## ✔️ Solución\n",
    "df_uno = sns.load_dataset(\"titanic\")\n",
    "# df_uno.head()\n",
    "# df_uno[[\"age\",\"embarked\",\"deck\"]].isnull().sum() ## ➡️ Cantidad de datos nulos: age(177) - embarked(2) - deck(688)\n",
    "\n",
    "\"\"\"\n",
    "2. Eliminación de filas duplicadas\n",
    "\n",
    "🗃️ Dataset: Diccionario\n",
    "🗒️ Enunciado: Elimina las filas duplicadas y conserva solo la primera aparición de cada registro.\n",
    "✍️ Resultado esperado: un DataFrame sin filas repetidas.\n",
    "\n",
    "\"\"\"\n",
    "## ✔️ Solución\n",
    "dict_data = {\n",
    " \"id\": [1,2,2,3,4,4,5],\n",
    " \"nombre\": [\"Ana\",\"Luis\",\"Luis\",\"María\",\"Pedro\",\"Pedro\",\"Sofía\"],\n",
    " \"edad\": [23,30,30,22,40,40,29]\n",
    "}\n",
    "df_dos = pd.DataFrame(dict_data)\n",
    "# df_dos.head()\n",
    "# df_dos.shape[0] ## ➡️ Cantidad de datos: 7\n",
    "df_dos.drop_duplicates(subset=[\"id\",\"nombre\",\"edad\"],keep=\"first\",inplace=True)\n",
    "# df_dos.head()\n",
    "df_dos.shape[0] ## ➡️ Cantidad de datos: 5\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "3. Reemplazo simple de valores faltantes\n",
    "\n",
    "🗃️ Dataset: PENGUINS\n",
    "🗒️ Enunciado: Reemplaza los valores nulos en la columna bill_length_mm con la media de esa misma columna.\n",
    "✍️ Resultado esperado: columna sin valores nulos en bill_length_mm.\n",
    "\n",
    "\"\"\"\n",
    "## ✔️ Solución\n",
    "df_tres = sns.load_dataset(\"penguins\")\n",
    "# df_tres.head()\n",
    "# df_tres[\"bill_length_mm\"].isnull().sum() ## ➡️ Cantidad de datos nulos: 2\n",
    "media_bill_length_mm = float(np.mean(df_tres[\"bill_length_mm\"].dropna()).round(2))\n",
    "df_tres.fillna({\"bill_length_mm\":media_bill_length_mm},inplace=True)\n",
    "df_tres[\"bill_length_mm\"].isnull().sum() ## ➡️ Cantidad de datos nulos: 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3644744",
   "metadata": {},
   "source": [
    "###### POLARS 🐻‍❄️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57f88ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "1. Detección de valores nulos en columnas principales\n",
    "\n",
    "🗃️ Dataset: TITANIC\n",
    "🗒️ Enunciado: Identifica cuántos valores faltantes hay en las columnas age, embarked y deck.\n",
    "✍️ Resultado esperado: un conteo por columna con la cantidad de valores nulos.\n",
    "\n",
    "\"\"\"\n",
    "## ✔️ Solución\n",
    "df_uno = pl.read_csv(\"../datasets/titanic.csv\",separator=\",\")\n",
    "# df_uno.head()\n",
    "df_uno.null_count()\n",
    "\n",
    "\"\"\"\n",
    "2. Eliminación de filas duplicadas\n",
    "\n",
    "🗃️ Dataset: Diccionario\n",
    "🗒️ Enunciado: Elimina las filas duplicadas y conserva solo la primera aparición de cada registro.\n",
    "✍️ Resultado esperado: un DataFrame sin filas repetidas.\n",
    "\n",
    "\"\"\"\n",
    "## ✔️ Solución\n",
    "dict_data = {\n",
    " \"id\": [1,2,2,3,4,4,5],\n",
    " \"nombre\": [\"Ana\",\"Luis\",\"Luis\",\"María\",\"Pedro\",\"Pedro\",\"Sofía\"],\n",
    " \"edad\": [23,30,30,22,40,40,29]\n",
    "}\n",
    "df_dos = pl.DataFrame(dict_data)\n",
    "# df_dos.head()\n",
    "df_dos = df_dos.unique(keep=\"first\")\n",
    "df_dos.head()\n",
    "\n",
    "\"\"\"\n",
    "3. Reemplazo simple de valores faltantes\n",
    "\n",
    "🗃️ Dataset: PENGUINS\n",
    "🗒️ Enunciado: Reemplaza los valores nulos en la columna bill_length_mm con la media de esa misma columna.\n",
    "✍️ Resultado esperado: columna sin valores nulos en bill_length_mm.\n",
    "\n",
    "\"\"\"\n",
    "## ✔️ Solución\n",
    "df_tres = pl.read_csv(\"../datasets/penguins.csv\",separator=\",\")\n",
    "# df_tres.head()\n",
    "# df_tres[\"bill_length_mm\"].null_count() ## ➡️ Cantidad Nulos: 2\n",
    "media_bill_length_mm = df_tres[\"bill_length_mm\"].mean().__round__(2)\n",
    "media_bill_length_mm\n",
    "df_tres = df_tres.with_columns(\n",
    "    pl.col(\"bill_length_mm\").fill_null(media_bill_length_mm).alias(\"bill_length_mm\")\n",
    ")\n",
    "# df_tres.head()\n",
    "df_tres[\"bill_length_mm\"].null_count() ## ➡️ Cantidad Nulos: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87889e12",
   "metadata": {},
   "source": [
    "##### 🥈 NIVEL INTERMEDIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55f9c68",
   "metadata": {},
   "source": [
    "###### PANDAS 🐼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4249f3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "4. Imputación condicional de valores faltantes\n",
    "\n",
    "🗃️ Dataset: TITANIC\n",
    "🗒️ Enunciado: Completa los valores faltantes de age con la edad promedio por clase (pclass).\n",
    "✍️ Resultado esperado: columna age sin valores nulos, imputada según clase de pasajero.\n",
    "\n",
    "\"\"\"\n",
    "## ✔️ Solución\n",
    "df_cuatro = sns.load_dataset(\"titanic\")\n",
    "# df_cuatro.head()\n",
    "# df_cuatro[\"age\"].isnull().sum() ## ➡️ Cantidad de datos nulos: 177\n",
    "edad_promedio_por_clase = df_cuatro.groupby(\"pclass\",as_index=False,observed=True)[\"age\"].mean().round(2)\n",
    "edad_promedio_por_clase\n",
    "# df_cuatro[\"age\"].isnull().sum() ## ➡️ Cantidad de datos nulos: 177\n",
    "\n",
    "df_cuatro_clean = df_cuatro.copy()\n",
    "df_cuatro_clean[df_cuatro_clean[\"pclass\"]==1] = df_cuatro_clean[df_cuatro_clean[\"pclass\"]==1].fillna({\n",
    "    \"age\":float(edad_promedio_por_clase.query('pclass==1')[\"age\"][0])\n",
    "})\n",
    "df_cuatro[df_cuatro[\"pclass\"]==2] = df_cuatro[df_cuatro[\"pclass\"]==2].fillna({\n",
    "    \"age\":float(edad_promedio_por_clase.query('pclass==2')[\"age\"][1])\n",
    "})\n",
    "df_cuatro[df_cuatro[\"pclass\"]==3] = df_cuatro[df_cuatro[\"pclass\"]==3].fillna({\n",
    "    \"age\":float(edad_promedio_por_clase.query(\"pclass==3\")[\"age\"][2])\n",
    "})\n",
    "# df_cuatro_clean[df_cuatro_clean[\"pclass\"]==1].isnull().sum() ## Cantidad: 0\n",
    "# df_cuatro_clean[df_cuatro_clean[\"pclass\"]==2].isnull().sum() ## Cantidad: 0\n",
    "# df_cuatro_clean[df_cuatro_clean[\"pclass\"]==3].isnull().sum() ## Cantidad: 0\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "5. Detección de outliers usando IQR\n",
    "\n",
    "🗃️ Dataset: Diccionario\n",
    "🗒️ Enunciado: Identifica los valores de ventas que son outliers según el rango intercuartílico (IQR).\n",
    "✍️ Resultado esperado: listado de los productos que presentan valores anómalos.\n",
    "\n",
    "\"\"\"\n",
    "## ✔️ Solución\n",
    "diccionario_cinco = {\n",
    " \"producto\": [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"],\n",
    " \"ventas\": [120, 130, 115, 1000, 140, 135]\n",
    "}\n",
    "df_cinco = pd.DataFrame(diccionario_cinco)\n",
    "# df_cinco.head()\n",
    "# df_cinco.describe()\n",
    "q1_ventas = float(np.quantile(df_cinco[\"ventas\"],0.25))\n",
    "q3_ventas = float(np.quantile(df_cinco[\"ventas\"],0.75))\n",
    "iqr_ventas = q3_ventas-q1_ventas\n",
    "lower_bound_ventas = q1_ventas - 1.5 * iqr_ventas\n",
    "upper_bound_ventas = q3_ventas + 1.5 * iqr_ventas\n",
    "df_cinco_outliers = df_cinco[(df_cinco[\"ventas\"]<lower_bound_ventas) | (df_cinco[\"ventas\"]>upper_bound_ventas)]\n",
    "# df_cinco_outliers.head()\n",
    "df_cinco_outliers.shape[0] ## CANTIDAD DE OUTLIERS EN COLUMNA VENTAS: 1\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "6. Eliminación selectiva de duplicados\n",
    "\n",
    "🗃️ Dataset: Diamonds\n",
    "🗒️ Enunciado: En el dataset de diamantes, elimina duplicados basados solo en las columnas carat y price.\n",
    "✍️ Resultado esperado: DataFrame sin duplicados en esas dos columnas, pero manteniendo el resto de filas.\n",
    "\n",
    "\"\"\"\n",
    "## ✔️ Solución\n",
    "df_seis = sns.load_dataset(\"diamonds\")\n",
    "df_seis.head()\n",
    "# df_seis.shape[0] ## 53940 DATOS\n",
    "# df_seis[\"carat\"].duplicated().sum() ## 53 667 DATOS DUPLICADOS EN ESTA COLUMNA\n",
    "# df_seis[\"price\"].duplicated().sum() ## 42 338 DATOS DUPLICADOS EN ESTA COLUMNA\n",
    "# df_seis.drop_duplicates(subset=[\"carat\",\"price\"],inplace=True)\n",
    "# df_seis.shape[0] ## 28988 DATOS DESPUES DE REMOVER DUPLICADOS\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "7. Relleno de valores faltantes con interpolación\n",
    "\n",
    "🗃️ Dataset: Diccionario\n",
    "🗒️ Enunciado: Rellena los valores nulos de la columna temperatura mediante interpolación lineal.\n",
    "✍️ Resultado esperado: columna completa sin valores nulos, con estimaciones suaves.\n",
    "\n",
    "\"\"\"\n",
    "## ✔️ Solución\n",
    "diccionario_siete = {\n",
    "    \"fecha\": pd.date_range(\"2024-01-01\", periods=10),\n",
    "    \"temperatura\": [21,22,None,24,25,None,None,28,29,30]\n",
    "}\n",
    "df_siete = pd.DataFrame(diccionario_siete)\n",
    "df_siete_interpolado = df_siete.copy()\n",
    "df_siete_interpolado = df_siete_interpolado.interpolate(method=\"linear\")\n",
    "df_siete_interpolado.head()\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "8. Conteo de valores faltantes combinados\n",
    "\n",
    "🗃️ Dataset: Penguins\n",
    "🗒️ Enunciado: Calcula el número de registros que tienen valores nulos simultáneamente\n",
    "    en las columnas bill_length_mm y bill_depth_mm.\n",
    "✍️ Resultado esperado: un número entero que indique cuántos registros cumplen esta condición.\n",
    "\n",
    "\"\"\"\n",
    "## ✔️ Solución\n",
    "df_ocho = sns.load_dataset(\"penguins\")\n",
    "# df_ocho.head()\n",
    "df_ocho[[\"bill_length_mm\",\"bill_depth_mm\"]].isnull().sum() ## ⬅️ Cantidad de datos nulos en ambas columnas (bill_length_mm:2 - bill_depth_mm: 2).\n",
    "df_ocho_nulos = df_ocho[(df_ocho[\"bill_length_mm\"].isnull()==True) & (df_ocho[\"bill_depth_mm\"].isnull()==True)]\n",
    "df_ocho_nulos.shape[0] ## ⬅️ Cantidad de valores nulos simultaneos en ambas columnas: 2\n",
    "\n",
    "#--- En caso no haya entendido el concepto, te dejo este otro ejemplo 👍.\n",
    "df_example = pd.DataFrame(data=[[1,None],[None,2],[None,None]],columns=[\"A\",\"B\"])\n",
    "# df_example.head() ## ⬅️ Como podremos observar hay un match en dos registros de la fila A y B que son nulos.\n",
    "cantidad_nulos = df_example[(df_example[\"A\"].isnull()==True) & (df_example[\"B\"].isnull()==True)]\n",
    "cantidad_nulos.shape[0] ## ⬅️ Cantidad de valores nulos simultaneos en ambas columnas: 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0d7d0b",
   "metadata": {},
   "source": [
    "###### POLARS 🐻‍❄️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3bbcaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "4. Imputación condicional de valores faltantes\n",
    "\n",
    "🗃️ Dataset: TITANIC\n",
    "🗒️ Enunciado: Completa los valores faltantes de age con la edad promedio por clase (pclass).\n",
    "✍️ Resultado esperado: columna age sin valores nulos, imputada según clase de pasajero.\n",
    "\n",
    "\"\"\"\n",
    "## ✔️ Solución\n",
    "df_cuatro = pl.read_csv(\"../datasets/titanic.csv\",separator=\",\")\n",
    "# df_cuatro.head()\n",
    "# df_cuatro[\"age\"].null_count() ## ➡️ Cantidad de datos nulos: 177\n",
    "def llenar_nulos_pclass_edad(dataframe):\n",
    "    df = dataframe\n",
    "    edad_promedio_por_clase = df_cuatro.group_by(\"pclass\").agg(\n",
    "        pl.col(\"age\").drop_nulls().mean().round(2).alias(\"avg_age_pclass\")\n",
    "    )\n",
    "    \n",
    "    for pclass,media in edad_promedio_por_clase.iter_rows():\n",
    "        df = df.with_columns(\n",
    "            pl.when(\n",
    "                (pl.col(\"pclass\")==pclass) & (pl.col(\"age\").is_null())\n",
    "            ).then(pl.lit(media))\n",
    "            .otherwise(pl.col(\"age\")).alias(\"age\")\n",
    "        )\n",
    "    return df\n",
    "df_cuatro_clean = llenar_nulos_pclass_edad(df_cuatro)\n",
    "df_cuatro_clean[[\"age\"]].null_count() ## ➡️ Cantidad de datos nulos: 0 \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "5. Detección de outliers usando IQR\n",
    "\n",
    "🗃️ Dataset: Diccionario\n",
    "🗒️ Enunciado: Identifica los valores de ventas que son outliers según el rango intercuartílico (IQR).\n",
    "✍️ Resultado esperado: listado de los productos que presentan valores anómalos.\n",
    "\n",
    "\"\"\"\n",
    "## ✔️ Solución\n",
    "diccionario_cinco = {\n",
    " \"producto\": [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"],\n",
    " \"ventas\": [120, 130, 115, 1000, 140, 135]\n",
    "}\n",
    "df_cinco = pl.DataFrame(diccionario_cinco)\n",
    "# df_cinco.head()\n",
    "q1_ventas = df_cinco[\"ventas\"].quantile(0.25)\n",
    "q1_ventas\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "6. Eliminación selectiva de duplicados\n",
    "\n",
    "🗃️ Dataset: Diamonds\n",
    "🗒️ Enunciado: En el dataset de diamantes, elimina duplicados basados solo en las columnas carat y price.\n",
    "✍️ Resultado esperado: DataFrame sin duplicados en esas dos columnas, pero manteniendo el resto de filas.\n",
    "\n",
    "\"\"\"\n",
    "## ✔️ Solución\n",
    "df_seis = pl.read_csv(\"../datasets/diamonds.csv\",separator=\",\")\n",
    "# df_seis.head()\n",
    "df_seis = df_seis.unique(subset=[\"carat\",\"price\"],keep=\"first\")\n",
    "df_seis.head()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "7. Relleno de valores faltantes con interpolación\n",
    "\n",
    "🗃️ Dataset: Diccionario\n",
    "🗒️ Enunciado: Rellena los valores nulos de la columna temperatura mediante interpolación lineal.\n",
    "✍️ Resultado esperado: columna completa sin valores nulos, con estimaciones suaves.\n",
    "\n",
    "\"\"\"\n",
    "## ✔️ Solución\n",
    "from datetime import date\n",
    "diccionario_siete  = {\n",
    " \"fecha\": pd.date_range(\"2024-01-01\", periods=10),\n",
    " \"temperatura\": [21,22,None,24,25,None,None,28,29,30]\n",
    "}\n",
    "df_siete = pl.DataFrame(diccionario_siete)\n",
    "df_siete = df_siete.select(pl.col(\"fecha\"),pl.col(\"temperatura\").interpolate().alias(\"temperatura\"))\n",
    "df_siete.head()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "8. Conteo de valores faltantes combinados\n",
    "\n",
    "🗃️ Dataset: Penguins\n",
    "🗒️ Enunciado: Calcula el número de registros que tienen valores nulos simultáneamente\n",
    "    en las columnas bill_length_mm y bill_depth_mm.\n",
    "✍️ Resultado esperado: un número entero que indique cuántos registros cumplen esta condición.\n",
    "\n",
    "\"\"\"\n",
    "## ✔️ Solución\n",
    "df_ocho = pl.read_csv(\"../datasets/penguins.csv\",separator=\",\")\n",
    "# df_ocho.head()\n",
    "# df_ocho[[\"bill_length_mm\",\"bill_depth_mm\"]].null_count() ## ➡️ Cantidad de Valores Nulos\n",
    "nulos_consecutivos = df_ocho.filter(\n",
    "    (pl.col(\"bill_length_mm\").is_null() & pl.col(\"bill_depth_mm\").is_null())\n",
    ")\n",
    "# nulos_consecutivos.head() ## ⬅️ Verificamos nulos simulares en ambas columnas\n",
    "# nulos_consecutivos.shape[0] ## ⬅️ Cantidad de nulos simulares en ambas columnas: 2\n",
    "\n",
    "#--- En caso no haya entendido el concepto, te dejo este otro ejemplo 👍.\n",
    "df_example = pl.DataFrame(data=[[1,None],[None,2],[None,None]],schema=[\"A\",\"B\"],orient=\"row\")\n",
    "# df_example.head() ## ⬅️ Verificamos que existen nulos en columnas similares\n",
    "nulos_consecutivos_2 = df_example.filter(\n",
    "    (pl.col(\"A\").is_null() & pl.col(\"B\").is_null())\n",
    ")\n",
    "# nulos_consecutivos_2.head() ## ⬅️ Verificamos nulos simulares en ambas columnas\n",
    "nulos_consecutivos_2.shape[0] ## ⬅️ Cantidad de nulos simulares en ambas columnas: 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cb401c5",
   "metadata": {},
   "source": [
    "## ⚡ Analítica Turbo con Polars: Fundamentos que todo Analista Moderno debe conocer 🐻‍❄️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba008a1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "👨‍💻 Autor: Brayan Neciosup  \n",
    "📍 Portafolio: [brayanneciosup](https://bryanneciosup626.wixsite.com/brayandataanalitics)  \n",
    "🔗 LinkedIn: [linkedin.com/brayanneciosup](https://www.linkedin.com/in/brayan-rafael-neciosup-bola%C3%B1os-407a59246/)  \n",
    "💻 GitHub: [github.com/BrayanR03](https://github.com/BrayanR03)  \n",
    "📚 Serie: Fundamentos de Pandas y Polars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c231f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar librería de polars: pip install polars\n",
    "# Importamos la librería\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80701532",
   "metadata": {},
   "source": [
    "### 📌 Manipulación de Datos en Polars: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b3078e",
   "metadata": {},
   "source": [
    "La manipulación de datos, también conocida como data wrangling, es una fase \n",
    "fundamental en todo proyecto de análisis de datos. Consiste en transformar \n",
    "un dataset crudo, es decir, datos en su forma original, posiblemente desordenada o\n",
    "incompleta en un formato estructurado y útil, como un DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3be9c10",
   "metadata": {},
   "source": [
    "#### Fase 1. Fuentes de Datos 🗃️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581dd6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Polars 🐻‍❄️ permite leer datos desde múltiples fuentes como archivos CSV, Excel, JSON, \n",
    "    bases de datos SQL, entre otros formatos comunes. Esta flexibilidad facilita el trabajo\n",
    "    con datasets provenientes de distintos orígenes, tanto locales como remotos de manera optimizada.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "503d90ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eventos_logs.json', 'json_basico.json', 'Pedidos.xlsx', 'penguins.csv', 'titanic.csv']\n"
     ]
    }
   ],
   "source": [
    "# Paso A). DEFINIR LA CARPETA ORIGEN DE DONDE PROVIENE NUESTROS DATASETS (LOCAL)\n",
    "\"\"\"\n",
    "    📝 SINTAXIS: \n",
    "        \n",
    "        carpeta_origen = \"RutaCarpetaOrigen\"\n",
    "    \n",
    "    ### 🧠 Va a depender en que entorno nos encontremos porque las rutas \n",
    "    ###     de carpetas pueden ser (\\) o (/).\n",
    "\"\"\"\n",
    "# 💡 EJEMPLO 1 (Ruta completa):\n",
    "\n",
    "# carpeta_origen = \"C:/Users/USER/Documents/FundamentosPandasPolars/datasets\" \n",
    "\n",
    "# print(carpeta_origen)\n",
    "\n",
    "# 💡 EJEMPLO 2 (Ruta relativa):\n",
    "\n",
    "carpeta_origen = f\"../datasets/\"\n",
    "# print(carpeta_origen)\n",
    "import os # ⬅️ Permite trabajar con archivos\n",
    "print(os.listdir(carpeta_origen)) # ⬅️ Mostrar los archivos de la carpeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d8968a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso B). DEFINIR EL NOMBRE DEL ARCHIVO DEL DATASET\n",
    "\"\"\"\n",
    "    📝 SINTAXIS:\n",
    "    \n",
    "        nombre_archivo = \"NombreArchivo.extension\"\n",
    "\n",
    "    ### 🧠 Dependerá de la extensión del archivo para indicarle a Polars que función utilizar.\n",
    "\"\"\"\n",
    "# 💡 EJEMPLO 1 (.csv): \n",
    "archivos_csv = \"penguins.csv\"\n",
    "\n",
    "# 💡 EJEMPLO 2 (.xlsx): \n",
    "archivos_xlsx = \"Pedidos.xlsx\"\n",
    "\n",
    "# 💡 EJEMPLO 3 (.json): \n",
    "archivos_json = \"eventos_logs.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d64c3212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>evento.usuario_id</th><th>evento.accion</th><th>evento.timestamp</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;U846&quot;</td><td>&quot;compra&quot;</td><td>&quot;2025-05-25T21:07:47.202219Z&quot;</td></tr><tr><td>&quot;U321&quot;</td><td>&quot;registro&quot;</td><td>&quot;2025-05-23T11:50:47.202219Z&quot;</td></tr><tr><td>&quot;U813&quot;</td><td>&quot;login&quot;</td><td>&quot;2025-05-25T19:09:47.202219Z&quot;</td></tr><tr><td>&quot;U677&quot;</td><td>&quot;registro&quot;</td><td>&quot;2025-05-27T09:41:47.202219Z&quot;</td></tr><tr><td>&quot;U425&quot;</td><td>&quot;compra&quot;</td><td>&quot;2025-05-23T14:44:47.202219Z&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌───────────────────┬───────────────┬─────────────────────────────┐\n",
       "│ evento.usuario_id ┆ evento.accion ┆ evento.timestamp            │\n",
       "│ ---               ┆ ---           ┆ ---                         │\n",
       "│ str               ┆ str           ┆ str                         │\n",
       "╞═══════════════════╪═══════════════╪═════════════════════════════╡\n",
       "│ U846              ┆ compra        ┆ 2025-05-25T21:07:47.202219Z │\n",
       "│ U321              ┆ registro      ┆ 2025-05-23T11:50:47.202219Z │\n",
       "│ U813              ┆ login         ┆ 2025-05-25T19:09:47.202219Z │\n",
       "│ U677              ┆ registro      ┆ 2025-05-27T09:41:47.202219Z │\n",
       "│ U425              ┆ compra        ┆ 2025-05-23T14:44:47.202219Z │\n",
       "└───────────────────┴───────────────┴─────────────────────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paso C). LECTURA DE LOS ARCHIVOS (PASO A + PASO B)\n",
    "\"\"\"\n",
    "    ### 🧠 Para los archivos .csv, se recomienda conocer el separador o\n",
    "    ###     delimitador presente en el archivo e indicarle a Polars.\n",
    "\n",
    "    📝 SINTAXIS:\n",
    "    \n",
    "        dataset_nombre = pl.read_extensión(carpeta_origen+nombre_archivo.extensión)\n",
    "\"\"\"\n",
    "import polars as pl # ✅ No olvidar importar polars al inicio del notebook\n",
    "\n",
    "# 💡 EJEMPLO 1 (Lectura de .csv): \n",
    "\n",
    "dataset_csv = pl.read_csv(carpeta_origen+archivos_csv,separator=\",\") # ⬅️ Indicamos el delimitador en separator.\n",
    "# dataset_csv.head() # ⬅️ Función que permite leer y retornar los 5 primeros registros del archivo.\n",
    "\"\"\"===============================================================================================\"\"\"\n",
    "# 💡 EJEMPLO 2 (Lectura de .xlsx): \n",
    "\n",
    "dataset_excel = pl.read_excel(\n",
    "                 source=carpeta_origen+archivos_xlsx,\n",
    "                 sheet_name=\"Hoja1\") # ⬅️ Indicamos el nombre de la Hoja donde se encuentra\n",
    "                                     #     la información.\n",
    "# dataset_excel.head() # ⬅️ Función que permite leer y retornar los 5 primeros registros del archivo.\n",
    "\n",
    "\"\"\" ⚠️ En caso les arroje error sobre: \" requiered package 'fastexcel' not found \"\n",
    "       solo instalemos el módulo con: pip install fastexcel\n",
    "'\"\"\"\n",
    "# dataset_excel.head() # ⬅️ Función que permite leer y retornar los 5 primeros registros del archivo.\n",
    "\"\"\"===============================================================================================\"\"\"\n",
    "# 💡 EJEMPLO 3 (Lectura de .json):\n",
    "\n",
    "### Archivo básico JSON\n",
    "archivo_json_basico = \"json_basico.json\" # ⬅️ Nombre de archivo básico JSON\n",
    "dataset_json1 = pl.read_json(carpeta_origen+archivo_json_basico) # ⬅️ Lectura de JSON básico\n",
    "# dataset_json1.head()\n",
    "\n",
    "# Archivo complejo JSON\n",
    "import json # ⬅️ Utilizaremos la librería json para el aplanamiento del Archivo JSON complejo.\n",
    "archivo_json_complejo = \"eventos_logs.json\" # ⬅️ Nombre de archivo complejo JSON\n",
    "with open(carpeta_origen + archivo_json_complejo, \"r\", encoding=\"utf-8\") as file_data:\n",
    "    data_archivo_json_complejo = json.load(file_data)\n",
    "dataset_json2 = pl.json_normalize(data_archivo_json_complejo) # ⬅️ Lectura de archivo JSON complejo.\n",
    "dataset_json2.head() # ⬅️ Función que permite leer y retornar los 5 primeros registros del archivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af78c5f",
   "metadata": {},
   "source": [
    "#### Fase 2. Exploración Inicial 🔍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbeb76e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>species</th><th>island</th><th>bill_length_mm</th><th>bill_depth_mm</th><th>flipper_length_mm</th><th>body_mass_g</th><th>sex</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>39.1</td><td>18.7</td><td>181.0</td><td>3750.0</td><td>&quot;Male&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>39.5</td><td>17.4</td><td>186.0</td><td>3800.0</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>40.3</td><td>18.0</td><td>195.0</td><td>3250.0</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>36.7</td><td>19.3</td><td>193.0</td><td>3450.0</td><td>&quot;Female&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌─────────┬───────────┬────────────────┬───────────────┬───────────────────┬─────────────┬────────┐\n",
       "│ species ┆ island    ┆ bill_length_mm ┆ bill_depth_mm ┆ flipper_length_mm ┆ body_mass_g ┆ sex    │\n",
       "│ ---     ┆ ---       ┆ ---            ┆ ---           ┆ ---               ┆ ---         ┆ ---    │\n",
       "│ str     ┆ str       ┆ f64            ┆ f64           ┆ f64               ┆ f64         ┆ str    │\n",
       "╞═════════╪═══════════╪════════════════╪═══════════════╪═══════════════════╪═════════════╪════════╡\n",
       "│ Adelie  ┆ Torgersen ┆ 39.1           ┆ 18.7          ┆ 181.0             ┆ 3750.0      ┆ Male   │\n",
       "│ Adelie  ┆ Torgersen ┆ 39.5           ┆ 17.4          ┆ 186.0             ┆ 3800.0      ┆ Female │\n",
       "│ Adelie  ┆ Torgersen ┆ 40.3           ┆ 18.0          ┆ 195.0             ┆ 3250.0      ┆ Female │\n",
       "│ Adelie  ┆ Torgersen ┆ null           ┆ null          ┆ null              ┆ null        ┆ null   │\n",
       "│ Adelie  ┆ Torgersen ┆ 36.7           ┆ 19.3          ┆ 193.0             ┆ 3450.0      ┆ Female │\n",
       "└─────────┴───────────┴────────────────┴───────────────┴───────────────────┴─────────────┴────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Utilizaremos el dataset de penguins (dataset de Seaborn importado en un csv)\n",
    "\"\"\"\n",
    "df_penguins = pl.read_csv(\"../datasets/penguins.csv\",separator=\",\") # ⬅️ Accedemos al archivo en la carpeta datasets\n",
    "df_penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a712abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column_1</th><th>column_2</th><th>column_3</th><th>column_4</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;DetallePedidosPedidoID&quot;</td><td>&quot;PedidoFechaHoraRegistro&quot;</td><td>&quot;PedidoEstado&quot;</td><td>&quot;Total&quot;</td></tr><tr><td>&quot;1&quot;</td><td>&quot;2025-05-26 18:02:01.240&quot;</td><td>&quot;F&quot;</td><td>&quot;524361.11&quot;</td></tr><tr><td>&quot;2&quot;</td><td>&quot;2025-05-26 18:02:02.430&quot;</td><td>&quot;F&quot;</td><td>&quot;524387.46&quot;</td></tr><tr><td>&quot;3&quot;</td><td>&quot;2025-05-26 18:02:46.287&quot;</td><td>&quot;F&quot;</td><td>&quot;515269.86&quot;</td></tr><tr><td>&quot;4&quot;</td><td>&quot;2025-05-26 18:02:46.290&quot;</td><td>&quot;F&quot;</td><td>&quot;523261.27&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌────────────────────────┬─────────────────────────┬──────────────┬───────────┐\n",
       "│ column_1               ┆ column_2                ┆ column_3     ┆ column_4  │\n",
       "│ ---                    ┆ ---                     ┆ ---          ┆ ---       │\n",
       "│ str                    ┆ str                     ┆ str          ┆ str       │\n",
       "╞════════════════════════╪═════════════════════════╪══════════════╪═══════════╡\n",
       "│ DetallePedidosPedidoID ┆ PedidoFechaHoraRegistro ┆ PedidoEstado ┆ Total     │\n",
       "│ 1                      ┆ 2025-05-26 18:02:01.240 ┆ F            ┆ 524361.11 │\n",
       "│ 2                      ┆ 2025-05-26 18:02:02.430 ┆ F            ┆ 524387.46 │\n",
       "│ 3                      ┆ 2025-05-26 18:02:46.287 ┆ F            ┆ 515269.86 │\n",
       "│ 4                      ┆ 2025-05-26 18:02:46.290 ┆ F            ┆ 523261.27 │\n",
       "└────────────────────────┴─────────────────────────┴──────────────┴───────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    A). Quitar encabezados originales provenientes del Dataset.\n",
    "    \n",
    "        📝 SINTAXIS:\n",
    "        \n",
    "            dataset_nombre = pl.read_extension(ruta_carpeta_archivo,separator=\"Delimitador\",has_header=True|False)\n",
    "            \n",
    "            💡 Importante: has_header, es el parámetro que si establecemos en False, los encabezados se vuelven parte\n",
    "                           de los registros del dataset, además, Polars agregará la posición de cada columna\n",
    "                           con un prefijo: columna_posición.\n",
    "                                        \n",
    "            ### 🧠 Tener en cuenta que solo se aplicará a las extensiones .excel y .csv\n",
    "    \n",
    "#### PARA LOS EJEMPLOS USAREMOS ALGUNOS DATASET PREVIAMENTE VISTOS EN LA FASE 1.\n",
    "\"\"\"\n",
    "\n",
    "# 💡 EJEMPLO 1: Archivo CSV \n",
    "\n",
    "df_penguins = pl.read_csv(carpeta_origen+archivos_csv,separator=\",\",has_header=True) #⬅️ Mostramos los encabezados\n",
    "# df_penguins.head()\n",
    "\n",
    "# 💡 EJEMPLO 2: Archivo CSV\n",
    "\n",
    "df_penguins = pl.read_csv(carpeta_origen+archivos_csv,separator=\",\",has_header=False) #⬅️ Ocultamos los encabezados\n",
    "# df_penguins.head()\n",
    "\n",
    "# 💡 EJEMPLO 3: Archivo EXCEL \n",
    "\n",
    "df_penguins_excel = pl.read_excel(carpeta_origen+archivos_xlsx,sheet_name=\"Hoja1\",has_header=True) #⬅️ Mostramos los encabezados\n",
    "# df_penguins_excel.head()\n",
    "\n",
    "# 💡 EJEMPLO 4: Archivo EXCEL\n",
    "\n",
    "df_penguins_excel = pl.read_excel(carpeta_origen+archivos_xlsx,sheet_name=\"Hoja1\",has_header=False) #⬅️ Ocultamos los encabezados\n",
    "df_penguins_excel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90290b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column_1</th><th>column_2</th><th>column_3</th><th>column_4</th><th>column_5</th><th>column_6</th><th>column_7</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;species&quot;</td><td>&quot;island&quot;</td><td>&quot;bill_length_mm&quot;</td><td>&quot;bill_depth_mm&quot;</td><td>&quot;flipper_length_mm&quot;</td><td>&quot;body_mass_g&quot;</td><td>&quot;sex&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>&quot;39.1&quot;</td><td>&quot;18.7&quot;</td><td>&quot;181.0&quot;</td><td>&quot;3750.0&quot;</td><td>&quot;Male&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>&quot;39.5&quot;</td><td>&quot;17.4&quot;</td><td>&quot;186.0&quot;</td><td>&quot;3800.0&quot;</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>&quot;40.3&quot;</td><td>&quot;18.0&quot;</td><td>&quot;195.0&quot;</td><td>&quot;3250.0&quot;</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>&quot;36.7&quot;</td><td>&quot;19.3&quot;</td><td>&quot;193.0&quot;</td><td>&quot;3450.0&quot;</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>&quot;39.3&quot;</td><td>&quot;20.6&quot;</td><td>&quot;190.0&quot;</td><td>&quot;3650.0&quot;</td><td>&quot;Male&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>&quot;38.9&quot;</td><td>&quot;17.8&quot;</td><td>&quot;181.0&quot;</td><td>&quot;3625.0&quot;</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>&quot;39.2&quot;</td><td>&quot;19.6&quot;</td><td>&quot;195.0&quot;</td><td>&quot;4675.0&quot;</td><td>&quot;Male&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>&quot;34.1&quot;</td><td>&quot;18.1&quot;</td><td>&quot;193.0&quot;</td><td>&quot;3475.0&quot;</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 7)\n",
       "┌──────────┬───────────┬────────────────┬───────────────┬─────────────────┬─────────────┬──────────┐\n",
       "│ column_1 ┆ column_2  ┆ column_3       ┆ column_4      ┆ column_5        ┆ column_6    ┆ column_7 │\n",
       "│ ---      ┆ ---       ┆ ---            ┆ ---           ┆ ---             ┆ ---         ┆ ---      │\n",
       "│ str      ┆ str       ┆ str            ┆ str           ┆ str             ┆ str         ┆ str      │\n",
       "╞══════════╪═══════════╪════════════════╪═══════════════╪═════════════════╪═════════════╪══════════╡\n",
       "│ species  ┆ island    ┆ bill_length_mm ┆ bill_depth_mm ┆ flipper_length_ ┆ body_mass_g ┆ sex      │\n",
       "│          ┆           ┆                ┆               ┆ mm              ┆             ┆          │\n",
       "│ Adelie   ┆ Torgersen ┆ 39.1           ┆ 18.7          ┆ 181.0           ┆ 3750.0      ┆ Male     │\n",
       "│ Adelie   ┆ Torgersen ┆ 39.5           ┆ 17.4          ┆ 186.0           ┆ 3800.0      ┆ Female   │\n",
       "│ Adelie   ┆ Torgersen ┆ 40.3           ┆ 18.0          ┆ 195.0           ┆ 3250.0      ┆ Female   │\n",
       "│ Adelie   ┆ Torgersen ┆ null           ┆ null          ┆ null            ┆ null        ┆ null     │\n",
       "│ Adelie   ┆ Torgersen ┆ 36.7           ┆ 19.3          ┆ 193.0           ┆ 3450.0      ┆ Female   │\n",
       "│ Adelie   ┆ Torgersen ┆ 39.3           ┆ 20.6          ┆ 190.0           ┆ 3650.0      ┆ Male     │\n",
       "│ Adelie   ┆ Torgersen ┆ 38.9           ┆ 17.8          ┆ 181.0           ┆ 3625.0      ┆ Female   │\n",
       "│ Adelie   ┆ Torgersen ┆ 39.2           ┆ 19.6          ┆ 195.0           ┆ 4675.0      ┆ Male     │\n",
       "│ Adelie   ┆ Torgersen ┆ 34.1           ┆ 18.1          ┆ 193.0           ┆ 3475.0      ┆ null     │\n",
       "└──────────┴───────────┴────────────────┴───────────────┴─────────────────┴─────────────┴──────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    B). Mostrar los N primeros registros de un dataset\n",
    "    \n",
    "        📝 SINTAXIS:\n",
    "    \n",
    "            dataset_nombre.head(NúmeroDeRegistros) ⬅️ Indicamos un número para la cantidad de registros a mostrar    \n",
    "\"\"\"\n",
    "# 💡 EJEMPO 1: \n",
    "\n",
    "# df_penguins.head(5) ## ⬅️ Mostrar 5 primeros registros del dataset\n",
    "\n",
    "# 💡 EJEMPO 2: \n",
    "\n",
    "df_penguins.head(10) ## ⬅️ Mostrar 10 primeros registros del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70b98fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column_1</th><th>column_2</th><th>column_3</th><th>column_4</th><th>column_5</th><th>column_6</th><th>column_7</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Gentoo&quot;</td><td>&quot;Biscoe&quot;</td><td>&quot;46.2&quot;</td><td>&quot;14.1&quot;</td><td>&quot;217.0&quot;</td><td>&quot;4375.0&quot;</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Gentoo&quot;</td><td>&quot;Biscoe&quot;</td><td>&quot;55.1&quot;</td><td>&quot;16.0&quot;</td><td>&quot;230.0&quot;</td><td>&quot;5850.0&quot;</td><td>&quot;Male&quot;</td></tr><tr><td>&quot;Gentoo&quot;</td><td>&quot;Biscoe&quot;</td><td>&quot;44.5&quot;</td><td>&quot;15.7&quot;</td><td>&quot;217.0&quot;</td><td>&quot;4875.0&quot;</td><td>null</td></tr><tr><td>&quot;Gentoo&quot;</td><td>&quot;Biscoe&quot;</td><td>&quot;48.8&quot;</td><td>&quot;16.2&quot;</td><td>&quot;222.0&quot;</td><td>&quot;6000.0&quot;</td><td>&quot;Male&quot;</td></tr><tr><td>&quot;Gentoo&quot;</td><td>&quot;Biscoe&quot;</td><td>&quot;47.2&quot;</td><td>&quot;13.7&quot;</td><td>&quot;214.0&quot;</td><td>&quot;4925.0&quot;</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Gentoo&quot;</td><td>&quot;Biscoe&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;Gentoo&quot;</td><td>&quot;Biscoe&quot;</td><td>&quot;46.8&quot;</td><td>&quot;14.3&quot;</td><td>&quot;215.0&quot;</td><td>&quot;4850.0&quot;</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Gentoo&quot;</td><td>&quot;Biscoe&quot;</td><td>&quot;50.4&quot;</td><td>&quot;15.7&quot;</td><td>&quot;222.0&quot;</td><td>&quot;5750.0&quot;</td><td>&quot;Male&quot;</td></tr><tr><td>&quot;Gentoo&quot;</td><td>&quot;Biscoe&quot;</td><td>&quot;45.2&quot;</td><td>&quot;14.8&quot;</td><td>&quot;212.0&quot;</td><td>&quot;5200.0&quot;</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Gentoo&quot;</td><td>&quot;Biscoe&quot;</td><td>&quot;49.9&quot;</td><td>&quot;16.1&quot;</td><td>&quot;213.0&quot;</td><td>&quot;5400.0&quot;</td><td>&quot;Male&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 7)\n",
       "┌──────────┬──────────┬──────────┬──────────┬──────────┬──────────┬──────────┐\n",
       "│ column_1 ┆ column_2 ┆ column_3 ┆ column_4 ┆ column_5 ┆ column_6 ┆ column_7 │\n",
       "│ ---      ┆ ---      ┆ ---      ┆ ---      ┆ ---      ┆ ---      ┆ ---      │\n",
       "│ str      ┆ str      ┆ str      ┆ str      ┆ str      ┆ str      ┆ str      │\n",
       "╞══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
       "│ Gentoo   ┆ Biscoe   ┆ 46.2     ┆ 14.1     ┆ 217.0    ┆ 4375.0   ┆ Female   │\n",
       "│ Gentoo   ┆ Biscoe   ┆ 55.1     ┆ 16.0     ┆ 230.0    ┆ 5850.0   ┆ Male     │\n",
       "│ Gentoo   ┆ Biscoe   ┆ 44.5     ┆ 15.7     ┆ 217.0    ┆ 4875.0   ┆ null     │\n",
       "│ Gentoo   ┆ Biscoe   ┆ 48.8     ┆ 16.2     ┆ 222.0    ┆ 6000.0   ┆ Male     │\n",
       "│ Gentoo   ┆ Biscoe   ┆ 47.2     ┆ 13.7     ┆ 214.0    ┆ 4925.0   ┆ Female   │\n",
       "│ Gentoo   ┆ Biscoe   ┆ null     ┆ null     ┆ null     ┆ null     ┆ null     │\n",
       "│ Gentoo   ┆ Biscoe   ┆ 46.8     ┆ 14.3     ┆ 215.0    ┆ 4850.0   ┆ Female   │\n",
       "│ Gentoo   ┆ Biscoe   ┆ 50.4     ┆ 15.7     ┆ 222.0    ┆ 5750.0   ┆ Male     │\n",
       "│ Gentoo   ┆ Biscoe   ┆ 45.2     ┆ 14.8     ┆ 212.0    ┆ 5200.0   ┆ Female   │\n",
       "│ Gentoo   ┆ Biscoe   ┆ 49.9     ┆ 16.1     ┆ 213.0    ┆ 5400.0   ┆ Male     │\n",
       "└──────────┴──────────┴──────────┴──────────┴──────────┴──────────┴──────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    C). Mostrar los N últimos registros de un dataset\n",
    "    \n",
    "        📝 SINTAXIS:\n",
    "    \n",
    "            dataset_nombre.tail(NúmeroDeRegistros) ⬅️ Indicamos un número para la cantidad de registros a mostrar    \n",
    "\"\"\"\n",
    "# 💡 EJEMPO 1: \n",
    "\n",
    "# df_penguins.tail(5) ## ⬅️ Mostrar 5 últimos registros del dataset\n",
    "\n",
    "# 💡 EJEMPO 2: \n",
    "\n",
    "df_penguins.tail(10) ## ⬅️ Mostrar 10 últimos registros del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73203557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    D). Mostrar el volúmen del dataset (Cantidad de filas y columnas respectivamente) \n",
    "    \n",
    "        📝 SINTAXIS:\n",
    "    \n",
    "            dataset_nombre.shape ⬅️ Nos muestra la cantidad de filas y columnas en forma de tupla (,)\n",
    "            \n",
    "            #### 🧠 Podemos acceder a la cantidad de filas o columnas basándonos en la posición\n",
    "                     de los datos que retorna la tupla, gracias a .shape ➡️ 0 = filas y 1 = columnas    \n",
    "\"\"\"\n",
    "# 💡 EJEMPO 1: \n",
    "\n",
    "df_penguins.shape ## ⬅️ Muestra el volúmen de registros del dataset en forma de tupla. (CantidadFilas,CantidadColumnas)\n",
    "\n",
    "# 💡 EJEMPO 2: \n",
    "\n",
    "df_penguins.shape[0] ## ⬅️ Muestra la cantidad de registros (filas) del dataset\n",
    "\n",
    "# 💡 EJEMPO 3: \n",
    "\n",
    "df_penguins.shape[1] ## ⬅️ Muestra la cantidad de columnas del dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f697ed18",
   "metadata": {},
   "source": [
    "#### Fase 3. Transformación de Datos 💱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ba8720",
   "metadata": {},
   "source": [
    "##### 3.1 Datos Cualitativos 🔠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2937a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>species</th><th>island</th><th>bill_length_mm</th><th>bill_depth_mm</th><th>flipper_length_mm</th><th>body_mass_g</th><th>sex</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>&quot;ADELIE&quot;</td><td>&quot;Torgersen&quot;</td><td>39.1</td><td>18.7</td><td>181.0</td><td>3750.0</td><td>&quot;Male&quot;</td></tr><tr><td>&quot;ADELIE&quot;</td><td>&quot;Torgersen&quot;</td><td>39.5</td><td>17.4</td><td>186.0</td><td>3800.0</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;ADELIE&quot;</td><td>&quot;Torgersen&quot;</td><td>40.3</td><td>18.0</td><td>195.0</td><td>3250.0</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;ADELIE&quot;</td><td>&quot;Torgersen&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;ADELIE&quot;</td><td>&quot;Torgersen&quot;</td><td>36.7</td><td>19.3</td><td>193.0</td><td>3450.0</td><td>&quot;Female&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌─────────┬───────────┬────────────────┬───────────────┬───────────────────┬─────────────┬────────┐\n",
       "│ species ┆ island    ┆ bill_length_mm ┆ bill_depth_mm ┆ flipper_length_mm ┆ body_mass_g ┆ sex    │\n",
       "│ ---     ┆ ---       ┆ ---            ┆ ---           ┆ ---               ┆ ---         ┆ ---    │\n",
       "│ str     ┆ str       ┆ f64            ┆ f64           ┆ f64               ┆ f64         ┆ str    │\n",
       "╞═════════╪═══════════╪════════════════╪═══════════════╪═══════════════════╪═════════════╪════════╡\n",
       "│ ADELIE  ┆ Torgersen ┆ 39.1           ┆ 18.7          ┆ 181.0             ┆ 3750.0      ┆ Male   │\n",
       "│ ADELIE  ┆ Torgersen ┆ 39.5           ┆ 17.4          ┆ 186.0             ┆ 3800.0      ┆ Female │\n",
       "│ ADELIE  ┆ Torgersen ┆ 40.3           ┆ 18.0          ┆ 195.0             ┆ 3250.0      ┆ Female │\n",
       "│ ADELIE  ┆ Torgersen ┆ null           ┆ null          ┆ null              ┆ null        ┆ null   │\n",
       "│ ADELIE  ┆ Torgersen ┆ 36.7           ┆ 19.3          ┆ 193.0             ┆ 3450.0      ┆ Female │\n",
       "└─────────┴───────────┴────────────────┴───────────────┴───────────────────┴─────────────┴────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    A). CONVERTIR A MAYÚSCULAS LOS DATOS CUALITATIVOS DE UNA COLUMNA EN UN DATASET\n",
    "    \n",
    "    📝 SINTAXIS:\n",
    "    \n",
    "        dataframe_nombre = dataframe_nombre.with_columns(\n",
    "            pl.col(NombreColumnaCualitativa).str.to_uppercase().alias(NombreColumnaCualitativa) \n",
    "        )\n",
    "    \n",
    "    ### 🧠 En este caso, debemos almacenar en una variable los cambios a realizar en el dataframe.\n",
    "\"\"\"\n",
    "\n",
    "# 💡 EJEMPLO:\n",
    "\n",
    "df_penguins = df_penguins.with_columns(\n",
    "    pl.col(\"species\").str.to_uppercase().alias(\"species\") ## ⬅️ Convertimos a mayúsculas los datos de la columna cualitativa \"\"species\"\"\n",
    ")\n",
    "df_penguins.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99166e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>species</th><th>island</th><th>bill_length_mm</th><th>bill_depth_mm</th><th>flipper_length_mm</th><th>body_mass_g</th><th>sex</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>&quot;adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>39.1</td><td>18.7</td><td>181.0</td><td>3750.0</td><td>&quot;Male&quot;</td></tr><tr><td>&quot;adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>39.5</td><td>17.4</td><td>186.0</td><td>3800.0</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>40.3</td><td>18.0</td><td>195.0</td><td>3250.0</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>36.7</td><td>19.3</td><td>193.0</td><td>3450.0</td><td>&quot;Female&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌─────────┬───────────┬────────────────┬───────────────┬───────────────────┬─────────────┬────────┐\n",
       "│ species ┆ island    ┆ bill_length_mm ┆ bill_depth_mm ┆ flipper_length_mm ┆ body_mass_g ┆ sex    │\n",
       "│ ---     ┆ ---       ┆ ---            ┆ ---           ┆ ---               ┆ ---         ┆ ---    │\n",
       "│ str     ┆ str       ┆ f64            ┆ f64           ┆ f64               ┆ f64         ┆ str    │\n",
       "╞═════════╪═══════════╪════════════════╪═══════════════╪═══════════════════╪═════════════╪════════╡\n",
       "│ adelie  ┆ Torgersen ┆ 39.1           ┆ 18.7          ┆ 181.0             ┆ 3750.0      ┆ Male   │\n",
       "│ adelie  ┆ Torgersen ┆ 39.5           ┆ 17.4          ┆ 186.0             ┆ 3800.0      ┆ Female │\n",
       "│ adelie  ┆ Torgersen ┆ 40.3           ┆ 18.0          ┆ 195.0             ┆ 3250.0      ┆ Female │\n",
       "│ adelie  ┆ Torgersen ┆ null           ┆ null          ┆ null              ┆ null        ┆ null   │\n",
       "│ adelie  ┆ Torgersen ┆ 36.7           ┆ 19.3          ┆ 193.0             ┆ 3450.0      ┆ Female │\n",
       "└─────────┴───────────┴────────────────┴───────────────┴───────────────────┴─────────────┴────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    B). CONVERTIR A MINÚSCULAS LOS DATOS CUALITATIVOS DE UNA COLUMNA EN UN DATASET\n",
    "    \n",
    "    📝 SINTAXIS:\n",
    "    \n",
    "        dataframe_nombre = dataframe_nombre.with_columns(\n",
    "            pl.col(NombreColumnaCualitativa).str.to_lowercase().alias(NombreColumnaCualitativa) \n",
    "        )\n",
    "    \n",
    "    ### 🧠 En este caso, debemos almacenar en una variable los cambios a realizar en el dataframe.\n",
    "\"\"\"\n",
    "\n",
    "# 💡 EJEMPLO:\n",
    "\n",
    "df_penguins = df_penguins.with_columns(\n",
    "    pl.col(\"species\").str.to_lowercase().alias(\"species\") ## ⬅️ Convertimos a minúsculas los datos de la columna cualitativa \"\"species\"\"\n",
    ")\n",
    "df_penguins.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e585f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>species</th><th>island</th><th>bill_length_mm</th><th>bill_depth_mm</th><th>flipper_length_mm</th><th>body_mass_g</th><th>sex</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>39.1</td><td>18.7</td><td>181.0</td><td>3750.0</td><td>&quot;Male&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>39.5</td><td>17.4</td><td>186.0</td><td>3800.0</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>40.3</td><td>18.0</td><td>195.0</td><td>3250.0</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>36.7</td><td>19.3</td><td>193.0</td><td>3450.0</td><td>&quot;Female&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌─────────┬───────────┬────────────────┬───────────────┬───────────────────┬─────────────┬────────┐\n",
       "│ species ┆ island    ┆ bill_length_mm ┆ bill_depth_mm ┆ flipper_length_mm ┆ body_mass_g ┆ sex    │\n",
       "│ ---     ┆ ---       ┆ ---            ┆ ---           ┆ ---               ┆ ---         ┆ ---    │\n",
       "│ str     ┆ str       ┆ f64            ┆ f64           ┆ f64               ┆ f64         ┆ str    │\n",
       "╞═════════╪═══════════╪════════════════╪═══════════════╪═══════════════════╪═════════════╪════════╡\n",
       "│ Adelie  ┆ Torgersen ┆ 39.1           ┆ 18.7          ┆ 181.0             ┆ 3750.0      ┆ Male   │\n",
       "│ Adelie  ┆ Torgersen ┆ 39.5           ┆ 17.4          ┆ 186.0             ┆ 3800.0      ┆ Female │\n",
       "│ Adelie  ┆ Torgersen ┆ 40.3           ┆ 18.0          ┆ 195.0             ┆ 3250.0      ┆ Female │\n",
       "│ Adelie  ┆ Torgersen ┆ null           ┆ null          ┆ null              ┆ null        ┆ null   │\n",
       "│ Adelie  ┆ Torgersen ┆ 36.7           ┆ 19.3          ┆ 193.0             ┆ 3450.0      ┆ Female │\n",
       "└─────────┴───────────┴────────────────┴───────────────┴───────────────────┴─────────────┴────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    C). CONVERTIR A MAYÚSCULA LA PRIMERA LETRA DE CADA DATO CUALITATIVOS DE UNA COLUMNA EN UN DATASET\n",
    "    \n",
    "    📝 SINTAXIS:\n",
    "    \n",
    "        dataframe_nombre = dataframe_nombre.with_columns(\n",
    "            pl.col(NombreColumnaCualitativa).str.to_titlecase().alias(NombreColumnaCualitativa) \n",
    "        )\n",
    "    \n",
    "    ### 🧠 En este caso, debemos almacenar en una variable los cambios a realizar en el dataframe.\n",
    "\"\"\"\n",
    "\n",
    "# 💡 EJEMPLO:\n",
    "\n",
    "df_penguins = df_penguins.with_columns(\n",
    "    pl.col(\"species\").str.to_titlecase().alias(\"species\") ## ⬅️ Convertimos la primera letra en mayúscula de cada dato en la columna cualitativa \"\"species\"\"\n",
    ")\n",
    "df_penguins.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77554794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>species</th><th>island</th><th>bill_length_mm</th><th>bill_depth_mm</th><th>flipper_length_mm</th><th>body_mass_g</th><th>sex</th><th>PrimeraLetraEnMayúscula</th><th>PrimeraLetraEnMinúscula</th><th>TodoDespuesDeUnaMayúscula</th><th>TodoDespuesDeUnaMinúscula</th><th>TodoDespuesDeUnNúmero</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>39.1</td><td>18.7</td><td>181.0</td><td>3750.0</td><td>&quot;Male&quot;</td><td>&quot;A&quot;</td><td>&quot;d&quot;</td><td>&quot;delie&quot;</td><td>&quot;&quot;</td><td>null</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>39.5</td><td>17.4</td><td>186.0</td><td>3800.0</td><td>&quot;Female&quot;</td><td>&quot;A&quot;</td><td>&quot;d&quot;</td><td>&quot;delie&quot;</td><td>&quot;&quot;</td><td>null</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>40.3</td><td>18.0</td><td>195.0</td><td>3250.0</td><td>&quot;Female&quot;</td><td>&quot;A&quot;</td><td>&quot;d&quot;</td><td>&quot;delie&quot;</td><td>&quot;&quot;</td><td>null</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;A&quot;</td><td>&quot;d&quot;</td><td>&quot;delie&quot;</td><td>&quot;&quot;</td><td>null</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>36.7</td><td>19.3</td><td>193.0</td><td>3450.0</td><td>&quot;Female&quot;</td><td>&quot;A&quot;</td><td>&quot;d&quot;</td><td>&quot;delie&quot;</td><td>&quot;&quot;</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 12)\n",
       "┌─────────┬───────────┬────────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ species ┆ island    ┆ bill_lengt ┆ bill_dept ┆ … ┆ PrimeraLe ┆ TodoDespu ┆ TodoDespu ┆ TodoDespu │\n",
       "│ ---     ┆ ---       ┆ h_mm       ┆ h_mm      ┆   ┆ traEnMinú ┆ esDeUnaMa ┆ esDeUnaMi ┆ esDeUnNúm │\n",
       "│ str     ┆ str       ┆ ---        ┆ ---       ┆   ┆ scula     ┆ yúscula   ┆ núscula   ┆ ero       │\n",
       "│         ┆           ┆ f64        ┆ f64       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│         ┆           ┆            ┆           ┆   ┆ str       ┆ str       ┆ str       ┆ str       │\n",
       "╞═════════╪═══════════╪════════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ Adelie  ┆ Torgersen ┆ 39.1       ┆ 18.7      ┆ … ┆ d         ┆ delie     ┆           ┆ null      │\n",
       "│ Adelie  ┆ Torgersen ┆ 39.5       ┆ 17.4      ┆ … ┆ d         ┆ delie     ┆           ┆ null      │\n",
       "│ Adelie  ┆ Torgersen ┆ 40.3       ┆ 18.0      ┆ … ┆ d         ┆ delie     ┆           ┆ null      │\n",
       "│ Adelie  ┆ Torgersen ┆ null       ┆ null      ┆ … ┆ d         ┆ delie     ┆           ┆ null      │\n",
       "│ Adelie  ┆ Torgersen ┆ 36.7       ┆ 19.3      ┆ … ┆ d         ┆ delie     ┆           ┆ null      │\n",
       "└─────────┴───────────┴────────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    D). EXTRAER DE CADA DATO CUALITATIVO UNA CADENA EN ESPECÍFICO MEDIANTE >>EXPRESIONES REGULARES<< EN UN DATASET\n",
    "    \n",
    "    📝 SINTAXIS:\n",
    "    \n",
    "        dataset_nombre[NombreColumnaCualitativa].str.extract()\n",
    "    \n",
    "    ### 🧠 En este caso, debemos almacenar en una variable los cambios a realizar en el dataframe\n",
    "\"\"\"\n",
    "##💡 EJEMPLO 1: ⬅️ Extraemos primera letra en mayúscula \n",
    "df_penguins = df_penguins.with_columns(\n",
    "    pl.col(\"species\").str.extract(r'([A-Z])').alias(\"PrimeraLetraEnMayúscula\")\n",
    ")\n",
    "# df_penguins.head()\n",
    "\n",
    "##💡 EJEMPLO 2: ⬅️ Extraemos primera letra en minúscula \n",
    "df_penguins = df_penguins.with_columns(\n",
    "    pl.col(\"species\").str.extract(r'([a-z])').alias(\"PrimeraLetraEnMinúscula\")\n",
    ")\n",
    "# df_penguins.head()\n",
    "\n",
    "##💡 EJEMPLO 3: ⬅️ Retornamos todo después de una letra en mayúscula\n",
    "df_penguins = df_penguins.with_columns(\n",
    "    pl.col(\"species\").str.extract(r'[A-Z]+(.*)').alias(\"TodoDespuesDeUnaMayúscula\")\n",
    ")\n",
    "# df_penguins.head()\n",
    "\n",
    "##💡 EJEMPLO 4: ⬅️ Retornamos todo después de una letra en minúscula\n",
    "df_penguins = df_penguins.with_columns(\n",
    "    pl.col(\"species\").str.extract(r'[a-z]+(.*)').alias(\"TodoDespuesDeUnaMinúscula\")\n",
    ")\n",
    "# df_penguins.head()\n",
    "\n",
    "##💡 EJEMPLO 5: ⬅️ Retornamos todo después de un número\n",
    "df_penguins = df_penguins.with_columns(\n",
    "    pl.col(\"species\").str.extract(r'[0-9]+(.*)').alias(\"TodoDespuesDeUnNúmero\")\n",
    ")\n",
    "df_penguins.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a487d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>nombre</th><th>categoria_producto</th><th>codigo</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot; JUAN pérez &quot;</td><td>&quot;ELECTRÓNICA 1&quot;</td><td>&quot;0001&quot;</td></tr><tr><td>&quot;MARÍA LÓPEZ&quot;</td><td>&quot;ropa Mujer&quot;</td><td>&quot;0023&quot;</td></tr><tr><td>&quot;Ana Martínez&quot;</td><td>&quot;hogar y DECORACIÓN&quot;</td><td>&quot;1234&quot;</td></tr><tr><td>&quot;carlos rodríguez &quot;</td><td>&quot;LIBROS &quot;</td><td>&quot;123&quot;</td></tr><tr><td>&quot;Sofía García&quot;</td><td>&quot;Juguetes niños&quot;</td><td>&quot;9999&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌───────────────────┬────────────────────┬────────┐\n",
       "│ nombre            ┆ categoria_producto ┆ codigo │\n",
       "│ ---               ┆ ---                ┆ ---    │\n",
       "│ str               ┆ str                ┆ str    │\n",
       "╞═══════════════════╪════════════════════╪════════╡\n",
       "│  JUAN pérez       ┆ ELECTRÓNICA 1      ┆ 0001   │\n",
       "│ MARÍA LÓPEZ       ┆ ropa Mujer         ┆ 0023   │\n",
       "│ Ana Martínez      ┆ hogar y DECORACIÓN ┆ 1234   │\n",
       "│ carlos rodríguez  ┆ LIBROS             ┆ 123    │\n",
       "│ Sofía García      ┆ Juguetes niños     ┆ 9999   │\n",
       "└───────────────────┴────────────────────┴────────┘"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    E). REEMPLAZAR VALORES DE DATOS CUALITATIVOS MEDIANTE >>EXPRESIONES REGULARES<< EN UN DATASET\n",
    "    \n",
    "    📝 SINTAXIS:\n",
    "    \n",
    "        dataset_nombre[NombreColumnaCualitativa].str.replace_all(pattern=PatrónExpresiónRegular,value=CadenaAReemplazar)\n",
    "    \n",
    "    ### 🧠 En este caso, debemos almacenar en una variable los cambios a realizar en el dataframe\n",
    "\"\"\"\n",
    "### DATASET DE PRUEBA PARA ESTE EJEMPLO\n",
    "datos_sucios = {\n",
    "    \"nombre\": [\n",
    "        \"  JUAN  pérez  \", \n",
    "        \"MARÍA@@LÓPEZ\", \n",
    "        \"Ana--Martínez\", \n",
    "        \"carlos_rodríguez \", \n",
    "        \"Sofía123 García\"\n",
    "    ],\n",
    "    \"categoria_producto\": [\n",
    "        \"ELECTRÓNICA#1\", \n",
    "        \"ropa--Mujer\", \n",
    "        \"hogar_y_DECORACIÓN\", \n",
    "        \"LIBROS@@\", \n",
    "        \"Juguetes  niños\"\n",
    "    ],\n",
    "    \"codigo\": [\n",
    "        \"ID-0001\", \n",
    "        \"ID-0023\", \n",
    "        \"CL-1234\", \n",
    "        \"ID-abc123\", \n",
    "        \"id-9999\"\n",
    "    ]\n",
    "}\n",
    "## Dataset de prueba (sucio)\n",
    "df_test = pl.DataFrame(datos_sucios)\n",
    "# df_test.head()\n",
    "\n",
    "## Dataset de prueba (limpio)\n",
    "df_test_clean = df_test \n",
    "\n",
    "## 💡 EJEMPLO 1: ⬅️ Eliminar caractéres especiales (@@,#,--,_)\n",
    "df_test_clean = df_test_clean.with_columns(\n",
    "    pl.col(\"categoria_producto\").str.replace_all(pattern=r'[^A-Za-z0-9ÁÉÍÓÚáéíóúÑñÜü]',value=\" \").alias(\"categoria_producto\"),\n",
    "    pl.col(\"nombre\").str.replace_all(pattern=r'[^A-Za-z0-9ÁÉÍÓÚáéíóúÑñÜü]',value=\" \").alias(\"nombre\")\n",
    ")\n",
    "# df_test_clean.head()\n",
    "\n",
    "## 💡 EJEMPLO 2: ⬅️ Normalizar espacios (Varios espacios en blanco a uno solo)\n",
    "df_test_clean = df_test_clean.with_columns(\n",
    "    pl.col(\"categoria_producto\").str.replace_all(pattern=r'\\s+',value=\" \").alias(\"categoria_producto\"),\n",
    "    pl.col(\"nombre\").str.replace_all(pattern=r'\\s+',value=\" \").alias(\"nombre\")\n",
    ")\n",
    "# df_test_clean.head()\n",
    "\n",
    "## 💡 EJEMPLO 3: ⬅️ Reemplazar guiones por espacios en blanco\n",
    "df_test_clean = df_test_clean.with_columns(\n",
    "    pl.col(\"nombre\").str.replace_all(pattern=r'[-_]',value=\" \").alias(\"nombre\")\n",
    ")\n",
    "# df_test_clean.head()\n",
    "\n",
    "## 💡 EJEMPLO 4: ⬅️ Eliminar prefijos (ID- || CL- || id- || Letras)\n",
    "df_test_clean = df_test_clean.with_columns(\n",
    "    pl.col(\"codigo\").str.replace_all(pattern=r'^ID-|CL-|id-|[A-Za-z]+',value=\"\").alias(\"codigo\")\n",
    ")\n",
    "df_test_clean.head()\n",
    "\n",
    "## 💡 EJEMPLO 5: ⬅️ Eliminar números dentro de cadenas\n",
    "df_test_clean = df_test_clean.with_columns(\n",
    "    pl.col(\"nombre\").str.replace_all(pattern=r'([0-9])',value=\"\").alias(\"nombre\")\n",
    ")\n",
    "df_test_clean.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422b82cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    F). ELIMINAR VALORES DUPLICADOS EN DATOS CUALITATIVOS DE UN DATASET\n",
    "    \n",
    "    📝 SINTAXIS:\n",
    "    \n",
    "        dataset_nombre.unique(subset=[NombreColumna1,NombreColumnaN],keep=\"first\" | \"last\" | \"any\" | None)\n",
    "        \n",
    "        keep: Es el parámetro que establece el valor que va a quedar de todos los duplicados \n",
    "              (Primer valor=first - Último valor=last - No mantenga filas duplicadas = any)\n",
    "              [En caso de no llamar al parámetro keep, se establece \"first\".]\n",
    "        \n",
    "    ### 🧠 En este caso, debemos trabajar sobre el mismo dataset/dataframe para eliminar los duplicados.\n",
    "\"\"\"\n",
    "### ✅🗃️ Dataset a utilizar: Diamonds\n",
    "import polars as pl\n",
    "df_diamonds = pl.read_csv(\"../datasets/diamonds.csv\",separator=\",\")\n",
    "# df_diamonds.head()\n",
    "# df_diamonds.shape[0] ## ⬅️ Cantidad de datos inicial: 53940\n",
    "\n",
    "## 💡 EJEMPLO 1: ELIMINAR VALORES DUPLICADOS DE TODO EL DATASET (keep=\"first\" por defecto)\n",
    "# df_diamonds = df_diamonds.unique()\n",
    "# df_diamonds.shape[0] ## ⬅️ Cantidad de datos restantes: 53794\n",
    "\n",
    "## 💡 EJEMPLO 2: ELIMINAR VALORES DUPLICADOS DE TODO EL DATASET (keep=\"last\")\n",
    "# df_diamonds = df_diamonds.unique(keep=\"last\") \n",
    "# df_diamonds.shape[0] ## ⬅️ Cantidad de datos restantes: 53794\n",
    "\n",
    "##💡 EJEMPLO 3: ELIMINAR VALORES DUPLICADOS DE UNA COLUMNA ESPECÍFICA (keep=\"first\" por defecto)\n",
    "# df_diamonds[\"carat\"].shape[0] ## ⬅️ Cantidad inicial de datos: 53940\n",
    "# df_diamonds = df_diamonds.unique(subset=[\"carat\"],keep=\"first\") \n",
    "# df_diamonds[\"carat\"].shape[0] ## ⬅️ Cantidad de datos restantes: 273   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3599e18b",
   "metadata": {},
   "source": [
    "##### 3.2 Datos Cuantitativos 🔢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb46f68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>species</th><th>island</th><th>bill_length_mm</th><th>bill_depth_mm</th><th>flipper_length_mm</th><th>body_mass_g</th><th>sex</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>39.1</td><td>18.7</td><td>181.0</td><td>3750.0</td><td>&quot;Male&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>39.5</td><td>17.4</td><td>186.0</td><td>3800.0</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>40.3</td><td>18.0</td><td>195.0</td><td>3250.0</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>36.7</td><td>19.3</td><td>193.0</td><td>3450.0</td><td>&quot;Female&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌─────────┬───────────┬────────────────┬───────────────┬───────────────────┬─────────────┬────────┐\n",
       "│ species ┆ island    ┆ bill_length_mm ┆ bill_depth_mm ┆ flipper_length_mm ┆ body_mass_g ┆ sex    │\n",
       "│ ---     ┆ ---       ┆ ---            ┆ ---           ┆ ---               ┆ ---         ┆ ---    │\n",
       "│ str     ┆ str       ┆ f64            ┆ f64           ┆ f64               ┆ f64         ┆ str    │\n",
       "╞═════════╪═══════════╪════════════════╪═══════════════╪═══════════════════╪═════════════╪════════╡\n",
       "│ Adelie  ┆ Torgersen ┆ 39.1           ┆ 18.7          ┆ 181.0             ┆ 3750.0      ┆ Male   │\n",
       "│ Adelie  ┆ Torgersen ┆ 39.5           ┆ 17.4          ┆ 186.0             ┆ 3800.0      ┆ Female │\n",
       "│ Adelie  ┆ Torgersen ┆ 40.3           ┆ 18.0          ┆ 195.0             ┆ 3250.0      ┆ Female │\n",
       "│ Adelie  ┆ Torgersen ┆ null           ┆ null          ┆ null              ┆ null        ┆ null   │\n",
       "│ Adelie  ┆ Torgersen ┆ 36.7           ┆ 19.3          ┆ 193.0             ┆ 3450.0      ┆ Female │\n",
       "└─────────┴───────────┴────────────────┴───────────────┴───────────────────┴─────────────┴────────┘"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_penguins = pl.read_csv(\"../datasets/penguins.csv\",separator=\",\") ## ⬅️ Para este ejemplo utilizaremos el dataset de \"\"\"penguins\"\"\"\n",
    "df_penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376c4372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "643131.077326748"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    A). EXPLORACIÓN BÁSICA Y RESUMEN ESTADÍSTICO\n",
    "        \n",
    "        📝 Para los datos cuantitativos podemos obtener su estadística básica\n",
    "            mediante .decribe() el cuál retornará el valor de las columnas float o int.\n",
    "            En los campos cualitativos se visualizará información no creíble.\n",
    "\"\"\"\n",
    "df_penguins.describe()                ## ⬅️ Estadística simple - Todas las columnas\n",
    "df_penguins[\"body_mass_g\"].describe() ## ⬅️ Estadística simple - Columna body_mass_g\n",
    "df_penguins[\"body_mass_g\"].mean()     ## ⬅️ Media estadística - Columna body_mass_g\n",
    "df_penguins[\"body_mass_g\"].median()   ## ⬅️ Mediana estadística - Columna body_mass_g\n",
    "df_penguins[\"body_mass_g\"].min()      ## ⬅️ Valor mínimo - Columna body_mass_g\n",
    "df_penguins[\"body_mass_g\"].max()      ## ⬅️ Valor máximo (IMC Gramos)\n",
    "df_penguins[\"body_mass_g\"].sum()      ## ⬅️ Suma total - Columna body_mass_g\n",
    "df_penguins[\"body_mass_g\"].std()      ## ⬅️ Desviación estándar - Columna body_mass_g\n",
    "df_penguins[\"body_mass_g\"].var()      ## ⬅️ Varianza - Columna body_mass_g\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12d55811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>body_mass_g</th></tr><tr><td>u32</td></tr></thead><tbody><tr><td>2</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 1)\n",
       "┌─────────────┐\n",
       "│ body_mass_g │\n",
       "│ ---         │\n",
       "│ u32         │\n",
       "╞═════════════╡\n",
       "│ 2           │\n",
       "└─────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    B). VERIFICAR VALORES NULOS EN LA(S) COLUMNA(AS) DEL DATASET\n",
    "        \n",
    "        🗒️SINTAXIS:\n",
    "    \n",
    "        dataset_nombre.isnull().sum() ⬅️ Para todo el dataset.\n",
    "        dataset_nombre[NombreColumna].isnull().sum() ⬅️ A nivel de columna\n",
    "\"\"\"\n",
    "\n",
    "## 💡 EJEMPLO 1: VERIFICAR CANTIDAD DE VALORES NULOS EN TODAS LAS COLUMNAS DEL DATASET\n",
    "df_penguins.null_count() ## ⬅️ Retorna la cantidad de datos nulos por columna.\n",
    "\n",
    "## 💡 EJEMPLO 2: VERIFICAR CANTIDAD DE VALORES NULOS EN UNA COLUMNA ESPECÍFICA DEL DATASET\n",
    "df_penguins[[\"body_mass_g\"]].null_count() ##⬅️ Retorna la cantidad de datos nulos de una columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91e67615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    C). FILTRANDO VALORES EN COLUMNAS CUANTITATIVAS\n",
    "\"\"\"\n",
    "\n",
    "df_penguins.shape[0] ## ⬅️ Cantidad de datos del dataset : 344\n",
    "\n",
    "## 💡 EJEMPLO 1: FILTRAR VALORES DE COLUMNA \"body_mass_g\" MAYOR A 3000\n",
    "df_penguins_bmg_mayor_3000 = df_penguins.filter(\n",
    "    pl.col(\"body_mass_g\")>3000\n",
    ")\n",
    "# df_penguins_bmg_mayor_3000.head()\n",
    "df_penguins_bmg_mayor_3000.shape[0] ## ⬅️ Cantidad de datos resultantes : 331\n",
    "\n",
    "## 💡 EJEMPLO 2: FILTRAR VALORES DE COLUMNA \"body_mass_g\" ENTRE 1000 y 3000\n",
    "df_penguins_bmg_entre_1000_3000 = df_penguins.filter(\n",
    "    pl.col(\"body_mass_g\").is_between(1000,3000)\n",
    ")\n",
    "# df_penguins_bmg_entre_1000_3000.head()\n",
    "df_penguins_bmg_entre_1000_3000.shape[0] ## ⬅️ Cantidad de datos resultantes : 11\n",
    "\n",
    "## 💡 EJEMPLO 3: FILTRAR VALORES NULOS EN COLUMNA \"body_mass_g\"\n",
    "df_penguins_nulos_body_mass_g = df_penguins.filter(\n",
    "    pl.col(\"body_mass_g\").is_null()\n",
    ")\n",
    "# df_penguins_nulos_body_mass_g.head()\n",
    "df_penguins_nulos_body_mass_g.shape[0] ## ⬅️ Cantidad de datos resultantes : 2\n",
    "\n",
    "## 💡 EJEMPLO 4: FILTRAR VALORES NO NULOS EN COLUMNA \"body_mass_g\"\n",
    "df_penguins_no_nulos_body_mass_g = df_penguins.filter(\n",
    "    pl.col(\"body_mass_g\").is_not_null()\n",
    ")\n",
    "# df_penguins_no_nulos_body_mass_g.head()\n",
    "df_penguins_no_nulos_body_mass_g.shape[0] ## ⬅️ Cantidad de datos resultantes : 342\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaafe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    D). RELLENANDO DATOS Null Y NaN DE LAS COLUMNAS DE UN DATASET\n",
    "    \n",
    "        ### 🧠EXISTE UNA DIFERENCIA ENTRE DATOS NaN Y Null Y CONOCERLA TE EVITA\n",
    "              ERRORES SILENCIOSOS QUE PUEDEN DESTRUIR UN ANÁLISIS NUMÉRICO SIN NOTARLO.\n",
    "\"\"\"\n",
    "\"\"\"======================================================================================\n",
    "    📝 RELLENANDO DATOS Null (Ausencia de valor en un registro)\n",
    "\n",
    "        🗒️SINTAXIS:\n",
    "        \n",
    "            dataset_nombre.fill_null(value=ValorARellenarNulos,strategy=EstrategiaDeRelleno)\n",
    "            \n",
    "            💡 Importante: El parámetro strategy admite (\"forward\" | \"backward\" | \"min\" | \"max\" | \"mean\" | \"zero\" | \"one\").\n",
    "            \n",
    "                💡forward:  ⬅️ rellenará la columna del dataset con su valor posterior a un null.\n",
    "                💡backward: ⬅️ rellenará la columna del dataset con su valor anterior a un null.\n",
    "                💡min:      ⬅️ rellenará la columna del dataset con su valor mínimo de la columna.\n",
    "                💡max:      ⬅️ rellenará la columna del dataset con su valor máximo de la columna.\n",
    "                💡mean:     ⬅️ rellenará la columna del dataset con la mediana de la columna.\n",
    "                💡zero:     ⬅️ rellenará la columna del dataset con ceros.\n",
    "                💡one:      ⬅️ rellenará la columna del dataset con unos.\n",
    "\n",
    "            ### 🧠 Tengamos en cuenta que debemos almacenar estos cambios en una nueva variable.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5276ee12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>species</th><th>island</th><th>bill_length_mm</th><th>bill_depth_mm</th><th>flipper_length_mm</th><th>body_mass_g</th><th>sex</th></tr><tr><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 7)\n",
       "┌─────────┬────────┬────────────────┬───────────────┬───────────────────┬─────────────┬─────┐\n",
       "│ species ┆ island ┆ bill_length_mm ┆ bill_depth_mm ┆ flipper_length_mm ┆ body_mass_g ┆ sex │\n",
       "│ ---     ┆ ---    ┆ ---            ┆ ---           ┆ ---               ┆ ---         ┆ --- │\n",
       "│ u32     ┆ u32    ┆ u32            ┆ u32           ┆ u32               ┆ u32         ┆ u32 │\n",
       "╞═════════╪════════╪════════════════╪═══════════════╪═══════════════════╪═════════════╪═════╡\n",
       "│ 0       ┆ 0      ┆ 0              ┆ 0             ┆ 0                 ┆ 0           ┆ 0   │\n",
       "└─────────┴────────┴────────────────┴───────────────┴───────────────────┴─────────────┴─────┘"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"✅ Función .fill_null() \"\"\"\n",
    "\n",
    "#==== ➡️ Rellenando con el parámetro strategy\n",
    "\n",
    "## 💡 EJEMPLO 1: ⬅️ Rellenamos nulos de todas las columnas del dataset.\n",
    "df_penguins = df_penguins.fill_null(strategy=\"forward\") \n",
    "# df_penguins.head()\n",
    "# df_penguins.null_count() ##✅ No existen datos nulos\n",
    "\n",
    "## 💡 EJEMPLO 2: ⬅️ Rellenamos nulos de todas las columnas del dataset.\n",
    "df_penguins = df_penguins.with_columns(\n",
    "    pl.col(\"body_mass_g\").fill_null(strategy=\"forward\")\n",
    ")\n",
    "# df_penguins.head()\n",
    "\n",
    "#==== ➡️ Rellenando con el parámetro value\n",
    "\n",
    "## 💡 EJEMPLO 3: ⬅️ Rellenamos nulos de todas las columnas del dataset.\n",
    "df_penguins = df_penguins.fill_null(value=0) ##⬅️ Rellenamos nulos de todas las columnas del dataset, con el valor cero.\n",
    "\n",
    "## 💡 EJEMPLO 4: ⬅️ Rellenamos nulos de todas las columnas del dataset.\n",
    "df_penguins = df_penguins.with_columns(\n",
    "    pl.col(\"body_mass_g\").fill_null(value=0)       ##⬅️ Rellenamos una columna específica del dataset, con el valor cero.\n",
    ")\n",
    "df_penguins.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafa313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"======================================================================================\n",
    "    📝 RELLENANDO DATOS NaN (Resultados indefinidos en un registro)\n",
    "\n",
    "        🗒️SINTAXIS:\n",
    "        \n",
    "            dataset_nombre.fill_nan(value=ValorARellenar)\n",
    "            \n",
    "            💡 Importante: El parámetro value admite cualquier valor a rellenar, e incluso una medida estadística\n",
    "                            de una columna específica en el dataset: (\"min\" | \"max\" | \"mean\" | \"median\")\n",
    " \n",
    "            ### 🧠 Tengamos en cuenta que debemos almacenar estos cambios en una nueva variable.\n",
    "\"\"\"\n",
    "\"\"\"✅ Función .fill_nan() \"\"\"\n",
    "import numpy as np\n",
    "### 📝 Utilizaremos de ejemplo este dataframe con datos NaN (Numpu)\n",
    "df_example = pl.DataFrame(data=[[1.0,np.nan,3.0,4.0,np.nan],[np.nan,5.0,np.nan,10.0,21.0]],schema=[\"Edad\",\"Puntos\"])\n",
    "df_example.head()\n",
    "\n",
    "#==== ➡️ Rellenando con un valor aleatorio: 1\n",
    "\n",
    "## 💡 EJEMPLO 1: ⬅️ Rellenamos NaN de todas las columnas del dataset.\n",
    "df_penguins = df_example.fill_nan(value=1)  \n",
    "\n",
    "## 💡 EJEMPLO 2: ⬅️ Rellenamos NaN de una columna específica del dataset.\n",
    "df_example = df_example.with_columns(\n",
    "    pl.col(\"Edad\").fill_nan(value=1)                 \n",
    ")\n",
    "\n",
    "#==== ➡️ Rellenando con una medida esadística de una columna: Edad ➡️ media\n",
    "\n",
    "## 💡 EJEMPLO 3: ⬅️ Rellenamos NaN de todas las columnas del dataset.\n",
    "df_example = df_example.fill_nan(value=pl.col(\"Edad\").drop_nans().mean()) \n",
    "\n",
    "## 💡 EJEMPLO 4: ⬅️ Rellenamos NaN de una columna específica del dataset.\n",
    "df_example = df_example.with_columns(\n",
    "    pl.col(\"Puntos\").fill_nan(value=pl.col(\"Puntos\").drop_nans().mean())      \n",
    ")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a14df30",
   "metadata": {},
   "source": [
    "#### Fase 4. Agrupamiento de Datos ♾️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38f6449",
   "metadata": {},
   "source": [
    "\"\"\"El agrupamiento de la información nos brinda el resumen de la información proveniente \n",
    "de un dataset, logrando econtrar ciertos patrones en cada grupo de información.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6fffe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    📝 SINTAXIS:\n",
    "\n",
    "        dataset_nuevo_agrupamiento= dataset_nombre.group_by([NombreColumna1,NombreColumnaN]).agg(\n",
    "            pl.col(ColumnaAgregacion).funcionAgregacion().alias(NombreNuevoDeColumna)\n",
    "        )\n",
    "        \n",
    "        ### 🧠 En este caso, debemos almacenar en una variable los cambios a realizar en el dataframe.\n",
    "\n",
    "❎ En el agrupamiento de información, podemos utilizar diversas funciones de agregación, tales como:\n",
    "\n",
    "💡.min():    ⬅️ Permite obtener el mínimo valor de la información agrupada.\n",
    "💡.max():    ⬅️ Permite obtener el máximo valor de la información agrupada.\n",
    "💡.sum():    ⬅️ Permite sumar la información de una columna cuantitativa por la información agrupada.\n",
    "💡.count():  ⬅️ Permite contar la cantidad de información de una columna por la información agrupada.\n",
    "💡.mean():   ⬅️ Permite obtener la media de una columna cuantitativa por la información agrupada.\n",
    "💡.median(): ⬅️ Permite obtener la mediana de una columna cuantitativa por la información agrupada.\n",
    "\"\"\"\n",
    "###✔️ Usaremos el dataset de \"penguins\"\n",
    "df_penguins = pl.read_csv(\"../datasets/penguins.csv\",separator=\",\")\n",
    "# df_penguins.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ad93703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>species</th><th>Cantidad</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;Adelie&quot;</td><td>152</td></tr><tr><td>&quot;Chinstrap&quot;</td><td>68</td></tr><tr><td>&quot;Gentoo&quot;</td><td>124</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 2)\n",
       "┌───────────┬──────────┐\n",
       "│ species   ┆ Cantidad │\n",
       "│ ---       ┆ ---      │\n",
       "│ str       ┆ u32      │\n",
       "╞═══════════╪══════════╡\n",
       "│ Adelie    ┆ 152      │\n",
       "│ Chinstrap ┆ 68       │\n",
       "│ Gentoo    ┆ 124      │\n",
       "└───────────┴──────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 💡 EJEMPLO 1: (AGRUPANDO POR UNA COLUMNA) \n",
    "df_agrupado_uno = df_penguins.group_by([\"species\"]).agg(\n",
    "    pl.col(\"body_mass_g\").mean().alias(\"PromedioBMG\") ## ⬅️ Hallamos la media de la columna \"body_mass_g\"\n",
    ")\n",
    "# df_agrupado_uno.head()\n",
    "\n",
    "## 💡 EJEMPLO 2: (AGRUPAR POR DOS COLUMNAS)\n",
    "df_agrupado_dos = df_penguins.group_by([\"species\",\"sex\"]).agg(\n",
    "    pl.col(\"body_mass_g\").mean().alias(\"Species_Sex_PromedioBMG\")\n",
    ")\n",
    "# df_agrupado_dos.head()\n",
    "\n",
    "## 💡 EJEMPLO 3: (AGRUPAR LA INFORMACIÓN POR LA CANTIDAD DE LA MISMA COLUMNA)\n",
    "\n",
    "df_agrupado_tres = df_penguins.group_by([\"species\"]).agg(\n",
    "    pl.col(\"species\").len().alias(\"Cantidad\") ## ⬅️ .len() : función clave para traer la cantidad de datos de la columna.\n",
    ")\n",
    "df_agrupado_tres.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf4b561",
   "metadata": {},
   "source": [
    "#### FASE 4.1 CÁLCULOS MÓVILES EN POLARS 🐻‍❄️💹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74583649",
   "metadata": {},
   "source": [
    "Así como SQL SERVER y Pandas permite realizar cálculos móviles basados en funciones de agregación\n",
    "(min,max,mean,entre otros), Polars lo realiza mediante la función con prefijo \".rolling_\" entre \n",
    "una N cantidad de filas hacia atrás."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911f3aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    📝 SINTAXIS: \n",
    "        \n",
    "        1️⃣ Cálculo Móvil sin Particionamiento: Permite el cálculo móvil de una columna que no es afectada por otra(s).\n",
    "        \n",
    "        dataset_nombre = dataset_nombre.with_columns(\n",
    "            pl.col(NombreColumnaCalcular).funcionAgregacionAcumulativa().alias(NuevaColumnaMovil)\n",
    "        ) \n",
    "                                             \n",
    "        2️⃣ Cálculo Móvil con Particionamiento: Permite el cálculo móvil por columnas en específico.\n",
    "        \n",
    "        dataset_nombre = dataset_nombre.with_columns(\n",
    "            pl.col(NombreColumnaCalcular).funcionAgregacion().over(partition_by=ColumnaParticionar).alias(NombreColumnaMovil)\n",
    "        )\n",
    "        \n",
    "        ### .over(): Permite el particionamiento por cierta(s) columna(s).\n",
    "\n",
    "        💡 Importante: Existen ciertas funciones de agregación que contienen dentro de sus parámetros\n",
    "                       [window_size: el cuál permite seleccionar una cierta cantidad de filas para el\n",
    "                       cálculo móvil y min_samples que permite establecer una mínima cantidad de \n",
    "                       periodos para evitar valores NaN, estas funciones tienen de prefijo \".rolling_\")                                            \n",
    "\n",
    "        ### 🧠 Cuando realizamos el cálculo móvil a una columna, Pandas siempre incluirá la fila actual.\n",
    "\"\"\"\n",
    "### 💹 USAREMOS EL SIGUIENTE DATASET DE EJEMPLO (FORMATO .json):\n",
    "import json\n",
    "with open(\"../datasets/ventas.json\",\"r\") as file:\n",
    "    data_json = json.load(file)\n",
    "df_ventas = pl.DataFrame(data=data_json[\"ventas\"])\n",
    "# df_ventas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f716bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>nro_venta</th><th>fecha</th><th>cliente</th><th>total</th><th>valor_minimo_3_dias</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1001</td><td>&quot;2024-01-22&quot;</td><td>&quot;Cliente_10&quot;</td><td>350.25</td><td>null</td></tr><tr><td>1002</td><td>&quot;2024-02-15&quot;</td><td>&quot;Cliente_3&quot;</td><td>410.5</td><td>null</td></tr><tr><td>1003</td><td>&quot;2024-03-08&quot;</td><td>&quot;Cliente_7&quot;</td><td>120.75</td><td>null</td></tr><tr><td>1004</td><td>&quot;2024-04-20&quot;</td><td>&quot;Cliente_1&quot;</td><td>250.0</td><td>120.75</td></tr><tr><td>1005</td><td>&quot;2024-05-11&quot;</td><td>&quot;Cliente_10&quot;</td><td>300.9</td><td>120.75</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌───────────┬────────────┬────────────┬────────┬─────────────────────┐\n",
       "│ nro_venta ┆ fecha      ┆ cliente    ┆ total  ┆ valor_minimo_3_dias │\n",
       "│ ---       ┆ ---        ┆ ---        ┆ ---    ┆ ---                 │\n",
       "│ i64       ┆ str        ┆ str        ┆ f64    ┆ f64                 │\n",
       "╞═══════════╪════════════╪════════════╪════════╪═════════════════════╡\n",
       "│ 1001      ┆ 2024-01-22 ┆ Cliente_10 ┆ 350.25 ┆ null                │\n",
       "│ 1002      ┆ 2024-02-15 ┆ Cliente_3  ┆ 410.5  ┆ null                │\n",
       "│ 1003      ┆ 2024-03-08 ┆ Cliente_7  ┆ 120.75 ┆ null                │\n",
       "│ 1004      ┆ 2024-04-20 ┆ Cliente_1  ┆ 250.0  ┆ 120.75              │\n",
       "│ 1005      ┆ 2024-05-11 ┆ Cliente_10 ┆ 300.9  ┆ 120.75              │\n",
       "└───────────┴────────────┴────────────┴────────┴─────────────────────┘"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 💡 EJEMPLO 1: CÁLCULO MÓVIL ➡️ VENTAS ACUMULATIVAS (SUMA ACUMULADA SIN PARTICIONES)\n",
    "df_ventas_acumuladas = df_ventas\n",
    "df_ventas_acumuladas = df_ventas_acumuladas.with_columns(\n",
    "    pl.col(\"total\").cum_sum().alias(\"ventas_acumuladas\")  ##⬅️ Usamos .cum_sum()\n",
    ") \n",
    "# df_ventas_acumuladas.tail()\n",
    "\n",
    "### 💡 EJEMPLO 2: CÁLCULO MÓVIL ➡️ VENTAS ACUMULATIVAS (SUMA ACUMULADA CADA 3 DIAS) (✅ INCLUYE FILA ACTUAL)\n",
    "df_ventas_acumuladas_3_dias = df_ventas\n",
    "df_ventas_acumuladas_3_dias = df_ventas_acumuladas_3_dias.with_columns(\n",
    "    pl.col(\"total\").rolling_sum(window_size=3).alias(\"ventas_acumuladas\") ## ⬅️.rolling_sum()\n",
    ") \n",
    "####💡 Los Valores NaN no permiten realizar sumatorias por 1 o 2 valores, deben ser 3 (✅ Incluye la fiLa actual - ❌No particionamos).\n",
    "# df_ventas_acumuladas_3_dias.head(6)\n",
    "\n",
    "### 💡 EJEMPLO 3: CÁLCULO MÓVIL ➡️ VENTAS ACUMULATIVAS (SUMA ACUMULADA CADA 3 DIAS) ✅ (❌ NO INCLUYE FILA ACTUAL)\n",
    "df_ventas_acumuladas_3_dias_sin_fila_actual = df_ventas\n",
    "df_ventas_acumuladas_3_dias_sin_fila_actual = df_ventas_acumuladas_3_dias_sin_fila_actual.with_columns(\n",
    "    pl.col(\"total\").shift(1).rolling_sum(window_size=3).alias(\"ventas_acumuladas\") ## ⬅️.rolling_sum()\n",
    ")\n",
    "####💡 Los Valores NaN no permiten realizar sumatorias por 1 o 2 valores, deben ser 3 (❌ No incluye la fiLa actual - ❌No particionamos).\n",
    "# df_ventas_acumuladas_3_dias_sin_fila_actual.head(7) \n",
    "\n",
    "### 💡 EJEMPLO 4: CÁLCULO MÓVIL ➡️ VENTAS ACUMULATIVAS (SUMA ACUMULADA CON PARTICIONES)\n",
    "df_ventas_acumuladas_particiones = df_ventas.sort(by=\"cliente\") #.sort(by=\"cliente\") ## ⬅️ Ordenamos antes de particionar\n",
    "# df_ventas_acumuladas_particiones.head()\n",
    "df_ventas_acumuladas_particiones = df_ventas_acumuladas_particiones.with_columns(\n",
    "    pl.col(\"total\").cum_sum().over(partition_by=\"cliente\").alias(\"ventas_acumuladas\")\n",
    ") \n",
    "# df_ventas_acumuladas_particiones.head() ## ✅ .over() permite el particionamiento y reinicia el acumulado por cada cliente.\n",
    "\n",
    "#=======================================================================================================================================\n",
    "\n",
    "### 💡 EJEMPLO 5: CÁLCULO MÓVIL ➡️ PROMEDIO MÓVIL (PROMEDIO CADA 3 DÍAS) (✅ INCLUYE FILA ACTUAL)\n",
    "df_ventas_promedio_3_dias = df_ventas \n",
    "# df_ventas_promedio_3_dias.head()\n",
    "df_ventas_promedio_3_dias = df_ventas_promedio_3_dias.with_columns(\n",
    "    pl.col(\"total\").rolling_mean(window_size=3).alias(\"promedio_ventas_3_dias\") ## ⬅️ Utilizamos .rolling_mean()\n",
    ")\n",
    "####💡 Los Valores NaN no permiten calcular el promedio por 1 o 2 valores, deben ser 3 (✅ Incluye la fiLa actual - ❌No particionamos).\n",
    "# df_ventas_promedio_3_dias.head()\n",
    "\n",
    "\n",
    "### 💡 EJEMPLO 6: CÁLCULO MÓVIL ➡️ PROMEDIO MÓVIL (PROMEDIO CADA 3 DÍAS) (❌ NO INCLUYE FILA ACTUAL)\n",
    "df_ventas_promedio_3_dias_sin_fila_actual = df_ventas\n",
    "# df_ventas_promedio_3_dias_sin_fila_actual.head()\n",
    "\n",
    "df_ventas_promedio_3_dias_sin_fila_actual = df_ventas_promedio_3_dias_sin_fila_actual.with_columns(\n",
    "    pl.col(\"total\").shift(1).rolling_mean(window_size=3).alias(\"promedio_ventas_3_dias\") ## ⬅️ Utilizamos .rolling_mean()\n",
    ")\n",
    "####💡 Los Valores NaN no permiten calcular el promedio por 1 o 2 valores, deben ser 3 (❌ No incluye la fiLa actual - ❌No particionamos).\n",
    "df_ventas_promedio_3_dias_sin_fila_actual.head()\n",
    "\n",
    "\n",
    "#=======================================================================================================================================\n",
    "\n",
    "### 💡 EJEMPLO 7: CÁLCULO MÓVIL ➡️ MÁXIMO MÓVIL (VALOR MÁXIMO CADA 3 DÍAS) (✅ INCLUYE FILA ACTUAL)\n",
    "df_ventas_maximo_3_dias = df_ventas\n",
    "# df_ventas_maximo_3_dias.head()\n",
    "df_ventas_maximo_3_dias = df_ventas_maximo_3_dias.with_columns(\n",
    "    pl.col(\"total\").rolling_max(window_size=3).alias(\"valor_maximo_3_dias\") ## ⬅️ Utilizamos .rolling_max()\n",
    ")\n",
    "####💡 Los Valores NaN no permiten calcular el promedio por 1 o 2 valores, deben ser 3 (✅ Incluye la fiLa actual - ❌No particionamos).\n",
    "df_ventas_maximo_3_dias.head()\n",
    "\n",
    "\n",
    "### 💡 EJEMPLO 8: CÁLCULO MÓVIL ➡️ MÁXIMO MÓVIL (VALOR MÁXIMO CADA 3 DÍAS) (❌ NO INCLUYE FILA ACTUAL)\n",
    "df_ventas_maximo_3_dias_sin_fila_actual = df_ventas\n",
    "# df_ventas_maximo_3_dias_sin_fila_actual.head()\n",
    "df_ventas_maximo_3_dias_sin_fila_actual = df_ventas_maximo_3_dias_sin_fila_actual.with_columns(\n",
    "    pl.col(\"total\").shift(1).rolling_max(window_size=3).alias(\"valor_maximo_3_dias\")\n",
    ")\n",
    "####💡 Los Valores NaN no permiten calcular el promedio por 1 o 2 valores, deben ser 3 (❌ No incluye la fiLa actual - ❌No particionamos).\n",
    "# df_ventas_maximo_3_dias_sin_fila_actual.head()\n",
    "\n",
    "\n",
    "#=======================================================================================================================================\n",
    "\n",
    "### 💡 EJEMPLO 9: CÁLCULO MÓVIL ➡️ MÍNIMO MÓVIL (VALOR MÍNIMO CADA 3 DÍAS) (✅ INCLUYE FILA ACTUAL)\n",
    "df_ventas_minimo_3_dias = df_ventas\n",
    "# df_ventas_minimo_3_dias.head()\n",
    "df_ventas_minimo_3_dias = df_ventas_minimo_3_dias.with_columns(\n",
    "    pl.col(\"total\").rolling_min(window_size=3).alias(\"valor_minimo_3_dias\")\n",
    ")\n",
    "####💡 Los Valores NaN no permiten calcular el promedio por 1 o 2 valores, deben ser 3 (✅ Incluye la fiLa actual - ❌No particionamos).\n",
    "# df_ventas_minimo_3_dias.head()\n",
    "\n",
    "\n",
    "### 💡 EJEMPLO 10: CÁLCULO MÓVIL ➡️ MÍNIMO MÓVIL (VALOR MÍNIMO CADA 3 DÍAS) (❌ NO INCLUYE FILA ACTUAL)\n",
    "df_ventas_minimo_3_dias_sin_fila_actual = df_ventas\n",
    "# df_ventas_minimo_3_dias_sin_fila_actual.head()\n",
    "df_ventas_minimo_3_dias_sin_fila_actual = df_ventas_minimo_3_dias_sin_fila_actual.with_columns(\n",
    "    pl.col(\"total\").shift(1).rolling_min(window_size=3).alias(\"valor_minimo_3_dias\")\n",
    ")\n",
    "####💡 Los Valores NaN no permiten calcular el promedio por 1 o 2 valores, deben ser 3 (❌ No incluye la fiLa actual - ❌No particionamos).\n",
    "df_ventas_minimo_3_dias_sin_fila_actual.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67b6fb4",
   "metadata": {},
   "source": [
    "#### FASE 4.2 PIVOT TABLES EN POLARS 🐻‍❄️💹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3e7caa",
   "metadata": {},
   "source": [
    "Las Pivot Table permiten transformar filas de un dataset/dataframe en columnas de un nuevo dataset/dataframe,\n",
    "permitiendo un análisis más detallado sobre un grupo específico de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fce1dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sex</th><th>avg</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;female&quot;</td><td>27.915709</td></tr><tr><td>&quot;male&quot;</td><td>30.726645</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌────────┬───────────┐\n",
       "│ sex    ┆ avg       │\n",
       "│ ---    ┆ ---       │\n",
       "│ str    ┆ f64       │\n",
       "╞════════╪═══════════╡\n",
       "│ female ┆ 27.915709 │\n",
       "│ male   ┆ 30.726645 │\n",
       "└────────┴───────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"     \n",
    "      📝 SINTAXIS:\n",
    "          dataset_pivoteado_nombre = dataset_original_nombre.pivot(index=NombreColumnaDataframe,on=NombreColumnaDataframe,\n",
    "                                     values=NombreColumnaDataframe,,aggregate_function=NombreFunciónAgregación) \n",
    "\n",
    "\"\"\"\n",
    "import polars as pl\n",
    "### ✅🗃️ Dataset a utilizar: titanic\n",
    "df_titanic = pl.read_csv(\"../datasets/titanic.csv\",separator=\",\")\n",
    "# df_titanic.head()\n",
    "\n",
    "#### 💡 EJEMPLO 1: HALLAR EL PROMEDIO DE EDAD POR CLASE Y GÉNERO\n",
    "df_pivot_uno = df_titanic.pivot(index=\"pclass\",on=\"sex\",values=\"age\",aggregate_function=\"mean\")\n",
    "df_pivot_uno.head() ##  ✅ Resultado exitoso.\n",
    "\n",
    "\n",
    "#### 💡 EJEMPLO 2: HALLAR EL PROMEDIO DE FARE POR CLASE Y SEXO, ADEMÁS AGREGAR UN TOTAL A NIVEL DE FILA Y COLUMNA CALCULANDO EL PROMEDIO)\n",
    "df_pivot_dos = df_titanic.pivot(index=\"pclass\",on=\"sex\",values=\"fare\",aggregate_function=\"mean\")\n",
    "df_pivot_dos = df_pivot_dos.with_columns(\n",
    "    pl.mean_horizontal(\"male\",\"female\").round(2).alias(\"total\")\n",
    ")\n",
    "## 💡 Cuando usamos pl.mean_horizontal() permite agregar una columna adicional para realizar un cálculo a nivel de fila.\n",
    "df_pivot_dos.head()\n",
    "## 💡 Calculamos la media de cada columna.\n",
    "total_avg_male, total_avg_female, total_avg = round(df_pivot_dos[\"male\"].mean(),2),round(df_pivot_dos[\"female\"].mean(),2),round(df_pivot_dos[\"total\"].mean(),2)\n",
    "## 💡 Asignamos los valores a un nuevo dataframe para poder unirlo al dataframe original\n",
    "df_pivot_total_columna = pl.DataFrame(data=[[\"Total\"],[total_avg_male],[total_avg_female],[total_avg]],schema={\"pclass\":pl.String,\"male\":pl.Float64,\"female\":pl.Float64,\"total\":pl.Float64})\n",
    "# df_pivot_total_columna.head() ## 💡 Agregamos un valor \"Total\" a la columna pclass para poder crear la nueva fila en el dataframe original.\n",
    "df_pivot_dos = df_pivot_dos.with_columns(\n",
    "    pl.col(\"pclass\").cast(pl.String).alias(\"pclass\") ## 💡 Casteamos la columna pclass a un String para poder concatenarlo con el dato del dataframe de totales.\n",
    ")\n",
    "# df_pivot_dos.head()\n",
    "## 💡 Concatenamos correctamente los dataframes con el cálculo de su total a nivel de columna.\n",
    "df_pivot_dos_final = pl.concat([df_pivot_dos,df_pivot_total_columna])\n",
    "df_pivot_dos_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713bbff3",
   "metadata": {},
   "source": [
    "#### FASE 4.2 UNPIVOT TABLES EN POLARS 🐻‍❄️💹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502ebf13",
   "metadata": {},
   "source": [
    "Los UnPivot Tables permiten transformar columnas de un dataset/dataframe en filas de un nuevo dataset/dataframe,\n",
    "permitiendo reestablecer el estado del dataframe al original, sin embargo:\n",
    "**LA FUNCIÓN DE AGREGACIÓN UTILIZADA EN PIVOT NO REGRESA A SU FORMA NORMAL LOS DATOS, ES DECIR, SE MANTIENE EL CÁLCULO DE LA FUNCIÓN DE AGREGACIÓN**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b1b0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 3)\n",
      "┌────────┬───────────┬───────────┐\n",
      "│ pclass ┆ male      ┆ female    │\n",
      "│ ---    ┆ ---       ┆ ---       │\n",
      "│ i64    ┆ f64       ┆ f64       │\n",
      "╞════════╪═══════════╪═══════════╡\n",
      "│ 3      ┆ 26.507589 ┆ 21.75     │\n",
      "│ 1      ┆ 41.281386 ┆ 34.611765 │\n",
      "│ 2      ┆ 30.740707 ┆ 28.722973 │\n",
      "└────────┴───────────┴───────────┘\n",
      "shape: (6, 3)\n",
      "┌────────┬────────┬───────────┐\n",
      "│ pclass ┆ sex    ┆ age       │\n",
      "│ ---    ┆ ---    ┆ ---       │\n",
      "│ i64    ┆ str    ┆ f64       │\n",
      "╞════════╪════════╪═══════════╡\n",
      "│ 3      ┆ male   ┆ 26.507589 │\n",
      "│ 1      ┆ male   ┆ 41.281386 │\n",
      "│ 2      ┆ male   ┆ 30.740707 │\n",
      "│ 3      ┆ female ┆ 21.75     │\n",
      "│ 1      ┆ female ┆ 34.611765 │\n",
      "│ 2      ┆ female ┆ 28.722973 │\n",
      "└────────┴────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "      📝 SINTAXIS:\n",
    "          dataframe_unpivoteado_nombre = NombreDataframePivoteado.unpivot(index=[NombreColumnaIndice],on=[Valor1Pivoteado,ValorNPivoteado],\n",
    "                                         variable_name=NombreColumnaValoresPivoteados,value_name=NombreColumnaValorFuncionAgregacionPivoteado)\n",
    "          index: Nombre de la columna del dataset/dataframe pivoteado que se estaleció como *index*\n",
    "          on: Nombre de cada valor establecido como columna en el dataset/dataframe pivoteado\n",
    "          variable_name: Nombre de la columna que será utilizada como parte de los valores pivoteados.\n",
    "          value_name: Nombre de la columna el dataset/dataframe pivoteado que es utlizada por la función de agregación.       \n",
    "\n",
    "\"\"\"\n",
    "import polars as pl\n",
    "### ✅🗃️ Dataframe pivoteado a utilizar: df_titanic\n",
    "df_titanic = pl.read_csv(\"../datasets/titanic.csv\",separator=\",\")\n",
    "# df_titanic.head()\n",
    "\n",
    "## ✅ DATASET PIVOTEADO\n",
    "df_pivoteado = df_titanic.pivot(index=\"pclass\",on=\"sex\",values=\"age\",aggregate_function=\"mean\")\n",
    "# df_pivoteado.head() \n",
    "\n",
    "#### 💡 EJEMPLO 1: DESPIVOTEAR EL DATASET PIVOTEADO\n",
    "df_unpivot_uno = df_pivoteado.unpivot(index=[\"pclass\"],on=[\"male\",\"female\"],variable_name=\"sex\",value_name=\"age\")\n",
    "df_unpivot_uno.head()\n",
    "\n",
    "##---- COMPARACIÓN DE PIVOT y UNPIVOT TABLE DEL DATASET/DATAFRAME\n",
    "print(df_pivoteado)\n",
    "print(df_unpivot_uno)\n",
    "## 💡 Como se mencionó anteriormente, el unpivot table no regresa los datos calculados por \n",
    "##    la función de agregación (en este caso \"mean\") a su forma base del dataset/dataframe original (df_titanic).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b9fc54",
   "metadata": {},
   "source": [
    "#### Fase 5. Combinar y Unir Datasets/Dataframes en Polars 🐻‍❄️♾️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c8aa16",
   "metadata": {},
   "source": [
    "A diferencia de Pandas, Polars permite la unificación de datasets/dataframes mediante dos formas:\n",
    "    - Utilizando Join\n",
    "    - Utilizando Concat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cb6566",
   "metadata": {},
   "source": [
    "##### Join en Polars 📊🐼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b121560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    📝 SINTAXIS: \n",
    "\n",
    "        dataset_unificado_nombre=dataset_nombre_1.join(other=dataset_nombre_2,on='ColumnaEnComun',\n",
    "                                how='left || rigth || inner || full || semi || anti || cross',\n",
    "                                left_on='NombreColumnaEnComún',right_on='NombreColumnaEnComún')                                \n",
    "                                \n",
    "        ==================================================================================================  \n",
    "\n",
    "    ### 💡Importante: Join permite unificar los datasets/dataframes a nivel columnar, es decir,\n",
    "                       unifica horizontalmente las columnas de un dataset/dataframe A; con las columnas\n",
    "                       de un dataset/dataframe B; gracias a una columna en común que tienen ambos \n",
    "                       conjuntos de datos.\n",
    "                       \n",
    "                       left_on ⬅️➡️ right_on : Parámetros que permiten unificar dataset/dataframes\n",
    "                                                cuando las columnas en común tienen diferente nombre.     \n",
    "\"\"\"\n",
    "### ✅ Utilizaremos este dataset de ejemplo:\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "diccionario_uno = {\n",
    "    \"ID_Cliente\":[1,2,3,4,5],\n",
    "    \"Nombre\": [\"Pepito\",\"Juanito\",\"Pedrito\",\"Brayan\",\"Carlos\"],\n",
    "    \"Departamento\":[\"LAS QUINTANAS\",\"EL GOLF\",\"BUENOS AIRES\",\"SAN ANDRÉS\",\"CALIFORNIA\"]\n",
    "}\n",
    "diccionario_dos = {\n",
    "    \"ID_Cliente\":[1,1,2,2,5,4,1,None],\n",
    "    \"Ventas\":np.random.uniform(low=1450.25,high=1980.30,size=8).tolist()\n",
    "}\n",
    "\n",
    "df_uno = pl.DataFrame(diccionario_uno)\n",
    "df_dos = pl.DataFrame(diccionario_dos)\n",
    "\n",
    "diccionario_tres = {\n",
    "    \"Cliente_ID\":[1,1,2,2,5,4,1,None],\n",
    "    \"Ventas\":np.random.uniform(low=1450.25,high=1980.30,size=8).tolist()\n",
    "}\n",
    "df_tres = pl.DataFrame(diccionario_tres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00bc719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ID_Cliente</th><th>Nombre</th><th>Departamento</th></tr><tr><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>&quot;Pepito&quot;</td><td>&quot;LAS QUINTANAS&quot;</td></tr><tr><td>2</td><td>&quot;Juanito&quot;</td><td>&quot;EL GOLF&quot;</td></tr><tr><td>4</td><td>&quot;Brayan&quot;</td><td>&quot;SAN ANDRÉS&quot;</td></tr><tr><td>5</td><td>&quot;Carlos&quot;</td><td>&quot;CALIFORNIA&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 3)\n",
       "┌────────────┬─────────┬───────────────┐\n",
       "│ ID_Cliente ┆ Nombre  ┆ Departamento  │\n",
       "│ ---        ┆ ---     ┆ ---           │\n",
       "│ i64        ┆ str     ┆ str           │\n",
       "╞════════════╪═════════╪═══════════════╡\n",
       "│ 1          ┆ Pepito  ┆ LAS QUINTANAS │\n",
       "│ 2          ┆ Juanito ┆ EL GOLF       │\n",
       "│ 4          ┆ Brayan  ┆ SAN ANDRÉS    │\n",
       "│ 5          ┆ Carlos  ┆ CALIFORNIA    │\n",
       "└────────────┴─────────┴───────────────┘"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#### 💡 EJEMPLO 1 (UNIFICACIÓN DE DATAFRAMES [INNER]) \n",
    "df_ejemplo_1 = df_uno.join(other=df_dos,on=\"ID_Cliente\",how=\"inner\")\n",
    "# df_ejemplo_1.shape[0] ## Cantidad de registros: 7\n",
    "# df_ejemplo_1.head(7)\n",
    "## [NO SE ENCUENTRA EL CLIENTE 3] ➡️ INNER MANTIENE LA INFORMACIÓN RELACIONADA Y EXISTENTE ENTRE AMBOS DATASETS\n",
    "\n",
    "#### 💡 EJEMPLO 2 (UNIFICACIÓN DE DATAFRAMES [LEFT])\n",
    "df_ejemplo_2 = df_uno.join(other=df_dos,on=\"ID_Cliente\",how=\"left\")\n",
    "# df_ejemplo_2.shape[0] ## Cantidad de registros: 8\n",
    "# df_ejemplo_2.head(8)\n",
    "## [SE ENCUENTRA EL CLIENTE 3] ➡️ LEFT MANTIENE LA INFORMACIÓN DEL LADO IZQUIERDO (df_uno) \n",
    "## [ASÍ NO EXISTA ALGÚN REGISTRO EN EL LADO DERECHO (df_dos)]\n",
    "\n",
    "#### 💡 EJEMPLO 3 (UNIFICACIÓN DE DATAFRAMES [RIGHT])\n",
    "df_ejemplo_3 = df_uno.join(other=df_dos,on=\"ID_Cliente\",how=\"right\")\n",
    "# df_ejemplo_3.shape[0] ## Cantidad de registros: 8\n",
    "# df_ejemplo_3.head(8)\n",
    "## [SE ENCUENTRA EL CLIENTE 3] ➡️ RIGHT MANTIENE LA INFORMACIÓN DEL LADO DERECHO (df_dos) \n",
    "## [ASÍ NO EXISTA ALGÚN REGISTRO EN EL LADO IZQUIERDO (df_uno)]\n",
    "\n",
    "#### 💡 EJEMPLO 4 (UNIFICACIÓN DE DATAFRAMES [FULL] o [OUTER]) ⬅️ AMBOS REALIZAN LO MISMO\n",
    "df_ejemplo_4 = df_uno.join(other=df_dos,on=\"ID_Cliente\",how=\"full\")\n",
    "# df_ejemplo_4.shape[0] ## Cantidad de registros: 9\n",
    "# df_ejemplo_4.head(9)\n",
    "## ➡️ FULL u OUTER MANTIENE LA INFORMACIÓN DE AMBOS DATAFRAMES.\n",
    "\n",
    "#### 💡 EJEMPLO 5 (UNIFICACIÓN DE DATAFRAMES [CROSS] ➡️ Forma 2.)\n",
    "df_ejemplo_5 = df_uno.join(other=df_dos,how=\"cross\")\n",
    "# df_ejemplo_5.shape[0] ## Cantidad de registros: 40\n",
    "# df_ejemplo_5.head()\n",
    "## ➡️ CROSS GENERA TODAS LAS COMBINACIONES POSIBLES DE LAS FILAS DEL df_uno CON LAS FILAS DEL df_dos. \n",
    "##     (YA NO NECESITAMOS UTILIZAR EL PARÁMETRO \"on=\")\n",
    "\n",
    "# #### 💡 EJEMPLO 6 (UNIFICACIÓN DE DATAFRAMES [INNER] ➡️ Forma 2. + left_on + right_on)\n",
    "df_ejemplo_6 = df_uno.join(other=df_tres,how=\"inner\",left_on=\"ID_Cliente\",right_on=\"Cliente_ID\")\n",
    "# df_ejemplo_6.shape[0] ## Cantidad de registros: 7\n",
    "# df_ejemplo_6.head(7)\n",
    "## ➡️ CUANDO UTILIZAMOS left_on Y right_on YA NO NECESITAMOS UTILIZAR EL PARÁMETRO \"on=\"\n",
    "## 📝 left_on ⬅️➡️ right_on : Parámetros que permiten unificar dataset/dataframes\n",
    "##    cuando las columnas en común tienen diferente nombre.\n",
    "\n",
    "\n",
    "#### 💡 EJEMPLO ANTI (PERMITE DEVOLVER LAS FILAS DE df_uno QUE NO SE ENCUENTRAN EN df_dos)\n",
    "df_ejemplo_anti = df_uno.join(other=df_dos,how=\"anti\",on=\"ID_Cliente\")\n",
    "# df_ejemplo_anti.shape[0] ## Cantidad de registros: 1\n",
    "# df_ejemplo_anti.head()\n",
    "\n",
    "\n",
    "#### 💡 EJEMPLO SEMI (PERMITE DEVOLVER LAS FILAS DE df_uno EXISTENTES EN df_dos)\n",
    "####        PERO DEVOLVIENDO SOLO LAS FILAS DE df_uno\n",
    "df_ejemplo_semi = df_uno.join(other=df_dos,how=\"semi\",on=\"ID_Cliente\")\n",
    "# df_ejemplo_semi.shape[0] ## Cantidad de registros: 1\n",
    "# df_ejemplo_semi.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ba45fd",
   "metadata": {},
   "source": [
    "##### Concat en Polars 📊🐼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2da9e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    📝 SINTAXIS: \n",
    "\n",
    "        dataset_union_nombre = pl.concat([\n",
    "            dataset_nombre_1.set_index([\"NombreColumna1\",\"NombreColumna2\",\"NombreColumnaN\"]),\n",
    "            dataset_nombre_2.set_index([\"NombreColumna1\",\"NombreColumna2\",\"NombreColumnaN\"])],\n",
    "            axis = 1,ignore_index = True\n",
    "        )\n",
    "                                                        \n",
    "        ==================================================================================================  \n",
    "\n",
    "    ### 💡Importante: Concat permite unificar los datasets/dataframes a nivel fila, es decir,\n",
    "                       unifica verticalmente las columnas de un dataset/dataframe A; con las columnas\n",
    "                       de un dataset/dataframe B; gracias a la(s) columna(s) en común que tienen ambos \n",
    "                       conjuntos de datos.\n",
    "                       \n",
    "                       Debemos tener en cuenta que ambos datasets/dataframes deben tener la misma cantidad\n",
    "                       tipos y orden en las columnas. Además, el parámetro \"axis\" siempre debe igualarse a 1 para\n",
    "                       que los datastes/dataframes se unifiquen a nivel vertical columnar. Por otro lado,\n",
    "                       el parámetro \"ignore_index\" debe permanecer en True para que el índice del dataset/\n",
    "                       dataframe nuevo se reestablezca.\n",
    "\"\"\"\n",
    "### ✅ Utilizaremos este dataset de ejemplo:\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "diccionario_uno = {\n",
    "    \"Categorias\":[\"ELECTRODOMÉSTICOS\",\"TECNOLOGÍA\",\"JUGUETES\",\"DEPORTE\",\"CULTURA\"],\n",
    "    \"Año\": [2022,2022,2023,2023,2023],\n",
    "    \"Ventas\":np.random.uniform(low=3500.25,high=3800.30,size=5).round(2).tolist()\n",
    "}\n",
    "\n",
    "diccionario_dos = {\n",
    "    \"Categorias\":[\"ELECTRODOMÉSTICOS\",\"TECNOLOGÍA\",\"JUGUETES\",\"DEPORTE\",\"CULTURA\"],\n",
    "    \"Año\": [2024,2024,2024,2025,2025],\n",
    "    \"Ventas\":np.random.uniform(low=2150.25,high=4580.30,size=5).round(2).tolist()\n",
    "}\n",
    "\n",
    "diccionario_tres = {\n",
    "    \"Cat\":[\"ELECTRODOMÉSTICOS\",\"TECNOLOGÍA\",\"JUGUETES\",\"DEPORTE\",\"CULTURA\"],\n",
    "    \"Años\": [2024,2024,2024,2025,2025],\n",
    "    \"Vent\":np.random.uniform(low=2150.25,high=4580.30,size=5).round(2).tolist()\n",
    "}\n",
    "\n",
    "diccionario_cuatro = {\n",
    "    \"Cat\":[\"ELECTRODOMÉSTICOS\",\"TECNOLOGÍA\",\"JUGUETES\",\"DEPORTE\",\"CULTURA\"],\n",
    "    \"Años\": [2024,2024,2024,2025,2025],\n",
    "    \"Vent\":np.random.uniform(low=2150.25,high=4580.30,size=5).round(2).tolist()\n",
    "}\n",
    "\n",
    "df_uno = pl.DataFrame(diccionario_uno)\n",
    "df_dos = pl.DataFrame(diccionario_dos)\n",
    "df_tres = pl.DataFrame(diccionario_tres)\n",
    "df_cuatro = pl.DataFrame(diccionario_cuatro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1336c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Categorias</th><th>Año</th><th>Ventas</th></tr><tr><td>str</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;ELECTRODOMÉSTICOS&quot;</td><td>2022</td><td>3620.09</td></tr><tr><td>&quot;TECNOLOGÍA&quot;</td><td>2022</td><td>3676.05</td></tr><tr><td>&quot;JUGUETES&quot;</td><td>2023</td><td>3667.62</td></tr><tr><td>&quot;DEPORTE&quot;</td><td>2023</td><td>3792.08</td></tr><tr><td>&quot;CULTURA&quot;</td><td>2023</td><td>3535.57</td></tr><tr><td>&quot;ELECTRODOMÉSTICOS&quot;</td><td>2024</td><td>3435.57</td></tr><tr><td>&quot;TECNOLOGÍA&quot;</td><td>2024</td><td>2695.34</td></tr><tr><td>&quot;JUGUETES&quot;</td><td>2024</td><td>2500.11</td></tr><tr><td>&quot;DEPORTE&quot;</td><td>2025</td><td>3923.25</td></tr><tr><td>&quot;CULTURA&quot;</td><td>2025</td><td>4531.17</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 3)\n",
       "┌───────────────────┬──────┬─────────┐\n",
       "│ Categorias        ┆ Año  ┆ Ventas  │\n",
       "│ ---               ┆ ---  ┆ ---     │\n",
       "│ str               ┆ i64  ┆ f64     │\n",
       "╞═══════════════════╪══════╪═════════╡\n",
       "│ ELECTRODOMÉSTICOS ┆ 2022 ┆ 3620.09 │\n",
       "│ TECNOLOGÍA        ┆ 2022 ┆ 3676.05 │\n",
       "│ JUGUETES          ┆ 2023 ┆ 3667.62 │\n",
       "│ DEPORTE           ┆ 2023 ┆ 3792.08 │\n",
       "│ CULTURA           ┆ 2023 ┆ 3535.57 │\n",
       "│ ELECTRODOMÉSTICOS ┆ 2024 ┆ 3435.57 │\n",
       "│ TECNOLOGÍA        ┆ 2024 ┆ 2695.34 │\n",
       "│ JUGUETES          ┆ 2024 ┆ 2500.11 │\n",
       "│ DEPORTE           ┆ 2025 ┆ 3923.25 │\n",
       "│ CULTURA           ┆ 2025 ┆ 4531.17 │\n",
       "└───────────────────┴──────┴─────────┘"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### 💡 EJEMPLO 1 (UNIFICACIÓN DE DATAFRAMES A NIVEL COLUMNAR - VERTICAL) \n",
    "df_ejemplo_1 = pl.concat([df_uno,df_dos],how=\"vertical\")\n",
    "# df_ejemplo_1.shape[0] ## Cantidad de registros: 10\n",
    "# df_ejemplo_1.head(10)\n",
    "\n",
    "#### 💡 EJEMPLO 2 (UNIFICACIÓN DE DATAFRAMES A NIVEL COLUMNAR - HORIZONTAL) \n",
    "##----- PARA LA UNIÓN EN HORIZONTAL, NO DEBEN EXISTIR COLUMNAS CON NOMBRE IGUALES\n",
    "df_ejemplo_2 = pl.concat([df_uno,df_tres],how=\"horizontal\")\n",
    "# df_ejemplo_2.shape[0] ## Cantidad de registros: 5\n",
    "# df_ejemplo_2.head(10)\n",
    "\n",
    "#### 💡 EJEMPLO 3 (UNIFICACIÓN DE DATAFRAMES A NIVEL COLUMNAR - DIAGONAL) \n",
    "df_ejemplo_3 = pl.concat([df_uno,df_tres],how=\"diagonal\")\n",
    "# df_ejemplo_3.shape[0] ## Cantidad de registros: 10\n",
    "# df_ejemplo_3.head(10)\n",
    "\n",
    "# #### 💡 EJEMPLO 4 (UNIFICACIÓN DE DATAFRAMES A NIVEL COLUMNAR - VERTICAL) ⬅️ CON DIFERENTES NOMBRES \n",
    "\n",
    "# ##---- PASO A). RENOMBRAR LAS COLUMNAS\n",
    "# df_cuatro = df_cuatro.rename({\"Cat\":\"Categorias\",\"Años\":\"Año\",\"Vent\":\"Ventas\"}) ##⬅️ EJECUTAMOS UNA SOLA VEZ\n",
    "# df_cuatro.head()\n",
    "\n",
    "# ##---- PASO B). UNIFICAR DATASETS/DATAFRAMES\n",
    "\n",
    "df_ejemplo_4 = pl.concat([df_uno,df_cuatro],how=\"vertical\")\n",
    "# df_ejemplo_4.shape[0] ## Cantidad de registros: 10\n",
    "# df_ejemplo_4.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54715cf",
   "metadata": {},
   "source": [
    "#### Fase 6. Exportación de Datos en Polars 🐻‍❄️🗃️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7132d042",
   "metadata": {},
   "source": [
    "Esta fase final en la manipulación de datos brinda permite que la información previamente procesada se pueda consumir, intercambiar o almacenar. Su importancia radica en garantizar información limpia y transformada esté disponible para otros sistemas, análisis posteriores o toma de decisiones, ya sea en archivos planos (CSV, Excel), estructurados (JSON, Parquet) o de alto rendimiento en entornos de Big Data (Parquet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87d7424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 💡 UTLIZAREMOS DE EJEMPLO ESTE DATASET\n",
    "data = {\n",
    "    \"id\": [1, 2, 3, 3, None],\n",
    "    \"nombre\": [\"Ana\", \"Luis\", \"Karla\", \"Karla\", \"Pedro\"],\n",
    "    \"edad\": [23, 35, 29, 29, None]\n",
    "}\n",
    "import polars as pl\n",
    "df = pl.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4299620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ✅ Realizaremos una Limpieza básica\n",
    "df = df.drop_nulls()                 # eliminar filas con valores nulos\n",
    "df = df.unique()        # eliminar duplicados\n",
    "df = df.with_columns(\n",
    "    pl.col(\"id\").cast(dtype=pl.Int64).alias(\"id\") # castear columna a entero\n",
    ")\n",
    "df = df.rename({\"nombre\":\"Nombre\",\"edad\":\"Edad\"},strict=True) # Renombrar columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfee8847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV exportado.\n"
     ]
    }
   ],
   "source": [
    "### ✅ Exportando el dataset\n",
    "## ----- Formato CSV(Comma Separated Values) \n",
    "\"\"\"\n",
    "    SINTAXIS: \n",
    "        dataset_nombre.write_csv(file=\"RutaAlmacenarArchivoExportado\",separator=\"SeparadorDatos\")    \n",
    "    \n",
    "    ✔️ file: Es el parámetro que permite especificar la ruta donde se almacenará el archivo.\n",
    "    ✔️ separator: Es el parámetro que permite especificar el signo de puntuación a separar los datos (Mayormente utilizamos (,) o (;) ).\n",
    "    \n",
    "    ### 🧠 TENER EN CUENTA QUE LA EXTENSIÓN DEBE SER IGUAL A LA FUNCIÓN DE EXPORTACIÓN DEL ARCHIVO\n",
    "    ###     Por ejemplo: ✅ write_csv-> .csv ---- ❌ write_csv -> .xlsx\n",
    "\"\"\"\n",
    "### 💡 EJEMPLO\n",
    "df.write_csv(file=\"../datasets/fase_exportacion/polars_export.csv\", separator=\",\")\n",
    "print(\"Archivo CSV exportado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6023b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo Excel exportado.\n"
     ]
    }
   ],
   "source": [
    "### ✅ Exportando el dataset\n",
    "## ----- Formato EXCEL\n",
    "\"\"\"\n",
    "    SINTAXIS: \n",
    "        dataset_nombre.df.write_excel(workbook=\"RutaAlmacenarArchivoExportado\",worksheet=\"NombreDeLaHojaDelExcel\")    \n",
    "    \n",
    "    ✔️ workbook: Es el parámetro que permite especificar la ruta donde se almacenará el archivo.\n",
    "    ✔️ worksheet: Es el parámetro que permite establecer el nombre de la hoja donde se almacenará el archivo excel.\n",
    "    \n",
    "    ### 🧠 TENER EN CUENTA QUE LA EXTENSIÓN DEBE SER IGUAL A LA FUNCIÓN DE EXPORTACIÓN DEL ARCHIVO\n",
    "    ###     Por ejemplo: ✅ write_excel-> .xlsx ---- ❌ write_excel -> .csv\n",
    "    \n",
    "    ### 🧠 SE MOSTRARÁN LOS EJEMPLOS CON LOS PRINCIPALES PARÁMETROS (workbook, worksheet)\n",
    "    ### ✔️ Necesitarás instalar el pluging para Polars (creación de archivos excel): pip install xlsxwriter\n",
    "\"\"\"\n",
    "### 💡 EJEMPLO\n",
    "df.write_excel(workbook=\"../datasets/fase_exportacion/polars_export.xlsx\",worksheet=\"HojaPrueba\") \n",
    "print(\"Archivo Excel exportado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010c357d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo JSON Básico exportado.\n"
     ]
    }
   ],
   "source": [
    "### ✅ Exportando el dataset\n",
    "## ----- Formato JSON (JAVASCRIPT OBJECT NOTATION)\n",
    "\"\"\"\n",
    "    SINTAXIS: \n",
    "        dataset_nombre.write_json(file=\"RutaAlmacenarArchivoExportado\")  \n",
    "    \n",
    "    ✔️ file: Es el parámetro que permite especificar la ruta donde se almacenará el archivo.\n",
    "              \n",
    "    ### 🧠 TENER EN CUENTA QUE LA EXTENSIÓN DEBE SER IGUAL A LA FUNCIÓN DE EXPORTACIÓN DEL ARCHIVO\n",
    "    ###     Por ejemplo: ✅ write_json-> .json ---- ❌ write_json -> .xlsx\n",
    "\"\"\"\n",
    "# df.write_json()\n",
    "# ### 💡 EJEMPLO \n",
    "df.write_json(file=\"../datasets/fase_exportacion/polars_export_basico.json\")\n",
    "print(\"Archivo JSON Básico exportado.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcb576f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo PARQUET exportado.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### ✅ Exportando el dataset\n",
    "## ----- Formato PARQUET (FORMATO COLUMNAR OPTIMIZADO PARA SOLUCIONES DE BIG DATA)\n",
    "\"\"\"\n",
    "    SINTAXIS: \n",
    "        dataset_nombre.write_parquet(file=\"RutaAlmacenarArchivoExportado\",compression=\"brotli|gzip|lzo|snappy|zstd\")\n",
    "    \n",
    "    ✔️ file: Es el parámetro que permite especificar la ruta donde se almacenará el archivo.\n",
    "    ✔️ compression: Es el parámetro que permite reducir el tamaño del archivo.\n",
    "                  \n",
    "    ### 🧠 TENER EN CUENTA QUE LA EXTENSIÓN DEBE SER IGUAL A LA FUNCIÓN DE EXPORTACIÓN DEL ARCHIVO\n",
    "    ###     Por ejemplo: ✅ write_parquet-> .parquet ---- ❌ write_parquet -> .xlsx\n",
    "    ### 💡 EN LOS SIGUIENTES EJEMPLOS UTILIZAREMOS LOS PARÁMETROS CON LOS VALORES MEJORES OPTIMIZADOS.\n",
    "\"\"\"\n",
    "### 💡 EJEMPLO 1: EXPOTANDO FORMATO PARQUET (compression='snappy' y engine='pyarrow')\n",
    "df.write_parquet(file=\"../datasets/fase_exportacion/polars_export_parquet.parquet\",compression=\"snappy\")\n",
    "print(\"Archivo PARQUET exportado.\")\n",
    "\n",
    "### 🧠 A tener en cuenta:\n",
    "\"\"\"\n",
    "compression=\"snappy\"  # Rápido, compresión moderada\n",
    "compression=\"gzip\"    # Lento, alta compresión\n",
    "compression=\"brotli\"  # Mejor compresión, más lento\n",
    "\n",
    "\"\"\"\n",
    "print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cb401c5",
   "metadata": {},
   "source": [
    "## âš¡ AnalÃ­tica Turbo con Polars: Fundamentos que todo Analista Moderno debe conocer ğŸ»â€â„ï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba008a1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "ğŸ‘¨â€ğŸ’» Autor: Brayan Neciosup  \n",
    "ğŸ“ Portafolio: [brayanneciosup](https://bryanneciosup626.wixsite.com/brayandataanalitics)  \n",
    "ğŸ”— LinkedIn: [linkedin.com/brayanneciosup](https://www.linkedin.com/in/brayan-rafael-neciosup-bola%C3%B1os-407a59246/)  \n",
    "ğŸ’» GitHub: [github.com/BrayanR03](https://github.com/BrayanR03)  \n",
    "ğŸ“š Serie: Fundamentos de Pandas y Polars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c231f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar librerÃ­a de polars: pip install polars\n",
    "# Importamos la librerÃ­a\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80701532",
   "metadata": {},
   "source": [
    "### ğŸ“Œ ManipulaciÃ³n de Datos en Polars: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b3078e",
   "metadata": {},
   "source": [
    "La manipulaciÃ³n de datos, tambiÃ©n conocida como data wrangling, es una fase \n",
    "fundamental en todo proyecto de anÃ¡lisis de datos. Consiste en transformar \n",
    "un dataset crudo, es decir, datos en su forma original, posiblemente desordenada o\n",
    "incompleta en un formato estructurado y Ãºtil, como un DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3be9c10",
   "metadata": {},
   "source": [
    "#### Fase 1. Fuentes de Datos ğŸ—ƒï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581dd6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Polars ğŸ»â€â„ï¸ permite leer datos desde mÃºltiples fuentes como archivos CSV, Excel, JSON, \n",
    "    bases de datos SQL, entre otros formatos comunes. Esta flexibilidad facilita el trabajo\n",
    "    con datasets provenientes de distintos orÃ­genes, tanto locales como remotos de manera optimizada.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "503d90ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eventos_logs.json', 'json_basico.json', 'Pedidos.xlsx', 'penguins.csv', 'titanic.csv']\n"
     ]
    }
   ],
   "source": [
    "# Paso A). DEFINIR LA CARPETA ORIGEN DE DONDE PROVIENE NUESTROS DATASETS (LOCAL)\n",
    "\"\"\"\n",
    "    ğŸ“ SINTAXIS: \n",
    "        \n",
    "        carpeta_origen = \"RutaCarpetaOrigen\"\n",
    "    \n",
    "    ### ğŸ§  Va a depender en que entorno nos encontremos porque las rutas \n",
    "    ###     de carpetas pueden ser (\\) o (/).\n",
    "\"\"\"\n",
    "# ğŸ’¡ EJEMPLO 1 (Ruta completa):\n",
    "\n",
    "# carpeta_origen = \"C:/Users/USER/Documents/FundamentosPandasPolars/datasets\" \n",
    "\n",
    "# print(carpeta_origen)\n",
    "\n",
    "# ğŸ’¡ EJEMPLO 2 (Ruta relativa):\n",
    "\n",
    "carpeta_origen = f\"../datasets/\"\n",
    "# print(carpeta_origen)\n",
    "import os # â¬…ï¸ Permite trabajar con archivos\n",
    "print(os.listdir(carpeta_origen)) # â¬…ï¸ Mostrar los archivos de la carpeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d8968a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso B). DEFINIR EL NOMBRE DEL ARCHIVO DEL DATASET\n",
    "\"\"\"\n",
    "    ğŸ“ SINTAXIS:\n",
    "    \n",
    "        nombre_archivo = \"NombreArchivo.extension\"\n",
    "\n",
    "    ### ğŸ§  DependerÃ¡ de la extensiÃ³n del archivo para indicarle a Polars que funciÃ³n utilizar.\n",
    "\"\"\"\n",
    "# ğŸ’¡ EJEMPLO 1 (.csv): \n",
    "archivos_csv = \"penguins.csv\"\n",
    "\n",
    "# ğŸ’¡ EJEMPLO 2 (.xlsx): \n",
    "archivos_xlsx = \"Pedidos.xlsx\"\n",
    "\n",
    "# ğŸ’¡ EJEMPLO 3 (.json): \n",
    "archivos_json = \"eventos_logs.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d64c3212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>evento.usuario_id</th><th>evento.accion</th><th>evento.timestamp</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;U846&quot;</td><td>&quot;compra&quot;</td><td>&quot;2025-05-25T21:07:47.202219Z&quot;</td></tr><tr><td>&quot;U321&quot;</td><td>&quot;registro&quot;</td><td>&quot;2025-05-23T11:50:47.202219Z&quot;</td></tr><tr><td>&quot;U813&quot;</td><td>&quot;login&quot;</td><td>&quot;2025-05-25T19:09:47.202219Z&quot;</td></tr><tr><td>&quot;U677&quot;</td><td>&quot;registro&quot;</td><td>&quot;2025-05-27T09:41:47.202219Z&quot;</td></tr><tr><td>&quot;U425&quot;</td><td>&quot;compra&quot;</td><td>&quot;2025-05-23T14:44:47.202219Z&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ evento.usuario_id â”† evento.accion â”† evento.timestamp            â”‚\n",
       "â”‚ ---               â”† ---           â”† ---                         â”‚\n",
       "â”‚ str               â”† str           â”† str                         â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ U846              â”† compra        â”† 2025-05-25T21:07:47.202219Z â”‚\n",
       "â”‚ U321              â”† registro      â”† 2025-05-23T11:50:47.202219Z â”‚\n",
       "â”‚ U813              â”† login         â”† 2025-05-25T19:09:47.202219Z â”‚\n",
       "â”‚ U677              â”† registro      â”† 2025-05-27T09:41:47.202219Z â”‚\n",
       "â”‚ U425              â”† compra        â”† 2025-05-23T14:44:47.202219Z â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paso C). LECTURA DE LOS ARCHIVOS (PASO A + PASO B)\n",
    "\"\"\"\n",
    "    ### ğŸ§  Para los archivos .csv, se recomienda conocer el separador o\n",
    "    ###     delimitador presente en el archivo e indicarle a Polars.\n",
    "\n",
    "    ğŸ“ SINTAXIS:\n",
    "    \n",
    "        dataset_nombre = pl.read_extensiÃ³n(carpeta_origen+nombre_archivo.extensiÃ³n)\n",
    "\"\"\"\n",
    "import polars as pl # âœ… No olvidar importar polars al inicio del notebook\n",
    "\n",
    "# ğŸ’¡ EJEMPLO 1 (Lectura de .csv): \n",
    "\n",
    "dataset_csv = pl.read_csv(carpeta_origen+archivos_csv,separator=\",\") # â¬…ï¸ Indicamos el delimitador en separator.\n",
    "# dataset_csv.head() # â¬…ï¸ FunciÃ³n que permite leer y retornar los 5 primeros registros del archivo.\n",
    "\"\"\"===============================================================================================\"\"\"\n",
    "# ğŸ’¡ EJEMPLO 2 (Lectura de .xlsx): \n",
    "\n",
    "dataset_excel = pl.read_excel(\n",
    "                 source=carpeta_origen+archivos_xlsx,\n",
    "                 sheet_name=\"Hoja1\") # â¬…ï¸ Indicamos el nombre de la Hoja donde se encuentra\n",
    "                                     #     la informaciÃ³n.\n",
    "# dataset_excel.head() # â¬…ï¸ FunciÃ³n que permite leer y retornar los 5 primeros registros del archivo.\n",
    "\n",
    "\"\"\" âš ï¸ En caso les arroje error sobre: \" requiered package 'fastexcel' not found \"\n",
    "       solo instalemos el mÃ³dulo con: pip install fastexcel\n",
    "'\"\"\"\n",
    "# dataset_excel.head() # â¬…ï¸ FunciÃ³n que permite leer y retornar los 5 primeros registros del archivo.\n",
    "\"\"\"===============================================================================================\"\"\"\n",
    "# ğŸ’¡ EJEMPLO 3 (Lectura de .json):\n",
    "\n",
    "### Archivo bÃ¡sico JSON\n",
    "archivo_json_basico = \"json_basico.json\" # â¬…ï¸ Nombre de archivo bÃ¡sico JSON\n",
    "dataset_json1 = pl.read_json(carpeta_origen+archivo_json_basico) # â¬…ï¸ Lectura de JSON bÃ¡sico\n",
    "# dataset_json1.head()\n",
    "\n",
    "# Archivo complejo JSON\n",
    "import json # â¬…ï¸ Utilizaremos la librerÃ­a json para el aplanamiento del Archivo JSON complejo.\n",
    "archivo_json_complejo = \"eventos_logs.json\" # â¬…ï¸ Nombre de archivo complejo JSON\n",
    "with open(carpeta_origen + archivo_json_complejo, \"r\", encoding=\"utf-8\") as file_data:\n",
    "    data_archivo_json_complejo = json.load(file_data)\n",
    "dataset_json2 = pl.json_normalize(data_archivo_json_complejo) # â¬…ï¸ Lectura de archivo JSON complejo.\n",
    "dataset_json2.head() # â¬…ï¸ FunciÃ³n que permite leer y retornar los 5 primeros registros del archivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af78c5f",
   "metadata": {},
   "source": [
    "#### Fase 2. ExploraciÃ³n Inicial ğŸ”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbeb76e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>species</th><th>island</th><th>bill_length_mm</th><th>bill_depth_mm</th><th>flipper_length_mm</th><th>body_mass_g</th><th>sex</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>39.1</td><td>18.7</td><td>181.0</td><td>3750.0</td><td>&quot;Male&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>39.5</td><td>17.4</td><td>186.0</td><td>3800.0</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>40.3</td><td>18.0</td><td>195.0</td><td>3250.0</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>36.7</td><td>19.3</td><td>193.0</td><td>3450.0</td><td>&quot;Female&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ species â”† island    â”† bill_length_mm â”† bill_depth_mm â”† flipper_length_mm â”† body_mass_g â”† sex    â”‚\n",
       "â”‚ ---     â”† ---       â”† ---            â”† ---           â”† ---               â”† ---         â”† ---    â”‚\n",
       "â”‚ str     â”† str       â”† f64            â”† f64           â”† f64               â”† f64         â”† str    â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ Adelie  â”† Torgersen â”† 39.1           â”† 18.7          â”† 181.0             â”† 3750.0      â”† Male   â”‚\n",
       "â”‚ Adelie  â”† Torgersen â”† 39.5           â”† 17.4          â”† 186.0             â”† 3800.0      â”† Female â”‚\n",
       "â”‚ Adelie  â”† Torgersen â”† 40.3           â”† 18.0          â”† 195.0             â”† 3250.0      â”† Female â”‚\n",
       "â”‚ Adelie  â”† Torgersen â”† null           â”† null          â”† null              â”† null        â”† null   â”‚\n",
       "â”‚ Adelie  â”† Torgersen â”† 36.7           â”† 19.3          â”† 193.0             â”† 3450.0      â”† Female â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Utilizaremos el dataset de penguins (dataset de Seaborn importado en un csv)\n",
    "\"\"\"\n",
    "df_penguins = pl.read_csv(\"../datasets/penguins.csv\",separator=\",\") # â¬…ï¸ Accedemos al archivo en la carpeta datasets\n",
    "df_penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a712abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column_1</th><th>column_2</th><th>column_3</th><th>column_4</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;DetallePedidosPedidoID&quot;</td><td>&quot;PedidoFechaHoraRegistro&quot;</td><td>&quot;PedidoEstado&quot;</td><td>&quot;Total&quot;</td></tr><tr><td>&quot;1&quot;</td><td>&quot;2025-05-26 18:02:01.240&quot;</td><td>&quot;F&quot;</td><td>&quot;524361.11&quot;</td></tr><tr><td>&quot;2&quot;</td><td>&quot;2025-05-26 18:02:02.430&quot;</td><td>&quot;F&quot;</td><td>&quot;524387.46&quot;</td></tr><tr><td>&quot;3&quot;</td><td>&quot;2025-05-26 18:02:46.287&quot;</td><td>&quot;F&quot;</td><td>&quot;515269.86&quot;</td></tr><tr><td>&quot;4&quot;</td><td>&quot;2025-05-26 18:02:46.290&quot;</td><td>&quot;F&quot;</td><td>&quot;523261.27&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ column_1               â”† column_2                â”† column_3     â”† column_4  â”‚\n",
       "â”‚ ---                    â”† ---                     â”† ---          â”† ---       â”‚\n",
       "â”‚ str                    â”† str                     â”† str          â”† str       â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ DetallePedidosPedidoID â”† PedidoFechaHoraRegistro â”† PedidoEstado â”† Total     â”‚\n",
       "â”‚ 1                      â”† 2025-05-26 18:02:01.240 â”† F            â”† 524361.11 â”‚\n",
       "â”‚ 2                      â”† 2025-05-26 18:02:02.430 â”† F            â”† 524387.46 â”‚\n",
       "â”‚ 3                      â”† 2025-05-26 18:02:46.287 â”† F            â”† 515269.86 â”‚\n",
       "â”‚ 4                      â”† 2025-05-26 18:02:46.290 â”† F            â”† 523261.27 â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    A). Quitar encabezados originales provenientes del Dataset.\n",
    "    \n",
    "        ğŸ“ SINTAXIS:\n",
    "        \n",
    "            dataset_nombre = pl.read_extension(ruta_carpeta_archivo,separator=\"Delimitador\",has_header=True|False)\n",
    "            \n",
    "            ğŸ’¡ Importante: has_header, es el parÃ¡metro que si establecemos en False, los encabezados se vuelven parte\n",
    "                           de los registros del dataset, ademÃ¡s, Polars agregarÃ¡ la posiciÃ³n de cada columna\n",
    "                           con un prefijo: columna_posiciÃ³n.\n",
    "                                        \n",
    "            ### ğŸ§  Tener en cuenta que solo se aplicarÃ¡ a las extensiones .excel y .csv\n",
    "    \n",
    "#### PARA LOS EJEMPLOS USAREMOS ALGUNOS DATASET PREVIAMENTE VISTOS EN LA FASE 1.\n",
    "\"\"\"\n",
    "\n",
    "# ğŸ’¡ EJEMPLO 1: Archivo CSV \n",
    "\n",
    "df_penguins = pl.read_csv(carpeta_origen+archivos_csv,separator=\",\",has_header=True) #â¬…ï¸ Mostramos los encabezados\n",
    "# df_penguins.head()\n",
    "\n",
    "# ğŸ’¡ EJEMPLO 2: Archivo CSV\n",
    "\n",
    "df_penguins = pl.read_csv(carpeta_origen+archivos_csv,separator=\",\",has_header=False) #â¬…ï¸ Ocultamos los encabezados\n",
    "# df_penguins.head()\n",
    "\n",
    "# ğŸ’¡ EJEMPLO 3: Archivo EXCEL \n",
    "\n",
    "df_penguins_excel = pl.read_excel(carpeta_origen+archivos_xlsx,sheet_name=\"Hoja1\",has_header=True) #â¬…ï¸ Mostramos los encabezados\n",
    "# df_penguins_excel.head()\n",
    "\n",
    "# ğŸ’¡ EJEMPLO 4: Archivo EXCEL\n",
    "\n",
    "df_penguins_excel = pl.read_excel(carpeta_origen+archivos_xlsx,sheet_name=\"Hoja1\",has_header=False) #â¬…ï¸ Ocultamos los encabezados\n",
    "df_penguins_excel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90290b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column_1</th><th>column_2</th><th>column_3</th><th>column_4</th><th>column_5</th><th>column_6</th><th>column_7</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;species&quot;</td><td>&quot;island&quot;</td><td>&quot;bill_length_mm&quot;</td><td>&quot;bill_depth_mm&quot;</td><td>&quot;flipper_length_mm&quot;</td><td>&quot;body_mass_g&quot;</td><td>&quot;sex&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>&quot;39.1&quot;</td><td>&quot;18.7&quot;</td><td>&quot;181.0&quot;</td><td>&quot;3750.0&quot;</td><td>&quot;Male&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>&quot;39.5&quot;</td><td>&quot;17.4&quot;</td><td>&quot;186.0&quot;</td><td>&quot;3800.0&quot;</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>&quot;40.3&quot;</td><td>&quot;18.0&quot;</td><td>&quot;195.0&quot;</td><td>&quot;3250.0&quot;</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>&quot;36.7&quot;</td><td>&quot;19.3&quot;</td><td>&quot;193.0&quot;</td><td>&quot;3450.0&quot;</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>&quot;39.3&quot;</td><td>&quot;20.6&quot;</td><td>&quot;190.0&quot;</td><td>&quot;3650.0&quot;</td><td>&quot;Male&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>&quot;38.9&quot;</td><td>&quot;17.8&quot;</td><td>&quot;181.0&quot;</td><td>&quot;3625.0&quot;</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>&quot;39.2&quot;</td><td>&quot;19.6&quot;</td><td>&quot;195.0&quot;</td><td>&quot;4675.0&quot;</td><td>&quot;Male&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>&quot;34.1&quot;</td><td>&quot;18.1&quot;</td><td>&quot;193.0&quot;</td><td>&quot;3475.0&quot;</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 7)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ column_1 â”† column_2  â”† column_3       â”† column_4      â”† column_5        â”† column_6    â”† column_7 â”‚\n",
       "â”‚ ---      â”† ---       â”† ---            â”† ---           â”† ---             â”† ---         â”† ---      â”‚\n",
       "â”‚ str      â”† str       â”† str            â”† str           â”† str             â”† str         â”† str      â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ species  â”† island    â”† bill_length_mm â”† bill_depth_mm â”† flipper_length_ â”† body_mass_g â”† sex      â”‚\n",
       "â”‚          â”†           â”†                â”†               â”† mm              â”†             â”†          â”‚\n",
       "â”‚ Adelie   â”† Torgersen â”† 39.1           â”† 18.7          â”† 181.0           â”† 3750.0      â”† Male     â”‚\n",
       "â”‚ Adelie   â”† Torgersen â”† 39.5           â”† 17.4          â”† 186.0           â”† 3800.0      â”† Female   â”‚\n",
       "â”‚ Adelie   â”† Torgersen â”† 40.3           â”† 18.0          â”† 195.0           â”† 3250.0      â”† Female   â”‚\n",
       "â”‚ Adelie   â”† Torgersen â”† null           â”† null          â”† null            â”† null        â”† null     â”‚\n",
       "â”‚ Adelie   â”† Torgersen â”† 36.7           â”† 19.3          â”† 193.0           â”† 3450.0      â”† Female   â”‚\n",
       "â”‚ Adelie   â”† Torgersen â”† 39.3           â”† 20.6          â”† 190.0           â”† 3650.0      â”† Male     â”‚\n",
       "â”‚ Adelie   â”† Torgersen â”† 38.9           â”† 17.8          â”† 181.0           â”† 3625.0      â”† Female   â”‚\n",
       "â”‚ Adelie   â”† Torgersen â”† 39.2           â”† 19.6          â”† 195.0           â”† 4675.0      â”† Male     â”‚\n",
       "â”‚ Adelie   â”† Torgersen â”† 34.1           â”† 18.1          â”† 193.0           â”† 3475.0      â”† null     â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    B). Mostrar los N primeros registros de un dataset\n",
    "    \n",
    "        ğŸ“ SINTAXIS:\n",
    "    \n",
    "            dataset_nombre.head(NÃºmeroDeRegistros) â¬…ï¸ Indicamos un nÃºmero para la cantidad de registros a mostrar    \n",
    "\"\"\"\n",
    "# ğŸ’¡ EJEMPO 1: \n",
    "\n",
    "# df_penguins.head(5) ## â¬…ï¸ Mostrar 5 primeros registros del dataset\n",
    "\n",
    "# ğŸ’¡ EJEMPO 2: \n",
    "\n",
    "df_penguins.head(10) ## â¬…ï¸ Mostrar 10 primeros registros del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70b98fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column_1</th><th>column_2</th><th>column_3</th><th>column_4</th><th>column_5</th><th>column_6</th><th>column_7</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Gentoo&quot;</td><td>&quot;Biscoe&quot;</td><td>&quot;46.2&quot;</td><td>&quot;14.1&quot;</td><td>&quot;217.0&quot;</td><td>&quot;4375.0&quot;</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Gentoo&quot;</td><td>&quot;Biscoe&quot;</td><td>&quot;55.1&quot;</td><td>&quot;16.0&quot;</td><td>&quot;230.0&quot;</td><td>&quot;5850.0&quot;</td><td>&quot;Male&quot;</td></tr><tr><td>&quot;Gentoo&quot;</td><td>&quot;Biscoe&quot;</td><td>&quot;44.5&quot;</td><td>&quot;15.7&quot;</td><td>&quot;217.0&quot;</td><td>&quot;4875.0&quot;</td><td>null</td></tr><tr><td>&quot;Gentoo&quot;</td><td>&quot;Biscoe&quot;</td><td>&quot;48.8&quot;</td><td>&quot;16.2&quot;</td><td>&quot;222.0&quot;</td><td>&quot;6000.0&quot;</td><td>&quot;Male&quot;</td></tr><tr><td>&quot;Gentoo&quot;</td><td>&quot;Biscoe&quot;</td><td>&quot;47.2&quot;</td><td>&quot;13.7&quot;</td><td>&quot;214.0&quot;</td><td>&quot;4925.0&quot;</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Gentoo&quot;</td><td>&quot;Biscoe&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;Gentoo&quot;</td><td>&quot;Biscoe&quot;</td><td>&quot;46.8&quot;</td><td>&quot;14.3&quot;</td><td>&quot;215.0&quot;</td><td>&quot;4850.0&quot;</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Gentoo&quot;</td><td>&quot;Biscoe&quot;</td><td>&quot;50.4&quot;</td><td>&quot;15.7&quot;</td><td>&quot;222.0&quot;</td><td>&quot;5750.0&quot;</td><td>&quot;Male&quot;</td></tr><tr><td>&quot;Gentoo&quot;</td><td>&quot;Biscoe&quot;</td><td>&quot;45.2&quot;</td><td>&quot;14.8&quot;</td><td>&quot;212.0&quot;</td><td>&quot;5200.0&quot;</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Gentoo&quot;</td><td>&quot;Biscoe&quot;</td><td>&quot;49.9&quot;</td><td>&quot;16.1&quot;</td><td>&quot;213.0&quot;</td><td>&quot;5400.0&quot;</td><td>&quot;Male&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 7)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ column_1 â”† column_2 â”† column_3 â”† column_4 â”† column_5 â”† column_6 â”† column_7 â”‚\n",
       "â”‚ ---      â”† ---      â”† ---      â”† ---      â”† ---      â”† ---      â”† ---      â”‚\n",
       "â”‚ str      â”† str      â”† str      â”† str      â”† str      â”† str      â”† str      â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ Gentoo   â”† Biscoe   â”† 46.2     â”† 14.1     â”† 217.0    â”† 4375.0   â”† Female   â”‚\n",
       "â”‚ Gentoo   â”† Biscoe   â”† 55.1     â”† 16.0     â”† 230.0    â”† 5850.0   â”† Male     â”‚\n",
       "â”‚ Gentoo   â”† Biscoe   â”† 44.5     â”† 15.7     â”† 217.0    â”† 4875.0   â”† null     â”‚\n",
       "â”‚ Gentoo   â”† Biscoe   â”† 48.8     â”† 16.2     â”† 222.0    â”† 6000.0   â”† Male     â”‚\n",
       "â”‚ Gentoo   â”† Biscoe   â”† 47.2     â”† 13.7     â”† 214.0    â”† 4925.0   â”† Female   â”‚\n",
       "â”‚ Gentoo   â”† Biscoe   â”† null     â”† null     â”† null     â”† null     â”† null     â”‚\n",
       "â”‚ Gentoo   â”† Biscoe   â”† 46.8     â”† 14.3     â”† 215.0    â”† 4850.0   â”† Female   â”‚\n",
       "â”‚ Gentoo   â”† Biscoe   â”† 50.4     â”† 15.7     â”† 222.0    â”† 5750.0   â”† Male     â”‚\n",
       "â”‚ Gentoo   â”† Biscoe   â”† 45.2     â”† 14.8     â”† 212.0    â”† 5200.0   â”† Female   â”‚\n",
       "â”‚ Gentoo   â”† Biscoe   â”† 49.9     â”† 16.1     â”† 213.0    â”† 5400.0   â”† Male     â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    C). Mostrar los N Ãºltimos registros de un dataset\n",
    "    \n",
    "        ğŸ“ SINTAXIS:\n",
    "    \n",
    "            dataset_nombre.tail(NÃºmeroDeRegistros) â¬…ï¸ Indicamos un nÃºmero para la cantidad de registros a mostrar    \n",
    "\"\"\"\n",
    "# ğŸ’¡ EJEMPO 1: \n",
    "\n",
    "# df_penguins.tail(5) ## â¬…ï¸ Mostrar 5 Ãºltimos registros del dataset\n",
    "\n",
    "# ğŸ’¡ EJEMPO 2: \n",
    "\n",
    "df_penguins.tail(10) ## â¬…ï¸ Mostrar 10 Ãºltimos registros del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73203557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    D). Mostrar el volÃºmen del dataset (Cantidad de filas y columnas respectivamente) \n",
    "    \n",
    "        ğŸ“ SINTAXIS:\n",
    "    \n",
    "            dataset_nombre.shape â¬…ï¸ Nos muestra la cantidad de filas y columnas en forma de tupla (,)\n",
    "            \n",
    "            #### ğŸ§  Podemos acceder a la cantidad de filas o columnas basÃ¡ndonos en la posiciÃ³n\n",
    "                     de los datos que retorna la tupla, gracias a .shape â¡ï¸ 0 = filas y 1 = columnas    \n",
    "\"\"\"\n",
    "# ğŸ’¡ EJEMPO 1: \n",
    "\n",
    "df_penguins.shape ## â¬…ï¸ Muestra el volÃºmen de registros del dataset en forma de tupla. (CantidadFilas,CantidadColumnas)\n",
    "\n",
    "# ğŸ’¡ EJEMPO 2: \n",
    "\n",
    "df_penguins.shape[0] ## â¬…ï¸ Muestra la cantidad de registros (filas) del dataset\n",
    "\n",
    "# ğŸ’¡ EJEMPO 3: \n",
    "\n",
    "df_penguins.shape[1] ## â¬…ï¸ Muestra la cantidad de columnas del dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f697ed18",
   "metadata": {},
   "source": [
    "#### Fase 3. TransformaciÃ³n de Datos ğŸ’±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ba8720",
   "metadata": {},
   "source": [
    "##### 3.1 Datos Cualitativos ğŸ” "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2937a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>species</th><th>island</th><th>bill_length_mm</th><th>bill_depth_mm</th><th>flipper_length_mm</th><th>body_mass_g</th><th>sex</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>&quot;ADELIE&quot;</td><td>&quot;Torgersen&quot;</td><td>39.1</td><td>18.7</td><td>181.0</td><td>3750.0</td><td>&quot;Male&quot;</td></tr><tr><td>&quot;ADELIE&quot;</td><td>&quot;Torgersen&quot;</td><td>39.5</td><td>17.4</td><td>186.0</td><td>3800.0</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;ADELIE&quot;</td><td>&quot;Torgersen&quot;</td><td>40.3</td><td>18.0</td><td>195.0</td><td>3250.0</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;ADELIE&quot;</td><td>&quot;Torgersen&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;ADELIE&quot;</td><td>&quot;Torgersen&quot;</td><td>36.7</td><td>19.3</td><td>193.0</td><td>3450.0</td><td>&quot;Female&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ species â”† island    â”† bill_length_mm â”† bill_depth_mm â”† flipper_length_mm â”† body_mass_g â”† sex    â”‚\n",
       "â”‚ ---     â”† ---       â”† ---            â”† ---           â”† ---               â”† ---         â”† ---    â”‚\n",
       "â”‚ str     â”† str       â”† f64            â”† f64           â”† f64               â”† f64         â”† str    â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ ADELIE  â”† Torgersen â”† 39.1           â”† 18.7          â”† 181.0             â”† 3750.0      â”† Male   â”‚\n",
       "â”‚ ADELIE  â”† Torgersen â”† 39.5           â”† 17.4          â”† 186.0             â”† 3800.0      â”† Female â”‚\n",
       "â”‚ ADELIE  â”† Torgersen â”† 40.3           â”† 18.0          â”† 195.0             â”† 3250.0      â”† Female â”‚\n",
       "â”‚ ADELIE  â”† Torgersen â”† null           â”† null          â”† null              â”† null        â”† null   â”‚\n",
       "â”‚ ADELIE  â”† Torgersen â”† 36.7           â”† 19.3          â”† 193.0             â”† 3450.0      â”† Female â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    A). CONVERTIR A MAYÃšSCULAS LOS DATOS CUALITATIVOS DE UNA COLUMNA EN UN DATASET\n",
    "    \n",
    "    ğŸ“ SINTAXIS:\n",
    "    \n",
    "        dataframe_nombre = dataframe_nombre.with_columns(\n",
    "            pl.col(NombreColumnaCualitativa).str.to_uppercase().alias(NombreColumnaCualitativa) \n",
    "        )\n",
    "    \n",
    "    ### ğŸ§  En este caso, debemos almacenar en una variable los cambios a realizar en el dataframe.\n",
    "\"\"\"\n",
    "\n",
    "# ğŸ’¡ EJEMPLO:\n",
    "\n",
    "df_penguins = df_penguins.with_columns(\n",
    "    pl.col(\"species\").str.to_uppercase().alias(\"species\") ## â¬…ï¸ Convertimos a mayÃºsculas los datos de la columna cualitativa \"\"species\"\"\n",
    ")\n",
    "df_penguins.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99166e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>species</th><th>island</th><th>bill_length_mm</th><th>bill_depth_mm</th><th>flipper_length_mm</th><th>body_mass_g</th><th>sex</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>&quot;adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>39.1</td><td>18.7</td><td>181.0</td><td>3750.0</td><td>&quot;Male&quot;</td></tr><tr><td>&quot;adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>39.5</td><td>17.4</td><td>186.0</td><td>3800.0</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>40.3</td><td>18.0</td><td>195.0</td><td>3250.0</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>36.7</td><td>19.3</td><td>193.0</td><td>3450.0</td><td>&quot;Female&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ species â”† island    â”† bill_length_mm â”† bill_depth_mm â”† flipper_length_mm â”† body_mass_g â”† sex    â”‚\n",
       "â”‚ ---     â”† ---       â”† ---            â”† ---           â”† ---               â”† ---         â”† ---    â”‚\n",
       "â”‚ str     â”† str       â”† f64            â”† f64           â”† f64               â”† f64         â”† str    â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ adelie  â”† Torgersen â”† 39.1           â”† 18.7          â”† 181.0             â”† 3750.0      â”† Male   â”‚\n",
       "â”‚ adelie  â”† Torgersen â”† 39.5           â”† 17.4          â”† 186.0             â”† 3800.0      â”† Female â”‚\n",
       "â”‚ adelie  â”† Torgersen â”† 40.3           â”† 18.0          â”† 195.0             â”† 3250.0      â”† Female â”‚\n",
       "â”‚ adelie  â”† Torgersen â”† null           â”† null          â”† null              â”† null        â”† null   â”‚\n",
       "â”‚ adelie  â”† Torgersen â”† 36.7           â”† 19.3          â”† 193.0             â”† 3450.0      â”† Female â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    B). CONVERTIR A MINÃšSCULAS LOS DATOS CUALITATIVOS DE UNA COLUMNA EN UN DATASET\n",
    "    \n",
    "    ğŸ“ SINTAXIS:\n",
    "    \n",
    "        dataframe_nombre = dataframe_nombre.with_columns(\n",
    "            pl.col(NombreColumnaCualitativa).str.to_lowercase().alias(NombreColumnaCualitativa) \n",
    "        )\n",
    "    \n",
    "    ### ğŸ§  En este caso, debemos almacenar en una variable los cambios a realizar en el dataframe.\n",
    "\"\"\"\n",
    "\n",
    "# ğŸ’¡ EJEMPLO:\n",
    "\n",
    "df_penguins = df_penguins.with_columns(\n",
    "    pl.col(\"species\").str.to_lowercase().alias(\"species\") ## â¬…ï¸ Convertimos a minÃºsculas los datos de la columna cualitativa \"\"species\"\"\n",
    ")\n",
    "df_penguins.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e585f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>species</th><th>island</th><th>bill_length_mm</th><th>bill_depth_mm</th><th>flipper_length_mm</th><th>body_mass_g</th><th>sex</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>39.1</td><td>18.7</td><td>181.0</td><td>3750.0</td><td>&quot;Male&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>39.5</td><td>17.4</td><td>186.0</td><td>3800.0</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>40.3</td><td>18.0</td><td>195.0</td><td>3250.0</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>36.7</td><td>19.3</td><td>193.0</td><td>3450.0</td><td>&quot;Female&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ species â”† island    â”† bill_length_mm â”† bill_depth_mm â”† flipper_length_mm â”† body_mass_g â”† sex    â”‚\n",
       "â”‚ ---     â”† ---       â”† ---            â”† ---           â”† ---               â”† ---         â”† ---    â”‚\n",
       "â”‚ str     â”† str       â”† f64            â”† f64           â”† f64               â”† f64         â”† str    â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ Adelie  â”† Torgersen â”† 39.1           â”† 18.7          â”† 181.0             â”† 3750.0      â”† Male   â”‚\n",
       "â”‚ Adelie  â”† Torgersen â”† 39.5           â”† 17.4          â”† 186.0             â”† 3800.0      â”† Female â”‚\n",
       "â”‚ Adelie  â”† Torgersen â”† 40.3           â”† 18.0          â”† 195.0             â”† 3250.0      â”† Female â”‚\n",
       "â”‚ Adelie  â”† Torgersen â”† null           â”† null          â”† null              â”† null        â”† null   â”‚\n",
       "â”‚ Adelie  â”† Torgersen â”† 36.7           â”† 19.3          â”† 193.0             â”† 3450.0      â”† Female â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    C). CONVERTIR A MAYÃšSCULA LA PRIMERA LETRA DE CADA DATO CUALITATIVOS DE UNA COLUMNA EN UN DATASET\n",
    "    \n",
    "    ğŸ“ SINTAXIS:\n",
    "    \n",
    "        dataframe_nombre = dataframe_nombre.with_columns(\n",
    "            pl.col(NombreColumnaCualitativa).str.to_titlecase().alias(NombreColumnaCualitativa) \n",
    "        )\n",
    "    \n",
    "    ### ğŸ§  En este caso, debemos almacenar en una variable los cambios a realizar en el dataframe.\n",
    "\"\"\"\n",
    "\n",
    "# ğŸ’¡ EJEMPLO:\n",
    "\n",
    "df_penguins = df_penguins.with_columns(\n",
    "    pl.col(\"species\").str.to_titlecase().alias(\"species\") ## â¬…ï¸ Convertimos la primera letra en mayÃºscula de cada dato en la columna cualitativa \"\"species\"\"\n",
    ")\n",
    "df_penguins.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77554794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>species</th><th>island</th><th>bill_length_mm</th><th>bill_depth_mm</th><th>flipper_length_mm</th><th>body_mass_g</th><th>sex</th><th>PrimeraLetraEnMayÃºscula</th><th>PrimeraLetraEnMinÃºscula</th><th>TodoDespuesDeUnaMayÃºscula</th><th>TodoDespuesDeUnaMinÃºscula</th><th>TodoDespuesDeUnNÃºmero</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>39.1</td><td>18.7</td><td>181.0</td><td>3750.0</td><td>&quot;Male&quot;</td><td>&quot;A&quot;</td><td>&quot;d&quot;</td><td>&quot;delie&quot;</td><td>&quot;&quot;</td><td>null</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>39.5</td><td>17.4</td><td>186.0</td><td>3800.0</td><td>&quot;Female&quot;</td><td>&quot;A&quot;</td><td>&quot;d&quot;</td><td>&quot;delie&quot;</td><td>&quot;&quot;</td><td>null</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>40.3</td><td>18.0</td><td>195.0</td><td>3250.0</td><td>&quot;Female&quot;</td><td>&quot;A&quot;</td><td>&quot;d&quot;</td><td>&quot;delie&quot;</td><td>&quot;&quot;</td><td>null</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;A&quot;</td><td>&quot;d&quot;</td><td>&quot;delie&quot;</td><td>&quot;&quot;</td><td>null</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>36.7</td><td>19.3</td><td>193.0</td><td>3450.0</td><td>&quot;Female&quot;</td><td>&quot;A&quot;</td><td>&quot;d&quot;</td><td>&quot;delie&quot;</td><td>&quot;&quot;</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 12)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ species â”† island    â”† bill_lengt â”† bill_dept â”† â€¦ â”† PrimeraLe â”† TodoDespu â”† TodoDespu â”† TodoDespu â”‚\n",
       "â”‚ ---     â”† ---       â”† h_mm       â”† h_mm      â”†   â”† traEnMinÃº â”† esDeUnaMa â”† esDeUnaMi â”† esDeUnNÃºm â”‚\n",
       "â”‚ str     â”† str       â”† ---        â”† ---       â”†   â”† scula     â”† yÃºscula   â”† nÃºscula   â”† ero       â”‚\n",
       "â”‚         â”†           â”† f64        â”† f64       â”†   â”† ---       â”† ---       â”† ---       â”† ---       â”‚\n",
       "â”‚         â”†           â”†            â”†           â”†   â”† str       â”† str       â”† str       â”† str       â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ Adelie  â”† Torgersen â”† 39.1       â”† 18.7      â”† â€¦ â”† d         â”† delie     â”†           â”† null      â”‚\n",
       "â”‚ Adelie  â”† Torgersen â”† 39.5       â”† 17.4      â”† â€¦ â”† d         â”† delie     â”†           â”† null      â”‚\n",
       "â”‚ Adelie  â”† Torgersen â”† 40.3       â”† 18.0      â”† â€¦ â”† d         â”† delie     â”†           â”† null      â”‚\n",
       "â”‚ Adelie  â”† Torgersen â”† null       â”† null      â”† â€¦ â”† d         â”† delie     â”†           â”† null      â”‚\n",
       "â”‚ Adelie  â”† Torgersen â”† 36.7       â”† 19.3      â”† â€¦ â”† d         â”† delie     â”†           â”† null      â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    D). EXTRAER DE CADA DATO CUALITATIVO UNA CADENA EN ESPECÃFICO MEDIANTE >>EXPRESIONES REGULARES<< EN UN DATASET\n",
    "    \n",
    "    ğŸ“ SINTAXIS:\n",
    "    \n",
    "        dataset_nombre[NombreColumnaCualitativa].str.extract()\n",
    "    \n",
    "    ### ğŸ§  En este caso, debemos almacenar en una variable los cambios a realizar en el dataframe\n",
    "\"\"\"\n",
    "##ğŸ’¡ EJEMPLO 1: â¬…ï¸ Extraemos primera letra en mayÃºscula \n",
    "df_penguins = df_penguins.with_columns(\n",
    "    pl.col(\"species\").str.extract(r'([A-Z])').alias(\"PrimeraLetraEnMayÃºscula\")\n",
    ")\n",
    "# df_penguins.head()\n",
    "\n",
    "##ğŸ’¡ EJEMPLO 2: â¬…ï¸ Extraemos primera letra en minÃºscula \n",
    "df_penguins = df_penguins.with_columns(\n",
    "    pl.col(\"species\").str.extract(r'([a-z])').alias(\"PrimeraLetraEnMinÃºscula\")\n",
    ")\n",
    "# df_penguins.head()\n",
    "\n",
    "##ğŸ’¡ EJEMPLO 3: â¬…ï¸ Retornamos todo despuÃ©s de una letra en mayÃºscula\n",
    "df_penguins = df_penguins.with_columns(\n",
    "    pl.col(\"species\").str.extract(r'[A-Z]+(.*)').alias(\"TodoDespuesDeUnaMayÃºscula\")\n",
    ")\n",
    "# df_penguins.head()\n",
    "\n",
    "##ğŸ’¡ EJEMPLO 4: â¬…ï¸ Retornamos todo despuÃ©s de una letra en minÃºscula\n",
    "df_penguins = df_penguins.with_columns(\n",
    "    pl.col(\"species\").str.extract(r'[a-z]+(.*)').alias(\"TodoDespuesDeUnaMinÃºscula\")\n",
    ")\n",
    "# df_penguins.head()\n",
    "\n",
    "##ğŸ’¡ EJEMPLO 5: â¬…ï¸ Retornamos todo despuÃ©s de un nÃºmero\n",
    "df_penguins = df_penguins.with_columns(\n",
    "    pl.col(\"species\").str.extract(r'[0-9]+(.*)').alias(\"TodoDespuesDeUnNÃºmero\")\n",
    ")\n",
    "df_penguins.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a487d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>nombre</th><th>categoria_producto</th><th>codigo</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot; JUAN pÃ©rez &quot;</td><td>&quot;ELECTRÃ“NICA 1&quot;</td><td>&quot;0001&quot;</td></tr><tr><td>&quot;MARÃA LÃ“PEZ&quot;</td><td>&quot;ropa Mujer&quot;</td><td>&quot;0023&quot;</td></tr><tr><td>&quot;Ana MartÃ­nez&quot;</td><td>&quot;hogar y DECORACIÃ“N&quot;</td><td>&quot;1234&quot;</td></tr><tr><td>&quot;carlos rodrÃ­guez &quot;</td><td>&quot;LIBROS &quot;</td><td>&quot;123&quot;</td></tr><tr><td>&quot;SofÃ­a GarcÃ­a&quot;</td><td>&quot;Juguetes niÃ±os&quot;</td><td>&quot;9999&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ nombre            â”† categoria_producto â”† codigo â”‚\n",
       "â”‚ ---               â”† ---                â”† ---    â”‚\n",
       "â”‚ str               â”† str                â”† str    â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡\n",
       "â”‚  JUAN pÃ©rez       â”† ELECTRÃ“NICA 1      â”† 0001   â”‚\n",
       "â”‚ MARÃA LÃ“PEZ       â”† ropa Mujer         â”† 0023   â”‚\n",
       "â”‚ Ana MartÃ­nez      â”† hogar y DECORACIÃ“N â”† 1234   â”‚\n",
       "â”‚ carlos rodrÃ­guez  â”† LIBROS             â”† 123    â”‚\n",
       "â”‚ SofÃ­a GarcÃ­a      â”† Juguetes niÃ±os     â”† 9999   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    E). REEMPLAZAR VALORES DE DATOS CUALITATIVOS MEDIANTE >>EXPRESIONES REGULARES<< EN UN DATASET\n",
    "    \n",
    "    ğŸ“ SINTAXIS:\n",
    "    \n",
    "        dataset_nombre[NombreColumnaCualitativa].str.replace_all(pattern=PatrÃ³nExpresiÃ³nRegular,value=CadenaAReemplazar)\n",
    "    \n",
    "    ### ğŸ§  En este caso, debemos almacenar en una variable los cambios a realizar en el dataframe\n",
    "\"\"\"\n",
    "### DATASET DE PRUEBA PARA ESTE EJEMPLO\n",
    "datos_sucios = {\n",
    "    \"nombre\": [\n",
    "        \"  JUAN  pÃ©rez  \", \n",
    "        \"MARÃA@@LÃ“PEZ\", \n",
    "        \"Ana--MartÃ­nez\", \n",
    "        \"carlos_rodrÃ­guez \", \n",
    "        \"SofÃ­a123 GarcÃ­a\"\n",
    "    ],\n",
    "    \"categoria_producto\": [\n",
    "        \"ELECTRÃ“NICA#1\", \n",
    "        \"ropa--Mujer\", \n",
    "        \"hogar_y_DECORACIÃ“N\", \n",
    "        \"LIBROS@@\", \n",
    "        \"Juguetes  niÃ±os\"\n",
    "    ],\n",
    "    \"codigo\": [\n",
    "        \"ID-0001\", \n",
    "        \"ID-0023\", \n",
    "        \"CL-1234\", \n",
    "        \"ID-abc123\", \n",
    "        \"id-9999\"\n",
    "    ]\n",
    "}\n",
    "## Dataset de prueba (sucio)\n",
    "df_test = pl.DataFrame(datos_sucios)\n",
    "# df_test.head()\n",
    "\n",
    "## Dataset de prueba (limpio)\n",
    "df_test_clean = df_test \n",
    "\n",
    "## ğŸ’¡ EJEMPLO 1: â¬…ï¸ Eliminar caractÃ©res especiales (@@,#,--,_)\n",
    "df_test_clean = df_test_clean.with_columns(\n",
    "    pl.col(\"categoria_producto\").str.replace_all(pattern=r'[^A-Za-z0-9ÃÃ‰ÃÃ“ÃšÃ¡Ã©Ã­Ã³ÃºÃ‘Ã±ÃœÃ¼]',value=\" \").alias(\"categoria_producto\"),\n",
    "    pl.col(\"nombre\").str.replace_all(pattern=r'[^A-Za-z0-9ÃÃ‰ÃÃ“ÃšÃ¡Ã©Ã­Ã³ÃºÃ‘Ã±ÃœÃ¼]',value=\" \").alias(\"nombre\")\n",
    ")\n",
    "# df_test_clean.head()\n",
    "\n",
    "## ğŸ’¡ EJEMPLO 2: â¬…ï¸ Normalizar espacios (Varios espacios en blanco a uno solo)\n",
    "df_test_clean = df_test_clean.with_columns(\n",
    "    pl.col(\"categoria_producto\").str.replace_all(pattern=r'\\s+',value=\" \").alias(\"categoria_producto\"),\n",
    "    pl.col(\"nombre\").str.replace_all(pattern=r'\\s+',value=\" \").alias(\"nombre\")\n",
    ")\n",
    "# df_test_clean.head()\n",
    "\n",
    "## ğŸ’¡ EJEMPLO 3: â¬…ï¸ Reemplazar guiones por espacios en blanco\n",
    "df_test_clean = df_test_clean.with_columns(\n",
    "    pl.col(\"nombre\").str.replace_all(pattern=r'[-_]',value=\" \").alias(\"nombre\")\n",
    ")\n",
    "# df_test_clean.head()\n",
    "\n",
    "## ğŸ’¡ EJEMPLO 4: â¬…ï¸ Eliminar prefijos (ID- || CL- || id- || Letras)\n",
    "df_test_clean = df_test_clean.with_columns(\n",
    "    pl.col(\"codigo\").str.replace_all(pattern=r'^ID-|CL-|id-|[A-Za-z]+',value=\"\").alias(\"codigo\")\n",
    ")\n",
    "df_test_clean.head()\n",
    "\n",
    "## ğŸ’¡ EJEMPLO 5: â¬…ï¸ Eliminar nÃºmeros dentro de cadenas\n",
    "df_test_clean = df_test_clean.with_columns(\n",
    "    pl.col(\"nombre\").str.replace_all(pattern=r'([0-9])',value=\"\").alias(\"nombre\")\n",
    ")\n",
    "df_test_clean.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422b82cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    F). ELIMINAR VALORES DUPLICADOS EN DATOS CUALITATIVOS DE UN DATASET\n",
    "    \n",
    "    ğŸ“ SINTAXIS:\n",
    "    \n",
    "        dataset_nombre.unique(subset=[NombreColumna1,NombreColumnaN],keep=\"first\" | \"last\" | \"any\" | None)\n",
    "        \n",
    "        keep: Es el parÃ¡metro que establece el valor que va a quedar de todos los duplicados \n",
    "              (Primer valor=first - Ãšltimo valor=last - No mantenga filas duplicadas = any)\n",
    "              [En caso de no llamar al parÃ¡metro keep, se establece \"first\".]\n",
    "        \n",
    "    ### ğŸ§  En este caso, debemos trabajar sobre el mismo dataset/dataframe para eliminar los duplicados.\n",
    "\"\"\"\n",
    "### âœ…ğŸ—ƒï¸ Dataset a utilizar: Diamonds\n",
    "import polars as pl\n",
    "df_diamonds = pl.read_csv(\"../datasets/diamonds.csv\",separator=\",\")\n",
    "# df_diamonds.head()\n",
    "# df_diamonds.shape[0] ## â¬…ï¸ Cantidad de datos inicial: 53940\n",
    "\n",
    "## ğŸ’¡ EJEMPLO 1: ELIMINAR VALORES DUPLICADOS DE TODO EL DATASET (keep=\"first\" por defecto)\n",
    "# df_diamonds = df_diamonds.unique()\n",
    "# df_diamonds.shape[0] ## â¬…ï¸ Cantidad de datos restantes: 53794\n",
    "\n",
    "## ğŸ’¡ EJEMPLO 2: ELIMINAR VALORES DUPLICADOS DE TODO EL DATASET (keep=\"last\")\n",
    "# df_diamonds = df_diamonds.unique(keep=\"last\") \n",
    "# df_diamonds.shape[0] ## â¬…ï¸ Cantidad de datos restantes: 53794\n",
    "\n",
    "##ğŸ’¡ EJEMPLO 3: ELIMINAR VALORES DUPLICADOS DE UNA COLUMNA ESPECÃFICA (keep=\"first\" por defecto)\n",
    "# df_diamonds[\"carat\"].shape[0] ## â¬…ï¸ Cantidad inicial de datos: 53940\n",
    "# df_diamonds = df_diamonds.unique(subset=[\"carat\"],keep=\"first\") \n",
    "# df_diamonds[\"carat\"].shape[0] ## â¬…ï¸ Cantidad de datos restantes: 273   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3599e18b",
   "metadata": {},
   "source": [
    "##### 3.2 Datos Cuantitativos ğŸ”¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb46f68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>species</th><th>island</th><th>bill_length_mm</th><th>bill_depth_mm</th><th>flipper_length_mm</th><th>body_mass_g</th><th>sex</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>39.1</td><td>18.7</td><td>181.0</td><td>3750.0</td><td>&quot;Male&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>39.5</td><td>17.4</td><td>186.0</td><td>3800.0</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>40.3</td><td>18.0</td><td>195.0</td><td>3250.0</td><td>&quot;Female&quot;</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>36.7</td><td>19.3</td><td>193.0</td><td>3450.0</td><td>&quot;Female&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ species â”† island    â”† bill_length_mm â”† bill_depth_mm â”† flipper_length_mm â”† body_mass_g â”† sex    â”‚\n",
       "â”‚ ---     â”† ---       â”† ---            â”† ---           â”† ---               â”† ---         â”† ---    â”‚\n",
       "â”‚ str     â”† str       â”† f64            â”† f64           â”† f64               â”† f64         â”† str    â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ Adelie  â”† Torgersen â”† 39.1           â”† 18.7          â”† 181.0             â”† 3750.0      â”† Male   â”‚\n",
       "â”‚ Adelie  â”† Torgersen â”† 39.5           â”† 17.4          â”† 186.0             â”† 3800.0      â”† Female â”‚\n",
       "â”‚ Adelie  â”† Torgersen â”† 40.3           â”† 18.0          â”† 195.0             â”† 3250.0      â”† Female â”‚\n",
       "â”‚ Adelie  â”† Torgersen â”† null           â”† null          â”† null              â”† null        â”† null   â”‚\n",
       "â”‚ Adelie  â”† Torgersen â”† 36.7           â”† 19.3          â”† 193.0             â”† 3450.0      â”† Female â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_penguins = pl.read_csv(\"../datasets/penguins.csv\",separator=\",\") ## â¬…ï¸ Para este ejemplo utilizaremos el dataset de \"\"\"penguins\"\"\"\n",
    "df_penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376c4372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "643131.077326748"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    A). EXPLORACIÃ“N BÃSICA Y RESUMEN ESTADÃSTICO\n",
    "        \n",
    "        ğŸ“ Para los datos cuantitativos podemos obtener su estadÃ­stica bÃ¡sica\n",
    "            mediante .decribe() el cuÃ¡l retornarÃ¡ el valor de las columnas float o int.\n",
    "            En los campos cualitativos se visualizarÃ¡ informaciÃ³n no creÃ­ble.\n",
    "\"\"\"\n",
    "df_penguins.describe()                ## â¬…ï¸ EstadÃ­stica simple - Todas las columnas\n",
    "df_penguins[\"body_mass_g\"].describe() ## â¬…ï¸ EstadÃ­stica simple - Columna body_mass_g\n",
    "df_penguins[\"body_mass_g\"].mean()     ## â¬…ï¸ Media estadÃ­stica - Columna body_mass_g\n",
    "df_penguins[\"body_mass_g\"].median()   ## â¬…ï¸ Mediana estadÃ­stica - Columna body_mass_g\n",
    "df_penguins[\"body_mass_g\"].min()      ## â¬…ï¸ Valor mÃ­nimo - Columna body_mass_g\n",
    "df_penguins[\"body_mass_g\"].max()      ## â¬…ï¸ Valor mÃ¡ximo (IMC Gramos)\n",
    "df_penguins[\"body_mass_g\"].sum()      ## â¬…ï¸ Suma total - Columna body_mass_g\n",
    "df_penguins[\"body_mass_g\"].std()      ## â¬…ï¸ DesviaciÃ³n estÃ¡ndar - Columna body_mass_g\n",
    "df_penguins[\"body_mass_g\"].var()      ## â¬…ï¸ Varianza - Columna body_mass_g\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12d55811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>body_mass_g</th></tr><tr><td>u32</td></tr></thead><tbody><tr><td>2</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 1)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ body_mass_g â”‚\n",
       "â”‚ ---         â”‚\n",
       "â”‚ u32         â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 2           â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    B). VERIFICAR VALORES NULOS EN LA(S) COLUMNA(AS) DEL DATASET\n",
    "        \n",
    "        ğŸ—’ï¸SINTAXIS:\n",
    "    \n",
    "        dataset_nombre.isnull().sum() â¬…ï¸ Para todo el dataset.\n",
    "        dataset_nombre[NombreColumna].isnull().sum() â¬…ï¸ A nivel de columna\n",
    "\"\"\"\n",
    "\n",
    "## ğŸ’¡ EJEMPLO 1: VERIFICAR CANTIDAD DE VALORES NULOS EN TODAS LAS COLUMNAS DEL DATASET\n",
    "df_penguins.null_count() ## â¬…ï¸ Retorna la cantidad de datos nulos por columna.\n",
    "\n",
    "## ğŸ’¡ EJEMPLO 2: VERIFICAR CANTIDAD DE VALORES NULOS EN UNA COLUMNA ESPECÃFICA DEL DATASET\n",
    "df_penguins[[\"body_mass_g\"]].null_count() ##â¬…ï¸ Retorna la cantidad de datos nulos de una columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91e67615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    C). FILTRANDO VALORES EN COLUMNAS CUANTITATIVAS\n",
    "\"\"\"\n",
    "\n",
    "df_penguins.shape[0] ## â¬…ï¸ Cantidad de datos del dataset : 344\n",
    "\n",
    "## ğŸ’¡ EJEMPLO 1: FILTRAR VALORES DE COLUMNA \"body_mass_g\" MAYOR A 3000\n",
    "df_penguins_bmg_mayor_3000 = df_penguins.filter(\n",
    "    pl.col(\"body_mass_g\")>3000\n",
    ")\n",
    "# df_penguins_bmg_mayor_3000.head()\n",
    "df_penguins_bmg_mayor_3000.shape[0] ## â¬…ï¸ Cantidad de datos resultantes : 331\n",
    "\n",
    "## ğŸ’¡ EJEMPLO 2: FILTRAR VALORES DE COLUMNA \"body_mass_g\" ENTRE 1000 y 3000\n",
    "df_penguins_bmg_entre_1000_3000 = df_penguins.filter(\n",
    "    pl.col(\"body_mass_g\").is_between(1000,3000)\n",
    ")\n",
    "# df_penguins_bmg_entre_1000_3000.head()\n",
    "df_penguins_bmg_entre_1000_3000.shape[0] ## â¬…ï¸ Cantidad de datos resultantes : 11\n",
    "\n",
    "## ğŸ’¡ EJEMPLO 3: FILTRAR VALORES NULOS EN COLUMNA \"body_mass_g\"\n",
    "df_penguins_nulos_body_mass_g = df_penguins.filter(\n",
    "    pl.col(\"body_mass_g\").is_null()\n",
    ")\n",
    "# df_penguins_nulos_body_mass_g.head()\n",
    "df_penguins_nulos_body_mass_g.shape[0] ## â¬…ï¸ Cantidad de datos resultantes : 2\n",
    "\n",
    "## ğŸ’¡ EJEMPLO 4: FILTRAR VALORES NO NULOS EN COLUMNA \"body_mass_g\"\n",
    "df_penguins_no_nulos_body_mass_g = df_penguins.filter(\n",
    "    pl.col(\"body_mass_g\").is_not_null()\n",
    ")\n",
    "# df_penguins_no_nulos_body_mass_g.head()\n",
    "df_penguins_no_nulos_body_mass_g.shape[0] ## â¬…ï¸ Cantidad de datos resultantes : 342\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaafe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    D). RELLENANDO DATOS Null Y NaN DE LAS COLUMNAS DE UN DATASET\n",
    "    \n",
    "        ### ğŸ§ EXISTE UNA DIFERENCIA ENTRE DATOS NaN Y Null Y CONOCERLA TE EVITA\n",
    "              ERRORES SILENCIOSOS QUE PUEDEN DESTRUIR UN ANÃLISIS NUMÃ‰RICO SIN NOTARLO.\n",
    "\"\"\"\n",
    "\"\"\"======================================================================================\n",
    "    ğŸ“ RELLENANDO DATOS Null (Ausencia de valor en un registro)\n",
    "\n",
    "        ğŸ—’ï¸SINTAXIS:\n",
    "        \n",
    "            dataset_nombre.fill_null(value=ValorARellenarNulos,strategy=EstrategiaDeRelleno)\n",
    "            \n",
    "            ğŸ’¡ Importante: El parÃ¡metro strategy admite (\"forward\" | \"backward\" | \"min\" | \"max\" | \"mean\" | \"zero\" | \"one\").\n",
    "            \n",
    "                ğŸ’¡forward:  â¬…ï¸ rellenarÃ¡ la columna del dataset con su valor posterior a un null.\n",
    "                ğŸ’¡backward: â¬…ï¸ rellenarÃ¡ la columna del dataset con su valor anterior a un null.\n",
    "                ğŸ’¡min:      â¬…ï¸ rellenarÃ¡ la columna del dataset con su valor mÃ­nimo de la columna.\n",
    "                ğŸ’¡max:      â¬…ï¸ rellenarÃ¡ la columna del dataset con su valor mÃ¡ximo de la columna.\n",
    "                ğŸ’¡mean:     â¬…ï¸ rellenarÃ¡ la columna del dataset con la mediana de la columna.\n",
    "                ğŸ’¡zero:     â¬…ï¸ rellenarÃ¡ la columna del dataset con ceros.\n",
    "                ğŸ’¡one:      â¬…ï¸ rellenarÃ¡ la columna del dataset con unos.\n",
    "\n",
    "            ### ğŸ§  Tengamos en cuenta que debemos almacenar estos cambios en una nueva variable.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5276ee12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>species</th><th>island</th><th>bill_length_mm</th><th>bill_depth_mm</th><th>flipper_length_mm</th><th>body_mass_g</th><th>sex</th></tr><tr><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 7)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”\n",
       "â”‚ species â”† island â”† bill_length_mm â”† bill_depth_mm â”† flipper_length_mm â”† body_mass_g â”† sex â”‚\n",
       "â”‚ ---     â”† ---    â”† ---            â”† ---           â”† ---               â”† ---         â”† --- â”‚\n",
       "â”‚ u32     â”† u32    â”† u32            â”† u32           â”† u32               â”† u32         â”† u32 â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•¡\n",
       "â”‚ 0       â”† 0      â”† 0              â”† 0             â”† 0                 â”† 0           â”† 0   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"âœ… FunciÃ³n .fill_null() \"\"\"\n",
    "\n",
    "#==== â¡ï¸ Rellenando con el parÃ¡metro strategy\n",
    "\n",
    "## ğŸ’¡ EJEMPLO 1: â¬…ï¸ Rellenamos nulos de todas las columnas del dataset.\n",
    "df_penguins = df_penguins.fill_null(strategy=\"forward\") \n",
    "# df_penguins.head()\n",
    "# df_penguins.null_count() ##âœ… No existen datos nulos\n",
    "\n",
    "## ğŸ’¡ EJEMPLO 2: â¬…ï¸ Rellenamos nulos de todas las columnas del dataset.\n",
    "df_penguins = df_penguins.with_columns(\n",
    "    pl.col(\"body_mass_g\").fill_null(strategy=\"forward\")\n",
    ")\n",
    "# df_penguins.head()\n",
    "\n",
    "#==== â¡ï¸ Rellenando con el parÃ¡metro value\n",
    "\n",
    "## ğŸ’¡ EJEMPLO 3: â¬…ï¸ Rellenamos nulos de todas las columnas del dataset.\n",
    "df_penguins = df_penguins.fill_null(value=0) ##â¬…ï¸ Rellenamos nulos de todas las columnas del dataset, con el valor cero.\n",
    "\n",
    "## ğŸ’¡ EJEMPLO 4: â¬…ï¸ Rellenamos nulos de todas las columnas del dataset.\n",
    "df_penguins = df_penguins.with_columns(\n",
    "    pl.col(\"body_mass_g\").fill_null(value=0)       ##â¬…ï¸ Rellenamos una columna especÃ­fica del dataset, con el valor cero.\n",
    ")\n",
    "df_penguins.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafa313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"======================================================================================\n",
    "    ğŸ“ RELLENANDO DATOS NaN (Resultados indefinidos en un registro)\n",
    "\n",
    "        ğŸ—’ï¸SINTAXIS:\n",
    "        \n",
    "            dataset_nombre.fill_nan(value=ValorARellenar)\n",
    "            \n",
    "            ğŸ’¡ Importante: El parÃ¡metro value admite cualquier valor a rellenar, e incluso una medida estadÃ­stica\n",
    "                            de una columna especÃ­fica en el dataset: (\"min\" | \"max\" | \"mean\" | \"median\")\n",
    " \n",
    "            ### ğŸ§  Tengamos en cuenta que debemos almacenar estos cambios en una nueva variable.\n",
    "\"\"\"\n",
    "\"\"\"âœ… FunciÃ³n .fill_nan() \"\"\"\n",
    "import numpy as np\n",
    "### ğŸ“ Utilizaremos de ejemplo este dataframe con datos NaN (Numpu)\n",
    "df_example = pl.DataFrame(data=[[1.0,np.nan,3.0,4.0,np.nan],[np.nan,5.0,np.nan,10.0,21.0]],schema=[\"Edad\",\"Puntos\"])\n",
    "df_example.head()\n",
    "\n",
    "#==== â¡ï¸ Rellenando con un valor aleatorio: 1\n",
    "\n",
    "## ğŸ’¡ EJEMPLO 1: â¬…ï¸ Rellenamos NaN de todas las columnas del dataset.\n",
    "df_penguins = df_example.fill_nan(value=1)  \n",
    "\n",
    "## ğŸ’¡ EJEMPLO 2: â¬…ï¸ Rellenamos NaN de una columna especÃ­fica del dataset.\n",
    "df_example = df_example.with_columns(\n",
    "    pl.col(\"Edad\").fill_nan(value=1)                 \n",
    ")\n",
    "\n",
    "#==== â¡ï¸ Rellenando con una medida esadÃ­stica de una columna: Edad â¡ï¸ media\n",
    "\n",
    "## ğŸ’¡ EJEMPLO 3: â¬…ï¸ Rellenamos NaN de todas las columnas del dataset.\n",
    "df_example = df_example.fill_nan(value=pl.col(\"Edad\").drop_nans().mean()) \n",
    "\n",
    "## ğŸ’¡ EJEMPLO 4: â¬…ï¸ Rellenamos NaN de una columna especÃ­fica del dataset.\n",
    "df_example = df_example.with_columns(\n",
    "    pl.col(\"Puntos\").fill_nan(value=pl.col(\"Puntos\").drop_nans().mean())      \n",
    ")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a14df30",
   "metadata": {},
   "source": [
    "#### Fase 4. Agrupamiento de Datos â™¾ï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38f6449",
   "metadata": {},
   "source": [
    "\"\"\"El agrupamiento de la informaciÃ³n nos brinda el resumen de la informaciÃ³n proveniente \n",
    "de un dataset, logrando econtrar ciertos patrones en cada grupo de informaciÃ³n.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6fffe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    ğŸ“ SINTAXIS:\n",
    "\n",
    "        dataset_nuevo_agrupamiento= dataset_nombre.group_by([NombreColumna1,NombreColumnaN]).agg(\n",
    "            pl.col(ColumnaAgregacion).funcionAgregacion().alias(NombreNuevoDeColumna)\n",
    "        )\n",
    "        \n",
    "        ### ğŸ§  En este caso, debemos almacenar en una variable los cambios a realizar en el dataframe.\n",
    "\n",
    "â En el agrupamiento de informaciÃ³n, podemos utilizar diversas funciones de agregaciÃ³n, tales como:\n",
    "\n",
    "ğŸ’¡.min():    â¬…ï¸ Permite obtener el mÃ­nimo valor de la informaciÃ³n agrupada.\n",
    "ğŸ’¡.max():    â¬…ï¸ Permite obtener el mÃ¡ximo valor de la informaciÃ³n agrupada.\n",
    "ğŸ’¡.sum():    â¬…ï¸ Permite sumar la informaciÃ³n de una columna cuantitativa por la informaciÃ³n agrupada.\n",
    "ğŸ’¡.count():  â¬…ï¸ Permite contar la cantidad de informaciÃ³n de una columna por la informaciÃ³n agrupada.\n",
    "ğŸ’¡.mean():   â¬…ï¸ Permite obtener la media de una columna cuantitativa por la informaciÃ³n agrupada.\n",
    "ğŸ’¡.median(): â¬…ï¸ Permite obtener la mediana de una columna cuantitativa por la informaciÃ³n agrupada.\n",
    "\"\"\"\n",
    "###âœ”ï¸ Usaremos el dataset de \"penguins\"\n",
    "df_penguins = pl.read_csv(\"../datasets/penguins.csv\",separator=\",\")\n",
    "# df_penguins.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ad93703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>species</th><th>Cantidad</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;Adelie&quot;</td><td>152</td></tr><tr><td>&quot;Chinstrap&quot;</td><td>68</td></tr><tr><td>&quot;Gentoo&quot;</td><td>124</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 2)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ species   â”† Cantidad â”‚\n",
       "â”‚ ---       â”† ---      â”‚\n",
       "â”‚ str       â”† u32      â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ Adelie    â”† 152      â”‚\n",
       "â”‚ Chinstrap â”† 68       â”‚\n",
       "â”‚ Gentoo    â”† 124      â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ğŸ’¡ EJEMPLO 1: (AGRUPANDO POR UNA COLUMNA) \n",
    "df_agrupado_uno = df_penguins.group_by([\"species\"]).agg(\n",
    "    pl.col(\"body_mass_g\").mean().alias(\"PromedioBMG\") ## â¬…ï¸ Hallamos la media de la columna \"body_mass_g\"\n",
    ")\n",
    "# df_agrupado_uno.head()\n",
    "\n",
    "## ğŸ’¡ EJEMPLO 2: (AGRUPAR POR DOS COLUMNAS)\n",
    "df_agrupado_dos = df_penguins.group_by([\"species\",\"sex\"]).agg(\n",
    "    pl.col(\"body_mass_g\").mean().alias(\"Species_Sex_PromedioBMG\")\n",
    ")\n",
    "# df_agrupado_dos.head()\n",
    "\n",
    "## ğŸ’¡ EJEMPLO 3: (AGRUPAR LA INFORMACIÃ“N POR LA CANTIDAD DE LA MISMA COLUMNA)\n",
    "\n",
    "df_agrupado_tres = df_penguins.group_by([\"species\"]).agg(\n",
    "    pl.col(\"species\").len().alias(\"Cantidad\") ## â¬…ï¸ .len() : funciÃ³n clave para traer la cantidad de datos de la columna.\n",
    ")\n",
    "df_agrupado_tres.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf4b561",
   "metadata": {},
   "source": [
    "#### FASE 4.1 CÃLCULOS MÃ“VILES EN POLARS ğŸ»â€â„ï¸ğŸ’¹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74583649",
   "metadata": {},
   "source": [
    "AsÃ­ como SQL SERVER y Pandas permite realizar cÃ¡lculos mÃ³viles basados en funciones de agregaciÃ³n\n",
    "(min,max,mean,entre otros), Polars lo realiza mediante la funciÃ³n con prefijo \".rolling_\" entre \n",
    "una N cantidad de filas hacia atrÃ¡s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911f3aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    ğŸ“ SINTAXIS: \n",
    "        \n",
    "        1ï¸âƒ£ CÃ¡lculo MÃ³vil sin Particionamiento: Permite el cÃ¡lculo mÃ³vil de una columna que no es afectada por otra(s).\n",
    "        \n",
    "        dataset_nombre = dataset_nombre.with_columns(\n",
    "            pl.col(NombreColumnaCalcular).funcionAgregacionAcumulativa().alias(NuevaColumnaMovil)\n",
    "        ) \n",
    "                                             \n",
    "        2ï¸âƒ£ CÃ¡lculo MÃ³vil con Particionamiento: Permite el cÃ¡lculo mÃ³vil por columnas en especÃ­fico.\n",
    "        \n",
    "        dataset_nombre = dataset_nombre.with_columns(\n",
    "            pl.col(NombreColumnaCalcular).funcionAgregacion().over(partition_by=ColumnaParticionar).alias(NombreColumnaMovil)\n",
    "        )\n",
    "        \n",
    "        ### .over(): Permite el particionamiento por cierta(s) columna(s).\n",
    "\n",
    "        ğŸ’¡ Importante: Existen ciertas funciones de agregaciÃ³n que contienen dentro de sus parÃ¡metros\n",
    "                       [window_size: el cuÃ¡l permite seleccionar una cierta cantidad de filas para el\n",
    "                       cÃ¡lculo mÃ³vil y min_samples que permite establecer una mÃ­nima cantidad de \n",
    "                       periodos para evitar valores NaN, estas funciones tienen de prefijo \".rolling_\")                                            \n",
    "\n",
    "        ### ğŸ§  Cuando realizamos el cÃ¡lculo mÃ³vil a una columna, Pandas siempre incluirÃ¡ la fila actual.\n",
    "\"\"\"\n",
    "### ğŸ’¹ USAREMOS EL SIGUIENTE DATASET DE EJEMPLO (FORMATO .json):\n",
    "import json\n",
    "with open(\"../datasets/ventas.json\",\"r\") as file:\n",
    "    data_json = json.load(file)\n",
    "df_ventas = pl.DataFrame(data=data_json[\"ventas\"])\n",
    "# df_ventas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f716bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>nro_venta</th><th>fecha</th><th>cliente</th><th>total</th><th>valor_minimo_3_dias</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1001</td><td>&quot;2024-01-22&quot;</td><td>&quot;Cliente_10&quot;</td><td>350.25</td><td>null</td></tr><tr><td>1002</td><td>&quot;2024-02-15&quot;</td><td>&quot;Cliente_3&quot;</td><td>410.5</td><td>null</td></tr><tr><td>1003</td><td>&quot;2024-03-08&quot;</td><td>&quot;Cliente_7&quot;</td><td>120.75</td><td>null</td></tr><tr><td>1004</td><td>&quot;2024-04-20&quot;</td><td>&quot;Cliente_1&quot;</td><td>250.0</td><td>120.75</td></tr><tr><td>1005</td><td>&quot;2024-05-11&quot;</td><td>&quot;Cliente_10&quot;</td><td>300.9</td><td>120.75</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ nro_venta â”† fecha      â”† cliente    â”† total  â”† valor_minimo_3_dias â”‚\n",
       "â”‚ ---       â”† ---        â”† ---        â”† ---    â”† ---                 â”‚\n",
       "â”‚ i64       â”† str        â”† str        â”† f64    â”† f64                 â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 1001      â”† 2024-01-22 â”† Cliente_10 â”† 350.25 â”† null                â”‚\n",
       "â”‚ 1002      â”† 2024-02-15 â”† Cliente_3  â”† 410.5  â”† null                â”‚\n",
       "â”‚ 1003      â”† 2024-03-08 â”† Cliente_7  â”† 120.75 â”† null                â”‚\n",
       "â”‚ 1004      â”† 2024-04-20 â”† Cliente_1  â”† 250.0  â”† 120.75              â”‚\n",
       "â”‚ 1005      â”† 2024-05-11 â”† Cliente_10 â”† 300.9  â”† 120.75              â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### ğŸ’¡ EJEMPLO 1: CÃLCULO MÃ“VIL â¡ï¸ VENTAS ACUMULATIVAS (SUMA ACUMULADA SIN PARTICIONES)\n",
    "df_ventas_acumuladas = df_ventas\n",
    "df_ventas_acumuladas = df_ventas_acumuladas.with_columns(\n",
    "    pl.col(\"total\").cum_sum().alias(\"ventas_acumuladas\")  ##â¬…ï¸ Usamos .cum_sum()\n",
    ") \n",
    "# df_ventas_acumuladas.tail()\n",
    "\n",
    "### ğŸ’¡ EJEMPLO 2: CÃLCULO MÃ“VIL â¡ï¸ VENTAS ACUMULATIVAS (SUMA ACUMULADA CADA 3 DIAS) (âœ… INCLUYE FILA ACTUAL)\n",
    "df_ventas_acumuladas_3_dias = df_ventas\n",
    "df_ventas_acumuladas_3_dias = df_ventas_acumuladas_3_dias.with_columns(\n",
    "    pl.col(\"total\").rolling_sum(window_size=3).alias(\"ventas_acumuladas\") ## â¬…ï¸.rolling_sum()\n",
    ") \n",
    "####ğŸ’¡ Los Valores NaN no permiten realizar sumatorias por 1 o 2 valores, deben ser 3 (âœ… Incluye la fiLa actual - âŒNo particionamos).\n",
    "# df_ventas_acumuladas_3_dias.head(6)\n",
    "\n",
    "### ğŸ’¡ EJEMPLO 3: CÃLCULO MÃ“VIL â¡ï¸ VENTAS ACUMULATIVAS (SUMA ACUMULADA CADA 3 DIAS) âœ… (âŒ NO INCLUYE FILA ACTUAL)\n",
    "df_ventas_acumuladas_3_dias_sin_fila_actual = df_ventas\n",
    "df_ventas_acumuladas_3_dias_sin_fila_actual = df_ventas_acumuladas_3_dias_sin_fila_actual.with_columns(\n",
    "    pl.col(\"total\").shift(1).rolling_sum(window_size=3).alias(\"ventas_acumuladas\") ## â¬…ï¸.rolling_sum()\n",
    ")\n",
    "####ğŸ’¡ Los Valores NaN no permiten realizar sumatorias por 1 o 2 valores, deben ser 3 (âŒ No incluye la fiLa actual - âŒNo particionamos).\n",
    "# df_ventas_acumuladas_3_dias_sin_fila_actual.head(7) \n",
    "\n",
    "### ğŸ’¡ EJEMPLO 4: CÃLCULO MÃ“VIL â¡ï¸ VENTAS ACUMULATIVAS (SUMA ACUMULADA CON PARTICIONES)\n",
    "df_ventas_acumuladas_particiones = df_ventas.sort(by=\"cliente\") #.sort(by=\"cliente\") ## â¬…ï¸ Ordenamos antes de particionar\n",
    "# df_ventas_acumuladas_particiones.head()\n",
    "df_ventas_acumuladas_particiones = df_ventas_acumuladas_particiones.with_columns(\n",
    "    pl.col(\"total\").cum_sum().over(partition_by=\"cliente\").alias(\"ventas_acumuladas\")\n",
    ") \n",
    "# df_ventas_acumuladas_particiones.head() ## âœ… .over() permite el particionamiento y reinicia el acumulado por cada cliente.\n",
    "\n",
    "#=======================================================================================================================================\n",
    "\n",
    "### ğŸ’¡ EJEMPLO 5: CÃLCULO MÃ“VIL â¡ï¸ PROMEDIO MÃ“VIL (PROMEDIO CADA 3 DÃAS) (âœ… INCLUYE FILA ACTUAL)\n",
    "df_ventas_promedio_3_dias = df_ventas \n",
    "# df_ventas_promedio_3_dias.head()\n",
    "df_ventas_promedio_3_dias = df_ventas_promedio_3_dias.with_columns(\n",
    "    pl.col(\"total\").rolling_mean(window_size=3).alias(\"promedio_ventas_3_dias\") ## â¬…ï¸ Utilizamos .rolling_mean()\n",
    ")\n",
    "####ğŸ’¡ Los Valores NaN no permiten calcular el promedio por 1 o 2 valores, deben ser 3 (âœ… Incluye la fiLa actual - âŒNo particionamos).\n",
    "# df_ventas_promedio_3_dias.head()\n",
    "\n",
    "\n",
    "### ğŸ’¡ EJEMPLO 6: CÃLCULO MÃ“VIL â¡ï¸ PROMEDIO MÃ“VIL (PROMEDIO CADA 3 DÃAS) (âŒ NO INCLUYE FILA ACTUAL)\n",
    "df_ventas_promedio_3_dias_sin_fila_actual = df_ventas\n",
    "# df_ventas_promedio_3_dias_sin_fila_actual.head()\n",
    "\n",
    "df_ventas_promedio_3_dias_sin_fila_actual = df_ventas_promedio_3_dias_sin_fila_actual.with_columns(\n",
    "    pl.col(\"total\").shift(1).rolling_mean(window_size=3).alias(\"promedio_ventas_3_dias\") ## â¬…ï¸ Utilizamos .rolling_mean()\n",
    ")\n",
    "####ğŸ’¡ Los Valores NaN no permiten calcular el promedio por 1 o 2 valores, deben ser 3 (âŒ No incluye la fiLa actual - âŒNo particionamos).\n",
    "df_ventas_promedio_3_dias_sin_fila_actual.head()\n",
    "\n",
    "\n",
    "#=======================================================================================================================================\n",
    "\n",
    "### ğŸ’¡ EJEMPLO 7: CÃLCULO MÃ“VIL â¡ï¸ MÃXIMO MÃ“VIL (VALOR MÃXIMO CADA 3 DÃAS) (âœ… INCLUYE FILA ACTUAL)\n",
    "df_ventas_maximo_3_dias = df_ventas\n",
    "# df_ventas_maximo_3_dias.head()\n",
    "df_ventas_maximo_3_dias = df_ventas_maximo_3_dias.with_columns(\n",
    "    pl.col(\"total\").rolling_max(window_size=3).alias(\"valor_maximo_3_dias\") ## â¬…ï¸ Utilizamos .rolling_max()\n",
    ")\n",
    "####ğŸ’¡ Los Valores NaN no permiten calcular el promedio por 1 o 2 valores, deben ser 3 (âœ… Incluye la fiLa actual - âŒNo particionamos).\n",
    "df_ventas_maximo_3_dias.head()\n",
    "\n",
    "\n",
    "### ğŸ’¡ EJEMPLO 8: CÃLCULO MÃ“VIL â¡ï¸ MÃXIMO MÃ“VIL (VALOR MÃXIMO CADA 3 DÃAS) (âŒ NO INCLUYE FILA ACTUAL)\n",
    "df_ventas_maximo_3_dias_sin_fila_actual = df_ventas\n",
    "# df_ventas_maximo_3_dias_sin_fila_actual.head()\n",
    "df_ventas_maximo_3_dias_sin_fila_actual = df_ventas_maximo_3_dias_sin_fila_actual.with_columns(\n",
    "    pl.col(\"total\").shift(1).rolling_max(window_size=3).alias(\"valor_maximo_3_dias\")\n",
    ")\n",
    "####ğŸ’¡ Los Valores NaN no permiten calcular el promedio por 1 o 2 valores, deben ser 3 (âŒ No incluye la fiLa actual - âŒNo particionamos).\n",
    "# df_ventas_maximo_3_dias_sin_fila_actual.head()\n",
    "\n",
    "\n",
    "#=======================================================================================================================================\n",
    "\n",
    "### ğŸ’¡ EJEMPLO 9: CÃLCULO MÃ“VIL â¡ï¸ MÃNIMO MÃ“VIL (VALOR MÃNIMO CADA 3 DÃAS) (âœ… INCLUYE FILA ACTUAL)\n",
    "df_ventas_minimo_3_dias = df_ventas\n",
    "# df_ventas_minimo_3_dias.head()\n",
    "df_ventas_minimo_3_dias = df_ventas_minimo_3_dias.with_columns(\n",
    "    pl.col(\"total\").rolling_min(window_size=3).alias(\"valor_minimo_3_dias\")\n",
    ")\n",
    "####ğŸ’¡ Los Valores NaN no permiten calcular el promedio por 1 o 2 valores, deben ser 3 (âœ… Incluye la fiLa actual - âŒNo particionamos).\n",
    "# df_ventas_minimo_3_dias.head()\n",
    "\n",
    "\n",
    "### ğŸ’¡ EJEMPLO 10: CÃLCULO MÃ“VIL â¡ï¸ MÃNIMO MÃ“VIL (VALOR MÃNIMO CADA 3 DÃAS) (âŒ NO INCLUYE FILA ACTUAL)\n",
    "df_ventas_minimo_3_dias_sin_fila_actual = df_ventas\n",
    "# df_ventas_minimo_3_dias_sin_fila_actual.head()\n",
    "df_ventas_minimo_3_dias_sin_fila_actual = df_ventas_minimo_3_dias_sin_fila_actual.with_columns(\n",
    "    pl.col(\"total\").shift(1).rolling_min(window_size=3).alias(\"valor_minimo_3_dias\")\n",
    ")\n",
    "####ğŸ’¡ Los Valores NaN no permiten calcular el promedio por 1 o 2 valores, deben ser 3 (âŒ No incluye la fiLa actual - âŒNo particionamos).\n",
    "df_ventas_minimo_3_dias_sin_fila_actual.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67b6fb4",
   "metadata": {},
   "source": [
    "#### FASE 4.2 PIVOT TABLES EN POLARS ğŸ»â€â„ï¸ğŸ’¹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3e7caa",
   "metadata": {},
   "source": [
    "Las Pivot Table permiten transformar filas de un dataset/dataframe en columnas de un nuevo dataset/dataframe,\n",
    "permitiendo un anÃ¡lisis mÃ¡s detallado sobre un grupo especÃ­fico de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fce1dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sex</th><th>avg</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;female&quot;</td><td>27.915709</td></tr><tr><td>&quot;male&quot;</td><td>30.726645</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ sex    â”† avg       â”‚\n",
       "â”‚ ---    â”† ---       â”‚\n",
       "â”‚ str    â”† f64       â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ female â”† 27.915709 â”‚\n",
       "â”‚ male   â”† 30.726645 â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"     \n",
    "      ğŸ“ SINTAXIS:\n",
    "          dataset_pivoteado_nombre = dataset_original_nombre.pivot(index=NombreColumnaDataframe,on=NombreColumnaDataframe,\n",
    "                                     values=NombreColumnaDataframe,,aggregate_function=NombreFunciÃ³nAgregaciÃ³n) \n",
    "\n",
    "\"\"\"\n",
    "import polars as pl\n",
    "### âœ…ğŸ—ƒï¸ Dataset a utilizar: titanic\n",
    "df_titanic = pl.read_csv(\"../datasets/titanic.csv\",separator=\",\")\n",
    "# df_titanic.head()\n",
    "\n",
    "#### ğŸ’¡ EJEMPLO 1: HALLAR EL PROMEDIO DE EDAD POR CLASE Y GÃ‰NERO\n",
    "df_pivot_uno = df_titanic.pivot(index=\"pclass\",on=\"sex\",values=\"age\",aggregate_function=\"mean\")\n",
    "df_pivot_uno.head() ##  âœ… Resultado exitoso.\n",
    "\n",
    "\n",
    "#### ğŸ’¡ EJEMPLO 2: HALLAR EL PROMEDIO DE FARE POR CLASE Y SEXO, ADEMÃS AGREGAR UN TOTAL A NIVEL DE FILA Y COLUMNA CALCULANDO EL PROMEDIO)\n",
    "df_pivot_dos = df_titanic.pivot(index=\"pclass\",on=\"sex\",values=\"fare\",aggregate_function=\"mean\")\n",
    "df_pivot_dos = df_pivot_dos.with_columns(\n",
    "    pl.mean_horizontal(\"male\",\"female\").round(2).alias(\"total\")\n",
    ")\n",
    "## ğŸ’¡ Cuando usamos pl.mean_horizontal() permite agregar una columna adicional para realizar un cÃ¡lculo a nivel de fila.\n",
    "df_pivot_dos.head()\n",
    "## ğŸ’¡ Calculamos la media de cada columna.\n",
    "total_avg_male, total_avg_female, total_avg = round(df_pivot_dos[\"male\"].mean(),2),round(df_pivot_dos[\"female\"].mean(),2),round(df_pivot_dos[\"total\"].mean(),2)\n",
    "## ğŸ’¡ Asignamos los valores a un nuevo dataframe para poder unirlo al dataframe original\n",
    "df_pivot_total_columna = pl.DataFrame(data=[[\"Total\"],[total_avg_male],[total_avg_female],[total_avg]],schema={\"pclass\":pl.String,\"male\":pl.Float64,\"female\":pl.Float64,\"total\":pl.Float64})\n",
    "# df_pivot_total_columna.head() ## ğŸ’¡ Agregamos un valor \"Total\" a la columna pclass para poder crear la nueva fila en el dataframe original.\n",
    "df_pivot_dos = df_pivot_dos.with_columns(\n",
    "    pl.col(\"pclass\").cast(pl.String).alias(\"pclass\") ## ğŸ’¡ Casteamos la columna pclass a un String para poder concatenarlo con el dato del dataframe de totales.\n",
    ")\n",
    "# df_pivot_dos.head()\n",
    "## ğŸ’¡ Concatenamos correctamente los dataframes con el cÃ¡lculo de su total a nivel de columna.\n",
    "df_pivot_dos_final = pl.concat([df_pivot_dos,df_pivot_total_columna])\n",
    "df_pivot_dos_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713bbff3",
   "metadata": {},
   "source": [
    "#### FASE 4.2 UNPIVOT TABLES EN POLARS ğŸ»â€â„ï¸ğŸ’¹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502ebf13",
   "metadata": {},
   "source": [
    "Los UnPivot Tables permiten transformar columnas de un dataset/dataframe en filas de un nuevo dataset/dataframe,\n",
    "permitiendo reestablecer el estado del dataframe al original, sin embargo:\n",
    "**LA FUNCIÃ“N DE AGREGACIÃ“N UTILIZADA EN PIVOT NO REGRESA A SU FORMA NORMAL LOS DATOS, ES DECIR, SE MANTIENE EL CÃLCULO DE LA FUNCIÃ“N DE AGREGACIÃ“N**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b1b0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 3)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ pclass â”† male      â”† female    â”‚\n",
      "â”‚ ---    â”† ---       â”† ---       â”‚\n",
      "â”‚ i64    â”† f64       â”† f64       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 3      â”† 26.507589 â”† 21.75     â”‚\n",
      "â”‚ 1      â”† 41.281386 â”† 34.611765 â”‚\n",
      "â”‚ 2      â”† 30.740707 â”† 28.722973 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "shape: (6, 3)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ pclass â”† sex    â”† age       â”‚\n",
      "â”‚ ---    â”† ---    â”† ---       â”‚\n",
      "â”‚ i64    â”† str    â”† f64       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 3      â”† male   â”† 26.507589 â”‚\n",
      "â”‚ 1      â”† male   â”† 41.281386 â”‚\n",
      "â”‚ 2      â”† male   â”† 30.740707 â”‚\n",
      "â”‚ 3      â”† female â”† 21.75     â”‚\n",
      "â”‚ 1      â”† female â”† 34.611765 â”‚\n",
      "â”‚ 2      â”† female â”† 28.722973 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "      ğŸ“ SINTAXIS:\n",
    "          dataframe_unpivoteado_nombre = NombreDataframePivoteado.unpivot(index=[NombreColumnaIndice],on=[Valor1Pivoteado,ValorNPivoteado],\n",
    "                                         variable_name=NombreColumnaValoresPivoteados,value_name=NombreColumnaValorFuncionAgregacionPivoteado)\n",
    "          index: Nombre de la columna del dataset/dataframe pivoteado que se estaleciÃ³ como *index*\n",
    "          on: Nombre de cada valor establecido como columna en el dataset/dataframe pivoteado\n",
    "          variable_name: Nombre de la columna que serÃ¡ utilizada como parte de los valores pivoteados.\n",
    "          value_name: Nombre de la columna el dataset/dataframe pivoteado que es utlizada por la funciÃ³n de agregaciÃ³n.       \n",
    "\n",
    "\"\"\"\n",
    "import polars as pl\n",
    "### âœ…ğŸ—ƒï¸ Dataframe pivoteado a utilizar: df_titanic\n",
    "df_titanic = pl.read_csv(\"../datasets/titanic.csv\",separator=\",\")\n",
    "# df_titanic.head()\n",
    "\n",
    "## âœ… DATASET PIVOTEADO\n",
    "df_pivoteado = df_titanic.pivot(index=\"pclass\",on=\"sex\",values=\"age\",aggregate_function=\"mean\")\n",
    "# df_pivoteado.head() \n",
    "\n",
    "#### ğŸ’¡ EJEMPLO 1: DESPIVOTEAR EL DATASET PIVOTEADO\n",
    "df_unpivot_uno = df_pivoteado.unpivot(index=[\"pclass\"],on=[\"male\",\"female\"],variable_name=\"sex\",value_name=\"age\")\n",
    "df_unpivot_uno.head()\n",
    "\n",
    "##---- COMPARACIÃ“N DE PIVOT y UNPIVOT TABLE DEL DATASET/DATAFRAME\n",
    "print(df_pivoteado)\n",
    "print(df_unpivot_uno)\n",
    "## ğŸ’¡ Como se mencionÃ³ anteriormente, el unpivot table no regresa los datos calculados por \n",
    "##    la funciÃ³n de agregaciÃ³n (en este caso \"mean\") a su forma base del dataset/dataframe original (df_titanic).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b9fc54",
   "metadata": {},
   "source": [
    "#### Fase 5. Combinar y Unir Datasets/Dataframes en Polars ğŸ»â€â„ï¸â™¾ï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c8aa16",
   "metadata": {},
   "source": [
    "A diferencia de Pandas, Polars permite la unificaciÃ³n de datasets/dataframes mediante dos formas:\n",
    "    - Utilizando Join\n",
    "    - Utilizando Concat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cb6566",
   "metadata": {},
   "source": [
    "##### Join en Polars ğŸ“ŠğŸ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b121560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    ğŸ“ SINTAXIS: \n",
    "\n",
    "        dataset_unificado_nombre=dataset_nombre_1.join(other=dataset_nombre_2,on='ColumnaEnComun',\n",
    "                                how='left || rigth || inner || full || semi || anti || cross',\n",
    "                                left_on='NombreColumnaEnComÃºn',right_on='NombreColumnaEnComÃºn')                                \n",
    "                                \n",
    "        ==================================================================================================  \n",
    "\n",
    "    ### ğŸ’¡Importante: Join permite unificar los datasets/dataframes a nivel columnar, es decir,\n",
    "                       unifica horizontalmente las columnas de un dataset/dataframe A; con las columnas\n",
    "                       de un dataset/dataframe B; gracias a una columna en comÃºn que tienen ambos \n",
    "                       conjuntos de datos.\n",
    "                       \n",
    "                       left_on â¬…ï¸â¡ï¸ right_on : ParÃ¡metros que permiten unificar dataset/dataframes\n",
    "                                                cuando las columnas en comÃºn tienen diferente nombre.     \n",
    "\"\"\"\n",
    "### âœ… Utilizaremos este dataset de ejemplo:\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "diccionario_uno = {\n",
    "    \"ID_Cliente\":[1,2,3,4,5],\n",
    "    \"Nombre\": [\"Pepito\",\"Juanito\",\"Pedrito\",\"Brayan\",\"Carlos\"],\n",
    "    \"Departamento\":[\"LAS QUINTANAS\",\"EL GOLF\",\"BUENOS AIRES\",\"SAN ANDRÃ‰S\",\"CALIFORNIA\"]\n",
    "}\n",
    "diccionario_dos = {\n",
    "    \"ID_Cliente\":[1,1,2,2,5,4,1,None],\n",
    "    \"Ventas\":np.random.uniform(low=1450.25,high=1980.30,size=8).tolist()\n",
    "}\n",
    "\n",
    "df_uno = pl.DataFrame(diccionario_uno)\n",
    "df_dos = pl.DataFrame(diccionario_dos)\n",
    "\n",
    "diccionario_tres = {\n",
    "    \"Cliente_ID\":[1,1,2,2,5,4,1,None],\n",
    "    \"Ventas\":np.random.uniform(low=1450.25,high=1980.30,size=8).tolist()\n",
    "}\n",
    "df_tres = pl.DataFrame(diccionario_tres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00bc719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ID_Cliente</th><th>Nombre</th><th>Departamento</th></tr><tr><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>&quot;Pepito&quot;</td><td>&quot;LAS QUINTANAS&quot;</td></tr><tr><td>2</td><td>&quot;Juanito&quot;</td><td>&quot;EL GOLF&quot;</td></tr><tr><td>4</td><td>&quot;Brayan&quot;</td><td>&quot;SAN ANDRÃ‰S&quot;</td></tr><tr><td>5</td><td>&quot;Carlos&quot;</td><td>&quot;CALIFORNIA&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 3)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ ID_Cliente â”† Nombre  â”† Departamento  â”‚\n",
       "â”‚ ---        â”† ---     â”† ---           â”‚\n",
       "â”‚ i64        â”† str     â”† str           â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 1          â”† Pepito  â”† LAS QUINTANAS â”‚\n",
       "â”‚ 2          â”† Juanito â”† EL GOLF       â”‚\n",
       "â”‚ 4          â”† Brayan  â”† SAN ANDRÃ‰S    â”‚\n",
       "â”‚ 5          â”† Carlos  â”† CALIFORNIA    â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#### ğŸ’¡ EJEMPLO 1 (UNIFICACIÃ“N DE DATAFRAMES [INNER]) \n",
    "df_ejemplo_1 = df_uno.join(other=df_dos,on=\"ID_Cliente\",how=\"inner\")\n",
    "# df_ejemplo_1.shape[0] ## Cantidad de registros: 7\n",
    "# df_ejemplo_1.head(7)\n",
    "## [NO SE ENCUENTRA EL CLIENTE 3] â¡ï¸ INNER MANTIENE LA INFORMACIÃ“N RELACIONADA Y EXISTENTE ENTRE AMBOS DATASETS\n",
    "\n",
    "#### ğŸ’¡ EJEMPLO 2 (UNIFICACIÃ“N DE DATAFRAMES [LEFT])\n",
    "df_ejemplo_2 = df_uno.join(other=df_dos,on=\"ID_Cliente\",how=\"left\")\n",
    "# df_ejemplo_2.shape[0] ## Cantidad de registros: 8\n",
    "# df_ejemplo_2.head(8)\n",
    "## [SE ENCUENTRA EL CLIENTE 3] â¡ï¸ LEFT MANTIENE LA INFORMACIÃ“N DEL LADO IZQUIERDO (df_uno) \n",
    "## [ASÃ NO EXISTA ALGÃšN REGISTRO EN EL LADO DERECHO (df_dos)]\n",
    "\n",
    "#### ğŸ’¡ EJEMPLO 3 (UNIFICACIÃ“N DE DATAFRAMES [RIGHT])\n",
    "df_ejemplo_3 = df_uno.join(other=df_dos,on=\"ID_Cliente\",how=\"right\")\n",
    "# df_ejemplo_3.shape[0] ## Cantidad de registros: 8\n",
    "# df_ejemplo_3.head(8)\n",
    "## [SE ENCUENTRA EL CLIENTE 3] â¡ï¸ RIGHT MANTIENE LA INFORMACIÃ“N DEL LADO DERECHO (df_dos) \n",
    "## [ASÃ NO EXISTA ALGÃšN REGISTRO EN EL LADO IZQUIERDO (df_uno)]\n",
    "\n",
    "#### ğŸ’¡ EJEMPLO 4 (UNIFICACIÃ“N DE DATAFRAMES [FULL] o [OUTER]) â¬…ï¸ AMBOS REALIZAN LO MISMO\n",
    "df_ejemplo_4 = df_uno.join(other=df_dos,on=\"ID_Cliente\",how=\"full\")\n",
    "# df_ejemplo_4.shape[0] ## Cantidad de registros: 9\n",
    "# df_ejemplo_4.head(9)\n",
    "## â¡ï¸ FULL u OUTER MANTIENE LA INFORMACIÃ“N DE AMBOS DATAFRAMES.\n",
    "\n",
    "#### ğŸ’¡ EJEMPLO 5 (UNIFICACIÃ“N DE DATAFRAMES [CROSS] â¡ï¸ Forma 2.)\n",
    "df_ejemplo_5 = df_uno.join(other=df_dos,how=\"cross\")\n",
    "# df_ejemplo_5.shape[0] ## Cantidad de registros: 40\n",
    "# df_ejemplo_5.head()\n",
    "## â¡ï¸ CROSS GENERA TODAS LAS COMBINACIONES POSIBLES DE LAS FILAS DEL df_uno CON LAS FILAS DEL df_dos. \n",
    "##     (YA NO NECESITAMOS UTILIZAR EL PARÃMETRO \"on=\")\n",
    "\n",
    "# #### ğŸ’¡ EJEMPLO 6 (UNIFICACIÃ“N DE DATAFRAMES [INNER] â¡ï¸ Forma 2. + left_on + right_on)\n",
    "df_ejemplo_6 = df_uno.join(other=df_tres,how=\"inner\",left_on=\"ID_Cliente\",right_on=\"Cliente_ID\")\n",
    "# df_ejemplo_6.shape[0] ## Cantidad de registros: 7\n",
    "# df_ejemplo_6.head(7)\n",
    "## â¡ï¸ CUANDO UTILIZAMOS left_on Y right_on YA NO NECESITAMOS UTILIZAR EL PARÃMETRO \"on=\"\n",
    "## ğŸ“ left_on â¬…ï¸â¡ï¸ right_on : ParÃ¡metros que permiten unificar dataset/dataframes\n",
    "##    cuando las columnas en comÃºn tienen diferente nombre.\n",
    "\n",
    "\n",
    "#### ğŸ’¡ EJEMPLO ANTI (PERMITE DEVOLVER LAS FILAS DE df_uno QUE NO SE ENCUENTRAN EN df_dos)\n",
    "df_ejemplo_anti = df_uno.join(other=df_dos,how=\"anti\",on=\"ID_Cliente\")\n",
    "# df_ejemplo_anti.shape[0] ## Cantidad de registros: 1\n",
    "# df_ejemplo_anti.head()\n",
    "\n",
    "\n",
    "#### ğŸ’¡ EJEMPLO SEMI (PERMITE DEVOLVER LAS FILAS DE df_uno EXISTENTES EN df_dos)\n",
    "####        PERO DEVOLVIENDO SOLO LAS FILAS DE df_uno\n",
    "df_ejemplo_semi = df_uno.join(other=df_dos,how=\"semi\",on=\"ID_Cliente\")\n",
    "# df_ejemplo_semi.shape[0] ## Cantidad de registros: 1\n",
    "# df_ejemplo_semi.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ba45fd",
   "metadata": {},
   "source": [
    "##### Concat en Polars ğŸ“ŠğŸ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2da9e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    ğŸ“ SINTAXIS: \n",
    "\n",
    "        dataset_union_nombre = pl.concat([\n",
    "            dataset_nombre_1.set_index([\"NombreColumna1\",\"NombreColumna2\",\"NombreColumnaN\"]),\n",
    "            dataset_nombre_2.set_index([\"NombreColumna1\",\"NombreColumna2\",\"NombreColumnaN\"])],\n",
    "            axis = 1,ignore_index = True\n",
    "        )\n",
    "                                                        \n",
    "        ==================================================================================================  \n",
    "\n",
    "    ### ğŸ’¡Importante: Concat permite unificar los datasets/dataframes a nivel fila, es decir,\n",
    "                       unifica verticalmente las columnas de un dataset/dataframe A; con las columnas\n",
    "                       de un dataset/dataframe B; gracias a la(s) columna(s) en comÃºn que tienen ambos \n",
    "                       conjuntos de datos.\n",
    "                       \n",
    "                       Debemos tener en cuenta que ambos datasets/dataframes deben tener la misma cantidad\n",
    "                       tipos y orden en las columnas. AdemÃ¡s, el parÃ¡metro \"axis\" siempre debe igualarse a 1 para\n",
    "                       que los datastes/dataframes se unifiquen a nivel vertical columnar. Por otro lado,\n",
    "                       el parÃ¡metro \"ignore_index\" debe permanecer en True para que el Ã­ndice del dataset/\n",
    "                       dataframe nuevo se reestablezca.\n",
    "\"\"\"\n",
    "### âœ… Utilizaremos este dataset de ejemplo:\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "diccionario_uno = {\n",
    "    \"Categorias\":[\"ELECTRODOMÃ‰STICOS\",\"TECNOLOGÃA\",\"JUGUETES\",\"DEPORTE\",\"CULTURA\"],\n",
    "    \"AÃ±o\": [2022,2022,2023,2023,2023],\n",
    "    \"Ventas\":np.random.uniform(low=3500.25,high=3800.30,size=5).round(2).tolist()\n",
    "}\n",
    "\n",
    "diccionario_dos = {\n",
    "    \"Categorias\":[\"ELECTRODOMÃ‰STICOS\",\"TECNOLOGÃA\",\"JUGUETES\",\"DEPORTE\",\"CULTURA\"],\n",
    "    \"AÃ±o\": [2024,2024,2024,2025,2025],\n",
    "    \"Ventas\":np.random.uniform(low=2150.25,high=4580.30,size=5).round(2).tolist()\n",
    "}\n",
    "\n",
    "diccionario_tres = {\n",
    "    \"Cat\":[\"ELECTRODOMÃ‰STICOS\",\"TECNOLOGÃA\",\"JUGUETES\",\"DEPORTE\",\"CULTURA\"],\n",
    "    \"AÃ±os\": [2024,2024,2024,2025,2025],\n",
    "    \"Vent\":np.random.uniform(low=2150.25,high=4580.30,size=5).round(2).tolist()\n",
    "}\n",
    "\n",
    "diccionario_cuatro = {\n",
    "    \"Cat\":[\"ELECTRODOMÃ‰STICOS\",\"TECNOLOGÃA\",\"JUGUETES\",\"DEPORTE\",\"CULTURA\"],\n",
    "    \"AÃ±os\": [2024,2024,2024,2025,2025],\n",
    "    \"Vent\":np.random.uniform(low=2150.25,high=4580.30,size=5).round(2).tolist()\n",
    "}\n",
    "\n",
    "df_uno = pl.DataFrame(diccionario_uno)\n",
    "df_dos = pl.DataFrame(diccionario_dos)\n",
    "df_tres = pl.DataFrame(diccionario_tres)\n",
    "df_cuatro = pl.DataFrame(diccionario_cuatro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1336c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Categorias</th><th>AÃ±o</th><th>Ventas</th></tr><tr><td>str</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;ELECTRODOMÃ‰STICOS&quot;</td><td>2022</td><td>3620.09</td></tr><tr><td>&quot;TECNOLOGÃA&quot;</td><td>2022</td><td>3676.05</td></tr><tr><td>&quot;JUGUETES&quot;</td><td>2023</td><td>3667.62</td></tr><tr><td>&quot;DEPORTE&quot;</td><td>2023</td><td>3792.08</td></tr><tr><td>&quot;CULTURA&quot;</td><td>2023</td><td>3535.57</td></tr><tr><td>&quot;ELECTRODOMÃ‰STICOS&quot;</td><td>2024</td><td>3435.57</td></tr><tr><td>&quot;TECNOLOGÃA&quot;</td><td>2024</td><td>2695.34</td></tr><tr><td>&quot;JUGUETES&quot;</td><td>2024</td><td>2500.11</td></tr><tr><td>&quot;DEPORTE&quot;</td><td>2025</td><td>3923.25</td></tr><tr><td>&quot;CULTURA&quot;</td><td>2025</td><td>4531.17</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 3)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ Categorias        â”† AÃ±o  â”† Ventas  â”‚\n",
       "â”‚ ---               â”† ---  â”† ---     â”‚\n",
       "â”‚ str               â”† i64  â”† f64     â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ ELECTRODOMÃ‰STICOS â”† 2022 â”† 3620.09 â”‚\n",
       "â”‚ TECNOLOGÃA        â”† 2022 â”† 3676.05 â”‚\n",
       "â”‚ JUGUETES          â”† 2023 â”† 3667.62 â”‚\n",
       "â”‚ DEPORTE           â”† 2023 â”† 3792.08 â”‚\n",
       "â”‚ CULTURA           â”† 2023 â”† 3535.57 â”‚\n",
       "â”‚ ELECTRODOMÃ‰STICOS â”† 2024 â”† 3435.57 â”‚\n",
       "â”‚ TECNOLOGÃA        â”† 2024 â”† 2695.34 â”‚\n",
       "â”‚ JUGUETES          â”† 2024 â”† 2500.11 â”‚\n",
       "â”‚ DEPORTE           â”† 2025 â”† 3923.25 â”‚\n",
       "â”‚ CULTURA           â”† 2025 â”† 4531.17 â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### ğŸ’¡ EJEMPLO 1 (UNIFICACIÃ“N DE DATAFRAMES A NIVEL COLUMNAR - VERTICAL) \n",
    "df_ejemplo_1 = pl.concat([df_uno,df_dos],how=\"vertical\")\n",
    "# df_ejemplo_1.shape[0] ## Cantidad de registros: 10\n",
    "# df_ejemplo_1.head(10)\n",
    "\n",
    "#### ğŸ’¡ EJEMPLO 2 (UNIFICACIÃ“N DE DATAFRAMES A NIVEL COLUMNAR - HORIZONTAL) \n",
    "##----- PARA LA UNIÃ“N EN HORIZONTAL, NO DEBEN EXISTIR COLUMNAS CON NOMBRE IGUALES\n",
    "df_ejemplo_2 = pl.concat([df_uno,df_tres],how=\"horizontal\")\n",
    "# df_ejemplo_2.shape[0] ## Cantidad de registros: 5\n",
    "# df_ejemplo_2.head(10)\n",
    "\n",
    "#### ğŸ’¡ EJEMPLO 3 (UNIFICACIÃ“N DE DATAFRAMES A NIVEL COLUMNAR - DIAGONAL) \n",
    "df_ejemplo_3 = pl.concat([df_uno,df_tres],how=\"diagonal\")\n",
    "# df_ejemplo_3.shape[0] ## Cantidad de registros: 10\n",
    "# df_ejemplo_3.head(10)\n",
    "\n",
    "# #### ğŸ’¡ EJEMPLO 4 (UNIFICACIÃ“N DE DATAFRAMES A NIVEL COLUMNAR - VERTICAL) â¬…ï¸ CON DIFERENTES NOMBRES \n",
    "\n",
    "# ##---- PASO A). RENOMBRAR LAS COLUMNAS\n",
    "# df_cuatro = df_cuatro.rename({\"Cat\":\"Categorias\",\"AÃ±os\":\"AÃ±o\",\"Vent\":\"Ventas\"}) ##â¬…ï¸ EJECUTAMOS UNA SOLA VEZ\n",
    "# df_cuatro.head()\n",
    "\n",
    "# ##---- PASO B). UNIFICAR DATASETS/DATAFRAMES\n",
    "\n",
    "df_ejemplo_4 = pl.concat([df_uno,df_cuatro],how=\"vertical\")\n",
    "# df_ejemplo_4.shape[0] ## Cantidad de registros: 10\n",
    "# df_ejemplo_4.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54715cf",
   "metadata": {},
   "source": [
    "#### Fase 6. ExportaciÃ³n de Datos en Polars ğŸ»â€â„ï¸ğŸ—ƒï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7132d042",
   "metadata": {},
   "source": [
    "Esta fase final en la manipulaciÃ³n de datos brinda permite que la informaciÃ³n previamente procesada se pueda consumir, intercambiar o almacenar. Su importancia radica en garantizar informaciÃ³n limpia y transformada estÃ© disponible para otros sistemas, anÃ¡lisis posteriores o toma de decisiones, ya sea en archivos planos (CSV, Excel), estructurados (JSON, Parquet) o de alto rendimiento en entornos de Big Data (Parquet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87d7424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ğŸ’¡ UTLIZAREMOS DE EJEMPLO ESTE DATASET\n",
    "data = {\n",
    "    \"id\": [1, 2, 3, 3, None],\n",
    "    \"nombre\": [\"Ana\", \"Luis\", \"Karla\", \"Karla\", \"Pedro\"],\n",
    "    \"edad\": [23, 35, 29, 29, None]\n",
    "}\n",
    "import polars as pl\n",
    "df = pl.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4299620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### âœ… Realizaremos una Limpieza bÃ¡sica\n",
    "df = df.drop_nulls()                 # eliminar filas con valores nulos\n",
    "df = df.unique()        # eliminar duplicados\n",
    "df = df.with_columns(\n",
    "    pl.col(\"id\").cast(dtype=pl.Int64).alias(\"id\") # castear columna a entero\n",
    ")\n",
    "df = df.rename({\"nombre\":\"Nombre\",\"edad\":\"Edad\"},strict=True) # Renombrar columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfee8847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV exportado.\n"
     ]
    }
   ],
   "source": [
    "### âœ… Exportando el dataset\n",
    "## ----- Formato CSV(Comma Separated Values) \n",
    "\"\"\"\n",
    "    SINTAXIS: \n",
    "        dataset_nombre.write_csv(file=\"RutaAlmacenarArchivoExportado\",separator=\"SeparadorDatos\")    \n",
    "    \n",
    "    âœ”ï¸ file: Es el parÃ¡metro que permite especificar la ruta donde se almacenarÃ¡ el archivo.\n",
    "    âœ”ï¸ separator: Es el parÃ¡metro que permite especificar el signo de puntuaciÃ³n a separar los datos (Mayormente utilizamos (,) o (;) ).\n",
    "    \n",
    "    ### ğŸ§  TENER EN CUENTA QUE LA EXTENSIÃ“N DEBE SER IGUAL A LA FUNCIÃ“N DE EXPORTACIÃ“N DEL ARCHIVO\n",
    "    ###     Por ejemplo: âœ… write_csv-> .csv ---- âŒ write_csv -> .xlsx\n",
    "\"\"\"\n",
    "### ğŸ’¡ EJEMPLO\n",
    "df.write_csv(file=\"../datasets/fase_exportacion/polars_export.csv\", separator=\",\")\n",
    "print(\"Archivo CSV exportado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6023b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo Excel exportado.\n"
     ]
    }
   ],
   "source": [
    "### âœ… Exportando el dataset\n",
    "## ----- Formato EXCEL\n",
    "\"\"\"\n",
    "    SINTAXIS: \n",
    "        dataset_nombre.df.write_excel(workbook=\"RutaAlmacenarArchivoExportado\",worksheet=\"NombreDeLaHojaDelExcel\")    \n",
    "    \n",
    "    âœ”ï¸ workbook: Es el parÃ¡metro que permite especificar la ruta donde se almacenarÃ¡ el archivo.\n",
    "    âœ”ï¸ worksheet: Es el parÃ¡metro que permite establecer el nombre de la hoja donde se almacenarÃ¡ el archivo excel.\n",
    "    \n",
    "    ### ğŸ§  TENER EN CUENTA QUE LA EXTENSIÃ“N DEBE SER IGUAL A LA FUNCIÃ“N DE EXPORTACIÃ“N DEL ARCHIVO\n",
    "    ###     Por ejemplo: âœ… write_excel-> .xlsx ---- âŒ write_excel -> .csv\n",
    "    \n",
    "    ### ğŸ§  SE MOSTRARÃN LOS EJEMPLOS CON LOS PRINCIPALES PARÃMETROS (workbook, worksheet)\n",
    "    ### âœ”ï¸ NecesitarÃ¡s instalar el pluging para Polars (creaciÃ³n de archivos excel): pip install xlsxwriter\n",
    "\"\"\"\n",
    "### ğŸ’¡ EJEMPLO\n",
    "df.write_excel(workbook=\"../datasets/fase_exportacion/polars_export.xlsx\",worksheet=\"HojaPrueba\") \n",
    "print(\"Archivo Excel exportado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010c357d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo JSON BÃ¡sico exportado.\n"
     ]
    }
   ],
   "source": [
    "### âœ… Exportando el dataset\n",
    "## ----- Formato JSON (JAVASCRIPT OBJECT NOTATION)\n",
    "\"\"\"\n",
    "    SINTAXIS: \n",
    "        dataset_nombre.write_json(file=\"RutaAlmacenarArchivoExportado\")  \n",
    "    \n",
    "    âœ”ï¸ file: Es el parÃ¡metro que permite especificar la ruta donde se almacenarÃ¡ el archivo.\n",
    "              \n",
    "    ### ğŸ§  TENER EN CUENTA QUE LA EXTENSIÃ“N DEBE SER IGUAL A LA FUNCIÃ“N DE EXPORTACIÃ“N DEL ARCHIVO\n",
    "    ###     Por ejemplo: âœ… write_json-> .json ---- âŒ write_json -> .xlsx\n",
    "\"\"\"\n",
    "# df.write_json()\n",
    "# ### ğŸ’¡ EJEMPLO \n",
    "df.write_json(file=\"../datasets/fase_exportacion/polars_export_basico.json\")\n",
    "print(\"Archivo JSON BÃ¡sico exportado.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcb576f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo PARQUET exportado.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### âœ… Exportando el dataset\n",
    "## ----- Formato PARQUET (FORMATO COLUMNAR OPTIMIZADO PARA SOLUCIONES DE BIG DATA)\n",
    "\"\"\"\n",
    "    SINTAXIS: \n",
    "        dataset_nombre.write_parquet(file=\"RutaAlmacenarArchivoExportado\",compression=\"brotli|gzip|lzo|snappy|zstd\")\n",
    "    \n",
    "    âœ”ï¸ file: Es el parÃ¡metro que permite especificar la ruta donde se almacenarÃ¡ el archivo.\n",
    "    âœ”ï¸ compression: Es el parÃ¡metro que permite reducir el tamaÃ±o del archivo.\n",
    "                  \n",
    "    ### ğŸ§  TENER EN CUENTA QUE LA EXTENSIÃ“N DEBE SER IGUAL A LA FUNCIÃ“N DE EXPORTACIÃ“N DEL ARCHIVO\n",
    "    ###     Por ejemplo: âœ… write_parquet-> .parquet ---- âŒ write_parquet -> .xlsx\n",
    "    ### ğŸ’¡ EN LOS SIGUIENTES EJEMPLOS UTILIZAREMOS LOS PARÃMETROS CON LOS VALORES MEJORES OPTIMIZADOS.\n",
    "\"\"\"\n",
    "### ğŸ’¡ EJEMPLO 1: EXPOTANDO FORMATO PARQUET (compression='snappy' y engine='pyarrow')\n",
    "df.write_parquet(file=\"../datasets/fase_exportacion/polars_export_parquet.parquet\",compression=\"snappy\")\n",
    "print(\"Archivo PARQUET exportado.\")\n",
    "\n",
    "### ğŸ§  A tener en cuenta:\n",
    "\"\"\"\n",
    "compression=\"snappy\"  # RÃ¡pido, compresiÃ³n moderada\n",
    "compression=\"gzip\"    # Lento, alta compresiÃ³n\n",
    "compression=\"brotli\"  # Mejor compresiÃ³n, mÃ¡s lento\n",
    "\n",
    "\"\"\"\n",
    "print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
